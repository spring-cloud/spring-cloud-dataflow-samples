[[gemfire-cq-log-local]]
==== Using the Local Server
===== Additional Prerequisites
* A Running Data Flow Server
include::{docs_dir}/local-server.adoc[]
* A running instance of https://www.rabbitmq.com[Rabbit MQ]

===== Building and Running the Demo

. Use gfsh to start a locator and server
+
```
gfsh>start locator --name=locator1
gfsh>start server --name=server1

```
. Create a region called `Orders`
+
```
gfsh>create region --name Orders --type=REPLICATE
```
+
*Use the Shell to create the sample stream*
+
. https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app[Register] the out-of-the-box applications for the Rabbit binder
+
include::{docs_dir}/maven-access.adoc[]
+
[subs="attributes"]
```
dataflow:>app import --uri {app-import-rabbit-maven}
```
+
. Create the stream
+
This example creates an gemfire-cq source to which will publish events matching a query criteria on a region. In this case we will monitor the `Orders` region. For simplicity, we will avoid creating a data structure for the order.
Each cache entry contains an integer value representing the quantity of the ordered item. This stream will fire a message whenever the value>999. By default, the source emits only the value. Here we will override that using the
`cq-event-expression` property.  This accepts a SpEL expression bound to a https://geode.apache.org/releases/latest/javadoc/org/apache/geode/cache/query/CqEvent.html[CQEvent]. To reference the entire CQEvent instance, we use `#this`.
In order to display the contents in the log, we will invoke `toString()` on the instance.
+
```
dataflow:>stream create --name orders --definition " gemfire-cq --query='SELECT * from /Orders o where o > 999' --cq-event-expression=#this.toString() | log" --deploy
```
NOTE: If the Geode locator isn't running on default port on `localhost`, add the options `--connect-type=locator --host-addresses=<host>:<port>`. If there are multiple
locators, you can provide a comma separated list of locator addresses. This is not necessary for the sample but is typical for production environments to enable fail-over.

. Verify the stream is successfully deployed
+
```
dataflow:>stream list
```

. Monitor stdout for the log sink. When you deploy the stream, you will see log messages in the Data Flow server console like this
+
```
2017-10-30 09:39:36.283  INFO 8167 --- [nio-9393-exec-5] o.s.c.d.spi.local.LocalAppDeployer       : Deploying app with deploymentId orders.log instance 0.
   Logs will be in /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/spring-cloud-dataflow-5375107584795488581/orders-1509370775940/orders.log
```
+
Copy the location of the `log` sink logs. This is a directory that ends in `orders.log`. The log files will be in `stdout_0.log` under this directory. You can monitor the output of the log sink using `tail`, or something similar:
+
```
$tail -f /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/spring-cloud-dataflow-5375107584795488581/orders-1509370775940/orders.log/stdout_0.log
```
+
. Using `gfsh`, create and update some cache entries
+
```
gfsh>put --region Orders  --value-class java.lang.Integer --key 01234 --value 1000
gfsh>put --region Orders  --value-class java.lang.Integer --key 11234 --value 1005
gfsh>put --region Orders  --value-class java.lang.Integer --key 21234 --value 100
gfsh>put --region Orders  --value-class java.lang.Integer --key 31234 --value 999
gfsh>put --region Orders  --value-class java.lang.Integer --key 21234 --value 1000

```
+
. Observe the log output
You should see messages like:
+
```
2017-10-30 09:53:02.231  INFO 8563 --- [ire-cq.orders-1] log-sink                                 : CqEvent [CqName=GfCq1; base operation=CREATE; cq operation=CREATE; key=01234; value=1000]
2017-10-30 09:53:19.732  INFO 8563 --- [ire-cq.orders-1] log-sink                                 : CqEvent [CqName=GfCq1; base operation=CREATE; cq operation=CREATE; key=11234; value=1005]
2017-10-30 09:53:53.242  INFO 8563 --- [ire-cq.orders-1] log-sink                                 : CqEvent [CqName=GfCq1; base operation=UPDATE; cq operation=CREATE; key=21234; value=1000]
```
+
. Another interesting demonstration combines `gemfire-cq` with the link::../http-gemfire/README.adoc[http-gemfire] example.
```
dataflow:> stream create --name stocks --definition "http --port=9090 | gemfire-json-server --regionName=Stocks --keyExpression=payload.getField('symbol')" --deploy
dataflow:> stream create --name stock_watch --definition "gemfire-cq --query='Select * from /Stocks where symbol=''VMW''' | log" --deploy
```

. You're done!
