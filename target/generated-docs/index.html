<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 1.5.3">
<title>Spring Cloud Data Flow Samples</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | http://asciidoctor.org */
/* Remove comment around @import statement below when using as a custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section,summary{display:block}
audio,canvas,video{display:inline-block}
audio:not([controls]){display:none;height:0}
[hidden],template{display:none}
script{display:none!important}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
body{margin:0}
a{background:transparent}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
input[type="search"]{-webkit-appearance:textfield;-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box}
input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*:before,*:after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
body{-webkit-font-smoothing:antialiased}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.spread{width:100%}
p.lead,.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{font-size:1.21875em;line-height:1.6}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:none}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #ddddd8;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol,ul.no-bullet,ol.no-bullet{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.no-bullet{list-style:none}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite:before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media only screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7;font-weight:bold}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt,table tr:nth-of-type(even){background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
body{tab-size:4}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix:before,.clearfix:after,.float-group:before,.float-group:after{content:" ";display:table}
.clearfix:after,.float-group:after{clear:both}
*:not(pre)>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background-color:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre,pre>code{line-height:1.45;color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;text-rendering:optimizeSpeed}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background-color:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menu{color:rgba(0,0,0,.8)}
b.button:before,b.button:after{position:relative;top:-1px;font-weight:400}
b.button:before{content:"[";padding:0 3px 0 2px}
b.button:after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header:before,#header:after,#content:before,#content:after,#footnotes:before,#footnotes:after,#footer:before,#footer:after{content:" ";display:table}
#header:after,#content:after,#footnotes:after,#footer:after{clear:both}
#content{margin-top:1.25em}
#content:before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #ddddd8}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #ddddd8;padding-bottom:8px}
#header .details{border-bottom:1px solid #ddddd8;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span:before{content:"\00a0\2013\00a0"}
#header .details br+span.author:before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark:before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber:after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #ddddd8;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #efefed;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media only screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background-color:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #efefed;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #efefed;left:auto;right:0}}
@media only screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background-color:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
.sect1{padding-bottom:.625em}
@media only screen and (min-width:768px){.sect1{padding-bottom:1.25em}}
.sect1+.sect1{border-top:1px solid #efefed}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor:before,h2>a.anchor:before,h3>a.anchor:before,#toctitle>a.anchor:before,.sidebarblock>.content>.title>a.anchor:before,h4>a.anchor:before,h5>a.anchor:before,h6>a.anchor:before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock>caption.title{white-space:nowrap;overflow:visible;max-width:0}
.paragraph.lead>p,#preamble>.sectionbody>.paragraph:first-of-type p{color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>.paragraph:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #ddddd8;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock pre:not(.highlight),.listingblock pre[class="highlight"],.listingblock pre[class^="highlight "],.listingblock pre.CodeRay,.listingblock pre.prettyprint{background:#f7f7f8}
.sidebarblock .literalblock pre,.sidebarblock .listingblock pre:not(.highlight),.sidebarblock .listingblock pre[class="highlight"],.sidebarblock .listingblock pre[class^="highlight "],.sidebarblock .listingblock pre.CodeRay,.sidebarblock .listingblock pre.prettyprint{background:#f2f1f1}
.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;padding:1em;font-size:.8125em}
.literalblock pre.nowrap,.literalblock pre[class].nowrap,.listingblock pre.nowrap,.listingblock pre[class].nowrap{overflow-x:auto;white-space:pre;word-wrap:normal}
@media only screen and (min-width:768px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:.90625em}}
@media only screen and (min-width:1280px){.literalblock pre,.literalblock pre[class],.listingblock pre,.listingblock pre[class]{font-size:1em}}
.literalblock.output pre{color:#f7f7f8;background-color:rgba(0,0,0,.9)}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.listingblock>.content{position:relative}
.listingblock code[data-lang]:before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:#999}
.listingblock:hover code[data-lang]:before{display:block}
.listingblock.terminal pre .command:before{content:attr(data-prompt);padding-right:.5em;color:#999}
.listingblock.terminal pre .command:not([data-prompt]):before{content:"$"}
table.pyhltable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.pyhltable td{vertical-align:top;padding-top:0;padding-bottom:0;line-height:1.45}
table.pyhltable td.code{padding-left:.75em;padding-right:0}
pre.pygments .lineno,table.pyhltable td:not(.code){color:#999;padding-left:0;padding-right:.5em;border-right:1px solid #ddddd8}
pre.pygments .lineno{display:inline-block;margin-right:.25em}
table.pyhltable .linenodiv{background:none!important;padding-right:0!important}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock blockquote p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote:before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.5em;margin-right:.5ex;text-align:right}
.quoteblock .quoteblock{margin-left:0;margin-right:0;padding:.5em 0;border-left:3px solid rgba(0,0,0,.6)}
.quoteblock .quoteblock blockquote{padding:0 0 0 .75em}
.quoteblock .quoteblock blockquote:before{display:none}
.verseblock{margin:0 1em 1.25em 1em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract{margin:0 0 1.25em 0;display:block}
.quoteblock.abstract blockquote,.quoteblock.abstract blockquote p{text-align:left;word-spacing:0}
.quoteblock.abstract blockquote:before,.quoteblock.abstract blockquote p:first-of-type:before{display:none}
table.tableblock{max-width:100%;border-collapse:separate}
table.tableblock td>.paragraph:last-child p>p:last-child,table.tableblock th>p:last-child,table.tableblock td>p:last-child{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all th.tableblock,table.grid-all td.tableblock{border-width:0 1px 1px 0}
table.grid-all tfoot>tr>th.tableblock,table.grid-all tfoot>tr>td.tableblock{border-width:1px 1px 0 0}
table.grid-cols th.tableblock,table.grid-cols td.tableblock{border-width:0 1px 0 0}
table.grid-all *>tr>.tableblock:last-child,table.grid-cols *>tr>.tableblock:last-child{border-right-width:0}
table.grid-rows th.tableblock,table.grid-rows td.tableblock{border-width:0 0 1px 0}
table.grid-all tbody>tr:last-child>th.tableblock,table.grid-all tbody>tr:last-child>td.tableblock,table.grid-all thead:last-child>tr>th.tableblock,table.grid-rows tbody>tr:last-child>th.tableblock,table.grid-rows tbody>tr:last-child>td.tableblock,table.grid-rows thead:last-child>tr>th.tableblock{border-bottom-width:0}
table.grid-rows tfoot>tr>th.tableblock,table.grid-rows tfoot>tr>td.tableblock{border-width:1px 0 0 0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot{border-width:1px 0}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
td>div.verse{white-space:pre}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.unstyled,ol.unnumbered,ul.checklist,ul.none{list-style-type:none}
ul.unstyled,ol.unnumbered,ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1em;font-size:.85em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{width:1em;position:relative;top:1px}
ul.inline{margin:0 auto .625em auto;margin-left:-1.375em;margin-right:0;padding:0;list-style:none;overflow:hidden}
ul.inline>li{list-style:none;float:left;margin-left:1.375em;display:block}
ul.inline>li>*{display:block}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist>table tr>td:first-of-type{padding:0 .75em;line-height:1}
.colist>table tr>td:last-of-type{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left,.imageblock[style*="float: left"]{margin:.25em .625em 1.25em 0}
.imageblock.right,.imageblock[style*="float: right"]{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em 0;border-width:1px 0 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;text-indent:-1.05em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background-color:#00fafa}
.black{color:#000}
.black-background{background-color:#000}
.blue{color:#0000bf}
.blue-background{background-color:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background-color:#fa00fa}
.gray{color:#606060}
.gray-background{background-color:#7d7d7d}
.green{color:#006000}
.green-background{background-color:#007d00}
.lime{color:#00bf00}
.lime-background{background-color:#00fa00}
.maroon{color:#600000}
.maroon-background{background-color:#7d0000}
.navy{color:#000060}
.navy-background{background-color:#00007d}
.olive{color:#606000}
.olive-background{background-color:#7d7d00}
.purple{color:#600060}
.purple-background{background-color:#7d007d}
.red{color:#bf0000}
.red-background{background-color:#fa0000}
.silver{color:#909090}
.silver-background{background-color:#bcbcbc}
.teal{color:#006060}
.teal-background{background-color:#007d7d}
.white{color:#bfbfbf}
.white-background{background-color:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background-color:#fafa00}
span.icon>.fa{cursor:default}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note:before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip:before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning:before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution:before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important:before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background-color:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]:after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background-color:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@media print{@page{margin:1.25cm .75cm}
*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare):after,a[href^="https:"]:not(.bare):after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]:after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #ddddd8!important;padding-bottom:0!important}
.sect1{padding-bottom:0!important}
.sect1+.sect1{border:0!important}
#header>h1:first-child{margin-top:1.25rem}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em 0}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span:before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]:before{display:block}
#footer{background:none!important;padding:0 .9375em}
#footer-text{color:rgba(0,0,0,.6)!important;font-size:.9em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
</style>
</head>
<body class="book toc2 toc-left">
<div id="header">
<h1>Spring Cloud Data Flow Samples</h1>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#spring-cloud-data-flow-samples-overview">1. Overview</a></li>
<li><a href="#_streaming">2. Streaming</a>
<ul class="sectlevel2">
<li><a href="#spring-cloud-data-flow-samples-cassandra-overview">2.1. Cassandra Samples</a></li>
<li><a href="#spring-cloud-data-flow-samples-jdbc-overview">JDBC Samples</a></li>
<li><a href="#spring-cloud-data-flow-samples-gemfire-overview">GemFire Samples</a></li>
<li><a href="#spring-cloud-data-flow-samples-custom-apps-overview">Custom Stream Application Samples</a></li>
</ul>
</li>
<li><a href="#_task_batch">3. Task / Batch</a>
<ul class="sectlevel2">
<li><a href="#spring-cloud-data-flow-samples-task-overview">3.1. Task Samples</a></li>
</ul>
</li>
<li><a href="#_analytics">4. Analytics</a>
<ul class="sectlevel3">
<li><a href="#spring-cloud-data-flow-samples-twitter-analytics-overview">4.1. Twitter Analytics</a></li>
</ul>
</li>
<li><a href="#_functions">5. Functions</a>
<ul class="sectlevel4">
<li><a href="#_functions_in_spring_cloud_data_flow">Functions in Spring Cloud Data Flow</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Version 1.2.0.BUILD-SNAPSHOT</p>
</div>
<div class="paragraph">
<p>&#169; 2012-2017 Pivotal Software, Inc.</p>
</div>
<div class="paragraph">
<p><em>Copies of this document may be made for your own use and for distribution to
others, provided that you do not charge any fee for such copies and further
provided that each copy contains this Copyright Notice, whether distributed in
print or electronically.</em></p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="spring-cloud-data-flow-samples-overview">1. Overview</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This guide contains samples and demonstrations of how to build data microservices applications with <a href="https://cloud.spring.io/spring-cloud-dataflow/">Spring Cloud Data Flow</a>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_streaming">2. Streaming</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="spring-cloud-data-flow-samples-cassandra-overview">2.1. Cassandra Samples</h3>
<div class="sect3">
<h4 id="spring-cloud-data-flow-samples-http-cassandra-overview">2.1.1. HTTP to Cassandra Demo</h4>
<div class="paragraph">
<p>In this demonstration, you will learn how to build a data pipeline using <a href="http://cloud.spring.io/spring-cloud-dataflow/">Spring Cloud Data Flow</a> to consume data from an <em>HTTP</em> endpoint and write the payload to a <em>Cassandra</em> database.</p>
</div>
<div class="paragraph">
<p>We will take you through the steps to configure and Spring Cloud Data Flow server in either a <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started/">local</a> or <a href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#getting-started">Cloud Foundry</a> environment.</p>
</div>
<div class="sect4">
<h5 id="_prerequisites">Prerequisites</h5>
<div class="ulist">
<ul>
<li>
<p>A Running Data Flow Shell</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Spring Cloud Data Flow Shell is available for <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-deploying-spring-cloud-dataflow">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow">build</a> it yourself.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
the Spring Cloud Data Flow Shell and Local server implementation are in the same repository and are both built by running <code>./mvnw install</code> from the project root directory. If you have already run the build, use the jar in <code>spring-cloud-dataflow-shell/target</code>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To run the Shell open a new terminal session:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar
  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
dataflow:&gt;</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The Spring Cloud Data Flow Shell is a Spring Boot application that connects to the Data Flow Serverâ€™s REST API and supports a DSL that simplifies the process of defining a stream or task and managing its lifecycle. Most of these samples
use the shell. If you prefer, you can use the Data Flow UI <a href="http://localhost:9393/dashboard" class="bare">localhost:9393/dashboard</a>, (or wherever it the server is hosted) to perform the same operations.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="http-cassandra-local">Using the Local Server</h5>
<div class="sect5">
<h6 id="_additional_prerequisites">Additional Prerequisites</h6>
<div class="ulist">
<ul>
<li>
<p>A running local Data Flow Server</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Local Data Flow Server is Spring Boot application available for <a href="http://cloud.spring.io/spring-cloud-dataflow/">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow">build</a> it yourself.
If you build it yourself, the executable jar will be in <code>spring-cloud-dataflow-server-local/target</code></p>
</div>
<div class="paragraph">
<p>To run the Local Data Flow server Open a new terminal session:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$cd  &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-LOCAL-JAR&gt;
$java -jar spring-cloud-dataflow-server-local-&lt;VERSION&gt;.jar</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Running instance of <a href="http://kafka.apache.org/downloads.html">Kafka</a></p>
</li>
<li>
<p>Running instance of <a href="http://cassandra.apache.org/">Apache Cassandra</a></p>
</li>
<li>
<p>A database utility tool such as <a href="http://dbeaver.jkiss.org/">DBeaver</a> to connect to the Cassandra instance. You might have to provide <code>host</code>, <code>port</code>, <code>username</code> and <code>password</code> depending on the Cassandra configuration you are using.</p>
</li>
<li>
<p>Create a keyspace and a <code>book</code> table in Cassandra using:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>CREATE KEYSPACE clouddata WITH REPLICATION = { 'class' : 'org.apache.cassandra.locator.SimpleStrategy', 'replication_factor': '1' } AND DURABLE_WRITES = true;
USE clouddata;
CREATE TABLE book  (
    id          uuid PRIMARY KEY,
    isbn        text,
    author      text,
    title       text
);</code></pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><a href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app">Register</a> the out-of-the-box applications for the Kafka binder</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
These samples assume that the Data Flow Server can access a remote Maven repository, <code><a href="https://repo.spring.io/libs-release" class="bare">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code>dataflow:&gt;app import --uri <a href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" class="bare">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code><a href="https://repo.spring.io" class="bare">repo.spring.io</a></code>. For example,
<code>source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code>http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code>maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties">download</a> the required apps or <a href="https://github.com/spring-cloud-stream-app-starters">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code>dataflow:&gt;app register&#8230;&#8203;</code> using the <code>maven://</code> resource URI format corresponding to your installed app.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-kafka-10-maven</code></pre>
</div>
</div>
</li>
<li>
<p>Create the stream</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream create cassandrastream --definition "http --server.port=8888 --spring.cloud.stream.bindings.output.contentType='application/json' | cassandra --ingestQuery='insert into book (id, isbn, title, author) values (uuid(), ?, ?, ?)' --keyspace=clouddata" --deploy

Created and deployed new stream 'cassandrastream'</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If Cassandra isn&#8217;t running on default port on <code>localhost</code> or if you need username and password to connect, use one of the following options to specify the necessary connection parameters: <code>--username='&lt;USERNAME&gt;' --password='&lt;PASSWORD&gt;' --port=&lt;PORT&gt; --contact-points=&lt;LIST-OF-HOSTS&gt;</code>
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Verify the stream is successfully deployed</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream list</code></pre>
</div>
</div>
</li>
<li>
<p>Notice that <code>cassandrastream-http</code> and <code>cassandrastream-cassandra</code> <a href="https://github.com/spring-cloud-stream-app-starters//">Spring Cloud Stream</a> applications are running as Spring Boot applications within the <code>server</code> as a collocated process.</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>2015-12-15 15:52:31.576  INFO 18337 --- [nio-9393-exec-1] o.s.c.d.a.s.l.OutOfProcessModuleDeployer : deploying module org.springframework.cloud.stream.module:cassandra-sink:jar:exec:1.0.0.BUILD-SNAPSHOT instance 0
   Logs will be in /var/folders/c3/ctx7_rns6x30tq7rb76wzqwr0000gp/T/spring-cloud-data-flow-284240942697761420/cassandrastream.cassandra
2015-12-15 15:52:31.583  INFO 18337 --- [nio-9393-exec-1] o.s.c.d.a.s.l.OutOfProcessModuleDeployer : deploying module org.springframework.cloud.stream.module:http-source:jar:exec:1.0.0.BUILD-SNAPSHOT instance 0
   Logs will be in /var/folders/c3/ctx7_rns6x30tq7rb76wzqwr0000gp/T/spring-cloud-data-flow-284240942697761420/cassandrastream.http</code></pre>
</div>
</div>
</li>
<li>
<p>Post sample data pointing to the <code>http</code> endpoint: <code><a href="http://localhost:8888" class="bare">localhost:8888</a></code> (<code>8888</code> is the <code>server.port</code> we specified for the <code>http</code> source in this case)</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;http post --contentType 'application/json' --data '{"isbn": "1599869772", "title": "The Art of War", "author": "Sun Tzu"}' --target http://localhost:8888
&gt; POST (application/json;charset=UTF-8) http://localhost:8888 {"isbn": "1599869772", "title": "The Art of War", "author": "Sun Tzu"}
&gt; 202 ACCEPTED</code></pre>
</div>
</div>
</li>
<li>
<p>Connect to the Cassandra instance and query the table <code>clouddata.book</code> to list the persisted records</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>select * from clouddata.book;</code></pre>
</div>
</div>
</li>
<li>
<p>You&#8217;re done!</p>
</li>
</ol>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="http-cassandra-cf">Using Cloud Foundry Server</h5>
<div class="sect5">
<h6 id="_additional_prerequisites_2">Additional Prerequisites</h6>
<div class="ulist">
<ul>
<li>
<p>Cloud Foundry instance</p>
</li>
<li>
<p>The Spring Cloud Data Flow Cloud Foundry Server</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Cloud Foundry Data Flow Server is Spring Boot application available for <a href="http://cloud.spring.io/spring-cloud-dataflow/">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow-server-cloudfoundry">build</a> it yourself.
If you build it yourself, the executable jar will be in <code>spring-cloud-dataflow-server-cloudfoundry/target</code></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Although you can run the Data Flow Cloud Foundry Server locally and configure it to deploy to any Cloud Foundry instance, we will
deploy the server to Cloud Foundry as recommended.
</td>
</tr>
</table>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Verify that CF instance is reachable (Your endpoint urls will be different from what is shown here).</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf api
API endpoint: https://api.system.io (API version: ...)

$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

No apps found</code></pre>
</div>
</div>
</li>
<li>
<p>Follow the instructions to deploy the <a href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle">Spring Cloud Data Flow Cloud Foundry server</a>. Don&#8217;t worry about creating a Redis service. We won&#8217;t need it. If you are familiar with Cloud Foundry
application manifests, we recommend creating a manifest for the the Data Flow server as shown <a href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#sample-manifest-template">here</a>.</p>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
As of this writing, there is a typo on the <code>SPRING_APPLICATION_JSON</code> entry in the sample manifest. <code>SPRING_APPLICATION_JSON</code> must be followed by <code>:</code> and The JSON string must be
wrapped in single quotes. Alternatively, you can replace that line with <code>MAVEN_REMOTE_REPOSITORIES_REPO1_URL: <a href="https://repo.spring.io/libs-snapshot" class="bare">repo.spring.io/libs-snapshot</a></code>.  If your Cloud Foundry installation is behind a firewall, you may need to install the stream apps used in this sample in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/1.3.0.M2/reference/htmlsingle/#getting-started-maven-configuration">configure</a> the server to access that repository.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Once you have successfully executed <code>cf push</code>, verify the dataflow server is running</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

name                 requested state   instances   memory   disk   urls
dataflow-server      started           1/1         1G       1G     dataflow-server.app.io</code></pre>
</div>
</div>
</li>
<li>
<p>Notice that the <code>dataflow-server</code> application is started and ready for interaction via the url endpoint</p>
</li>
<li>
<p>Connect the <code>shell</code> with <code>server</code> running on Cloud Foundry, e.g., <code><a href="http://dataflow-server.app.io" class="bare">dataflow-server.app.io</a></code></p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar

  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
server-unknown:&gt;</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>server-unknown:&gt;dataflow config server http://dataflow-server.app.io
Successfully targeted http://dataflow-server.app.io
dataflow:&gt;</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Running instance of <code>cassandra</code> in Cloud Foundry or from another Cloud provider</p>
</li>
<li>
<p>A database utility tool such as <a href="http://dbeaver.jkiss.org/">DBeaver</a> to connect to the Cassandra instance. You might have to provide <code>host</code>, <code>port</code>, <code>username</code> and <code>password</code> depending on the Cassandra configuration you are using.</p>
</li>
<li>
<p>Create a <code>book</code> table in your Cassandra keyspace using:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>CREATE TABLE book  (
    id          uuid PRIMARY KEY,
    isbn        text,
    author      text,
    title       text
);</code></pre>
</div>
</div>
</li>
</ul>
</div>
</li>
<li>
<p><a href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app">Register</a> the out-of-the-box applications for the Rabbit binder</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
These samples assume that the Data Flow Server can access a remote Maven repository, <code><a href="https://repo.spring.io/libs-release" class="bare">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code>dataflow:&gt;app import --uri <a href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" class="bare">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code><a href="https://repo.spring.io" class="bare">repo.spring.io</a></code>. For example,
<code>source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code>http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code>maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties">download</a> the required apps or <a href="https://github.com/spring-cloud-stream-app-starters">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code>dataflow:&gt;app register&#8230;&#8203;</code> using the <code>maven://</code> resource URI format corresponding to your installed app.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</code></pre>
</div>
</div>
</li>
<li>
<p>Create the stream</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream create cassandrastream --definition "http --spring.cloud.stream.bindings.output.contentType='application/json' | cassandra --ingestQuery='insert into book (id, isbn, title, author) values (uuid(), ?, ?, ?)' --username='&lt;USERNAME&gt;' --password='&lt;PASSWORD&gt;' --port=&lt;PORT&gt; --contact-points=&lt;HOST&gt; --keyspace='&lt;KEYSPACE&gt;'" --deploy

Created and deployed new stream 'cassandrastream'</code></pre>
</div>
</div>
</li>
<li>
<p>Verify the stream is successfully deployed</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream list</code></pre>
</div>
</div>
</li>
<li>
<p>Notice that <code>cassandrastream-http</code> and <code>cassandrastream-cassandra</code> <a href="https://github.com/spring-cloud-stream-app-starters/">Spring Cloud Stream</a> applications are running as <em>cloud-native</em> (microservice) applications in Cloud Foundry</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

name                        requested state   instances   memory   disk   urls
cassandrastream-cassandra   started           1/1         1G       1G     cassandrastream-cassandra.app.io
cassandrastream-http        started           1/1         1G       1G     cassandrastream-http.app.io
dataflow-server             started           1/1         1G       1G     dataflow-server.app.io</code></pre>
</div>
</div>
</li>
<li>
<p>Lookup the <code>url</code> for <code>cassandrastream-http</code> application from the list above. Post sample data pointing to the <code>http</code> endpoint: <code>&lt;YOUR-cassandrastream-http-APP-URL&gt;</code></p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>http post --contentType 'application/json' --data '{"isbn": "1599869772", "title": "The Art of War", "author": "Sun Tzu"}' --target http://&lt;YOUR-cassandrastream-http-APP-URL&gt;
&gt; POST (application/json;charset=UTF-8) http://cassandrastream-http.app.io {"isbn": "1599869772", "title": "The Art of War", "author": "Sun Tzu"}
&gt; 202 ACCEPTED</code></pre>
</div>
</div>
</li>
<li>
<p>Connect to the Cassandra instance and query the table <code>book</code> to list the data inserted</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>select * from book;</code></pre>
</div>
</div>
</li>
<li>
<p>Now, let&#8217;s try to take advantage of Pivotal Cloud Foundry&#8217;s platform capability. Let&#8217;s scale the <code>cassandrastream-http</code> application from 1 to 3 instances</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf scale cassandrastream-http -i 3
Scaling app cassandrastream-http in org user-dataflow / space development as user...
OK</code></pre>
</div>
</div>
</li>
<li>
<p>Verify App instances (3/3) running successfully</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf apps
Getting apps in org user-dataflow / space development as user...
OK

name                        requested state   instances   memory   disk   urls
cassandrastream-cassandra   started           1/1         1G       1G     cassandrastream-cassandra.app.io
cassandrastream-http        started           3/3         1G       1G     cassandrastream-http.app.io
dataflow-server             started           1/1         1G       1G     dataflow-server.app.io</code></pre>
</div>
</div>
</li>
<li>
<p>You&#8217;re done!</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_summary">Summary</h5>
<div class="paragraph">
<p>In this sample, you have learned:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>How to use Spring Cloud Data Flow&#8217;s <code>Local</code> and <code>Cloud Foundry</code> servers</p>
</li>
<li>
<p>How to use Spring Cloud Data Flow&#8217;s <code>shell</code></p>
</li>
<li>
<p>How to create streaming data pipeline to connect and write to <code>Cassandra</code></p>
</li>
<li>
<p>How to scale data microservice applications on <code>Pivotal Cloud Foundry</code></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="spring-cloud-data-flow-samples-jdbc-overview">JDBC Samples</h3>
<div class="sect3">
<h4 id="_http_to_mysql_demo">2.1.1. HTTP to MySQL Demo</h4>
<div class="paragraph">
<p>In this demonstration, you will learn how to build a data pipeline using <a href="http://cloud.spring.io/spring-cloud-dataflow/">Spring Cloud Data Flow</a> to consume data from an <code>http</code> endpoint and write to MySQL database using <code>jdbc</code> sink.</p>
</div>
<div class="paragraph">
<p>We will take you through the steps to configure and Spring Cloud Data Flow server in either a <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started/">local</a> or <a href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#getting-started">Cloud Foundry</a> environment.</p>
</div>
<div class="sect4">
<h5 id="_prerequisites_2">Prerequisites</h5>
<div class="ulist">
<ul>
<li>
<p>A Running Data Flow Shell</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Spring Cloud Data Flow Shell is available for <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-deploying-spring-cloud-dataflow">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow">build</a> it yourself.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
the Spring Cloud Data Flow Shell and Local server implementation are in the same repository and are both built by running <code>./mvnw install</code> from the project root directory. If you have already run the build, use the jar in <code>spring-cloud-dataflow-shell/target</code>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To run the Shell open a new terminal session:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar
  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
dataflow:&gt;</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The Spring Cloud Data Flow Shell is a Spring Boot application that connects to the Data Flow Serverâ€™s REST API and supports a DSL that simplifies the process of defining a stream or task and managing its lifecycle. Most of these samples
use the shell. If you prefer, you can use the Data Flow UI <a href="http://localhost:9393/dashboard" class="bare">localhost:9393/dashboard</a>, (or wherever it the server is hosted) to perform the same operations.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="_using_local_server">Using Local Server</h5>
<div class="sect5">
<h6 id="_additional_prerequisites_3">Additional Prerequisites</h6>
<div class="ulist">
<ul>
<li>
<p>A running local Data Flow Server</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Local Data Flow Server is Spring Boot application available for <a href="http://cloud.spring.io/spring-cloud-dataflow/">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow">build</a> it yourself.
If you build it yourself, the executable jar will be in <code>spring-cloud-dataflow-server-local/target</code></p>
</div>
<div class="paragraph">
<p>To run the Local Data Flow server Open a new terminal session:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$cd  &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-LOCAL-JAR&gt;
$java -jar spring-cloud-dataflow-server-local-&lt;VERSION&gt;.jar</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Running instance of <a href="http://kafka.apache.org/downloads.html">Kafka</a></p>
</li>
<li>
<p>Running instance of <a href="http://www.mysql.com/">MySQL</a></p>
</li>
<li>
<p>A database utility tool such as <a href="http://dbeaver.jkiss.org/">DBeaver</a> or <a href="https://www.dbvis.com/">DbVisualizer</a></p>
</li>
<li>
<p>Create the <code>test</code> database with a <code>names</code> table (in MySQL) using:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>CREATE DATABASE test;
USE test;
CREATE TABLE names
(
	name varchar(255)
);</code></pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><a href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app">Register</a> the out-of-the-box applications for the Kafka binder</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
These samples assume that the Data Flow Server can access a remote Maven repository, <code><a href="https://repo.spring.io/libs-release" class="bare">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code>dataflow:&gt;app import --uri <a href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" class="bare">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code><a href="https://repo.spring.io" class="bare">repo.spring.io</a></code>. For example,
<code>source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code>http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code>maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties">download</a> the required apps or <a href="https://github.com/spring-cloud-stream-app-starters">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code>dataflow:&gt;app register&#8230;&#8203;</code> using the <code>maven://</code> resource URI format corresponding to your installed app.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-kafka-10-maven</code></pre>
</div>
</div>
</li>
<li>
<p>Create the stream</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream create --name mysqlstream --definition "http --server.port=8787 | jdbc --tableName=names --columns=name --spring.datasource.driver-class-name=org.mariadb.jdbc.Driver --spring.datasource.url='jdbc:mysql://localhost:3306/test'" --deploy

Created and deployed new stream 'mysqlstream'</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If MySQL isn&#8217;t running on default port on <code>localhost</code> or if you need username and password to connect, use one of the following options to specify the necessary connection parameters: <code>--spring.datasource.url='jdbc:mysql://&lt;HOST&gt;:&lt;PORT&gt;/&lt;NAME&gt;' --spring.datasource.username=&lt;USERNAME&gt; --spring.datasource.password=&lt;PASSWORD&gt;</code>
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Verify the stream is successfully deployed</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream list</code></pre>
</div>
</div>
</li>
<li>
<p>Notice that <code>mysqlstream-http</code> and <code>mysqlstream-jdbc</code> <a href="https://github.com/spring-cloud-stream-app-starters//">Spring Cloud Stream</a> applications are running as Spring Boot applications within the Local <code>server</code> as collocated processes.</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>2016-05-03 09:29:55.918  INFO 65162 --- [nio-9393-exec-3] o.s.c.d.spi.local.LocalAppDeployer       : deploying app mysqlstream.jdbc instance 0
   Logs will be in /var/folders/c3/ctx7_rns6x30tq7rb76wzqwr0000gp/T/spring-cloud-dataflow-6850863945840320040/mysqlstream1-1462292995903/mysqlstream.jdbc
2016-05-03 09:29:55.939  INFO 65162 --- [nio-9393-exec-3] o.s.c.d.spi.local.LocalAppDeployer       : deploying app mysqlstream.http instance 0
   Logs will be in /var/folders/c3/ctx7_rns6x30tq7rb76wzqwr0000gp/T/spring-cloud-dataflow-6850863945840320040/mysqlstream-1462292995934/mysqlstream.http</code></pre>
</div>
</div>
</li>
<li>
<p>Post sample data pointing to the <code>http</code> endpoint: <code><a href="http://localhost:8787" class="bare">localhost:8787</a></code> [<code>8787</code> is the <code>server.port</code> we specified for the <code>http</code> source in this case]</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;http post --contentType 'application/json' --target http://localhost:8787 --data "{\"name\": \"Foo\"}"
&gt; POST (application/json;charset=UTF-8) http://localhost:8787 {"name": "Spring Boot"}
&gt; 202 ACCEPTED</code></pre>
</div>
</div>
<div class="paragraph">
<p>+</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Connect to the MySQL instance and query the table <code>test.names</code> to list the new rows:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>select * from test.names;</code></pre>
</div>
</div>
</li>
<li>
<p>You&#8217;re done!</p>
</li>
</ol>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_using_cloud_foundry_server">Using Cloud Foundry Server</h5>
<div class="sect5">
<h6 id="_additional_prerequisites_4">Additional Prerequisites</h6>
<div class="ulist">
<ul>
<li>
<p>Cloud Foundry instance</p>
</li>
<li>
<p>The Spring Cloud Data Flow Cloud Foundry Server</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Cloud Foundry Data Flow Server is Spring Boot application available for <a href="http://cloud.spring.io/spring-cloud-dataflow/">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow-server-cloudfoundry">build</a> it yourself.
If you build it yourself, the executable jar will be in <code>spring-cloud-dataflow-server-cloudfoundry/target</code></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Although you can run the Data Flow Cloud Foundry Server locally and configure it to deploy to any Cloud Foundry instance, we will
deploy the server to Cloud Foundry as recommended.
</td>
</tr>
</table>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Verify that CF instance is reachable (Your endpoint urls will be different from what is shown here).</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf api
API endpoint: https://api.system.io (API version: ...)

$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

No apps found</code></pre>
</div>
</div>
</li>
<li>
<p>Follow the instructions to deploy the <a href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle">Spring Cloud Data Flow Cloud Foundry server</a>. Don&#8217;t worry about creating a Redis service. We won&#8217;t need it. If you are familiar with Cloud Foundry
application manifests, we recommend creating a manifest for the the Data Flow server as shown <a href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#sample-manifest-template">here</a>.</p>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
As of this writing, there is a typo on the <code>SPRING_APPLICATION_JSON</code> entry in the sample manifest. <code>SPRING_APPLICATION_JSON</code> must be followed by <code>:</code> and The JSON string must be
wrapped in single quotes. Alternatively, you can replace that line with <code>MAVEN_REMOTE_REPOSITORIES_REPO1_URL: <a href="https://repo.spring.io/libs-snapshot" class="bare">repo.spring.io/libs-snapshot</a></code>.  If your Cloud Foundry installation is behind a firewall, you may need to install the stream apps used in this sample in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/1.3.0.M2/reference/htmlsingle/#getting-started-maven-configuration">configure</a> the server to access that repository.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Once you have successfully executed <code>cf push</code>, verify the dataflow server is running</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

name                 requested state   instances   memory   disk   urls
dataflow-server      started           1/1         1G       1G     dataflow-server.app.io</code></pre>
</div>
</div>
</li>
<li>
<p>Notice that the <code>dataflow-server</code> application is started and ready for interaction via the url endpoint</p>
</li>
<li>
<p>Connect the <code>shell</code> with <code>server</code> running on Cloud Foundry, e.g., <code><a href="http://dataflow-server.app.io" class="bare">dataflow-server.app.io</a></code></p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar

  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
server-unknown:&gt;</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>server-unknown:&gt;dataflow config server http://dataflow-server.app.io
Successfully targeted http://dataflow-server.app.io
dataflow:&gt;</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Running instance of <code>rabbit</code> in Cloud Foundry</p>
</li>
<li>
<p>Running instance of <code>mysql</code> in Cloud Foundry</p>
</li>
<li>
<p>A database utility tool such as <a href="http://dbeaver.jkiss.org/">DBeaver</a> or <a href="https://www.dbvis.com/">DbVisualizer</a></p>
</li>
<li>
<p>Create the <code>names</code> table (in MySQL) using:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>CREATE TABLE names
(
	name varchar(255)
);</code></pre>
</div>
</div>
</li>
</ul>
</div>
</li>
<li>
<p><a href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app">Register</a> the out-of-the-box applications for the Rabbit binder</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
These samples assume that the Data Flow Server can access a remote Maven repository, <code><a href="https://repo.spring.io/libs-release" class="bare">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code>dataflow:&gt;app import --uri <a href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" class="bare">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code><a href="https://repo.spring.io" class="bare">repo.spring.io</a></code>. For example,
<code>source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code>http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code>maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties">download</a> the required apps or <a href="https://github.com/spring-cloud-stream-app-starters">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code>dataflow:&gt;app register&#8230;&#8203;</code> using the <code>maven://</code> resource URI format corresponding to your installed app.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</code></pre>
</div>
</div>
</li>
<li>
<p>Create the stream</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream create --name mysqlstream --definition "http | jdbc --tableName=names --columns=name"
Created new stream 'mysqlstream'

dataflow:&gt;stream deploy --name mysqlstream --properties "app.jdbc.spring.cloud.deployer.cloudfoundry.services=mysql"
Deployed stream 'mysqlstream'</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
By supplying  the <code>app.jdbc.spring.cloud.deployer.cloudfoundry.services=mysql</code> property, we are deploying the stream with <code>jdbc-sink</code> to automatically bind to <code>mysql</code> service and only this application in the stream gets the service binding. This also eliminates the requirement to supply <code>datasource</code> credentials in stream definition.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Verify the stream is successfully deployed</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream list</code></pre>
</div>
</div>
</li>
<li>
<p>Notice that <code>mysqlstream-http</code> and <code>mysqlstream-jdbc</code> <a href="https://github.com/spring-cloud-stream-app-starters/">Spring Cloud Stream</a> applications are running as <em>cloud-native</em> (microservice) applications in Cloud Foundry</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf apps
Getting apps in org user-dataflow / space development as user...
OK

name                        requested state   instances   memory   disk   urls
mysqlstream-http            started           1/1         1G       1G     mysqlstream-http.app.io
mysqlstream-jdbc            started           1/1         1G       1G     mysqlstream-jdbc.app.io
dataflow-server             started           1/1         1G       1G     dataflow-server.app.io</code></pre>
</div>
</div>
</li>
<li>
<p>Lookup the <code>url</code> for <code>mysqlstream-http</code> application from the list above. Post sample data pointing to the <code>http</code> endpoint: <code>&lt;YOUR-mysqlstream-http-APP-URL&gt;</code></p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>http post --contentType 'application/json' --target http://mysqlstream-http.app.io --data "{\"name\": \"Bar"}"
&gt; POST (application/json;charset=UTF-8) http://mysqlstream-http.app.io {"name": "Bar"}
&gt; 202 ACCEPTED</code></pre>
</div>
</div>
</li>
<li>
<p>Connect to the MySQL instance and query the table <code>names</code> to list the new rows:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>select * from names;</code></pre>
</div>
</div>
</li>
<li>
<p>Now, let&#8217;s take advantage of Pivotal Cloud Foundry&#8217;s platform capability. Let&#8217;s scale the <code>mysqlstream-http</code> application from 1 to 3 instances</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf scale mysqlstream-http -i 3
Scaling app mysqlstream-http in org user-dataflow / space development as user...
OK</code></pre>
</div>
</div>
</li>
<li>
<p>Verify App instances (3/3) running successfully</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf apps
Getting apps in org user-dataflow / space development as user...
OK

name                        requested state   instances   memory   disk   urls
mysqlstream-http            started           3/3         1G       1G     mysqlstream-http.app.io
mysqlstream-jdbc            started           1/1         1G       1G     mysqlstream-jdbc.app.io
dataflow-server             started           1/1         1G       1G     dataflow-server.app.io</code></pre>
</div>
</div>
</li>
<li>
<p>You&#8217;re done!</p>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_summary_2">Summary</h4>
<div class="paragraph">
<p>In this sample, you have learned:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>How to use Spring Cloud Data Flow&#8217;s <code>Local</code> and <code>Cloud Foundry</code> servers</p>
</li>
<li>
<p>How to use Spring Cloud Data Flow&#8217;s <code>shell</code></p>
</li>
<li>
<p>How to create streaming data pipeline to connect and write to <code>MySQL</code></p>
</li>
<li>
<p>How to scale data microservice applications on <code>Pivotal Cloud Foundry</code></p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="spring-cloud-data-flow-samples-gemfire-overview">GemFire Samples</h3>
<div class="sect3">
<h4 id="spring-cloud-data-flow-samples-gemfire-http-overview">2.1.1. HTTP to Gemfire Demo</h4>
<div class="paragraph">
<p>In this demonstration, you will learn how to build a data pipeline using <a href="http://cloud.spring.io/spring-cloud-dataflow/">Spring Cloud Data Flow</a> to consume data from an <code>http</code> endpoint and write to Gemfire using the <code>gemfire</code> sink.</p>
</div>
<div class="paragraph">
<p>We will take you through the steps to configure and run Spring Cloud Data Flow server in either a <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started/">local</a> or <a href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#getting-started">Cloud Foundry</a> environment.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
For legacy reasons the <code>gemfire</code> Spring Cloud Stream Apps are named after <code>Pivotal GemFire</code>. The code base for the commercial product has since been open sourced as <code>Apache Geode</code>. These samples should work with compatible versions of Pivotal GemFire or Apache Geode. Herein we will refer to the installed IMDG simply as <code>Geode</code>.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="_prerequisites_3">Prerequisites</h5>
<div class="ulist">
<ul>
<li>
<p>A Running Data Flow Shell</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Spring Cloud Data Flow Shell is available for <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-deploying-spring-cloud-dataflow">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow">build</a> it yourself.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
the Spring Cloud Data Flow Shell and Local server implementation are in the same repository and are both built by running <code>./mvnw install</code> from the project root directory. If you have already run the build, use the jar in <code>spring-cloud-dataflow-shell/target</code>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To run the Shell open a new terminal session:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar
  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
dataflow:&gt;</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The Spring Cloud Data Flow Shell is a Spring Boot application that connects to the Data Flow Serverâ€™s REST API and supports a DSL that simplifies the process of defining a stream or task and managing its lifecycle. Most of these samples
use the shell. If you prefer, you can use the Data Flow UI <a href="http://localhost:9393/dashboard" class="bare">localhost:9393/dashboard</a>, (or wherever it the server is hosted) to perform the same operations.
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>A Geode installation with a locator and cache server running
Unresolved directive in streaming/gemfire/gemfire-http/overview.adoc - include::geode-setup.adoc[]</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="gemfire-http-local">Using the Local Server</h5>
<div class="sect5">
<h6 id="_additional_prerequisites_5">Additional Prerequisites</h6>
<div class="ulist">
<ul>
<li>
<p>A running local Data Flow Server</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Local Data Flow Server is Spring Boot application available for <a href="http://cloud.spring.io/spring-cloud-dataflow/">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow">build</a> it yourself.
If you build it yourself, the executable jar will be in <code>spring-cloud-dataflow-server-local/target</code></p>
</div>
<div class="paragraph">
<p>To run the Local Data Flow server Open a new terminal session:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$cd  &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-LOCAL-JAR&gt;
$java -jar spring-cloud-dataflow-server-local-&lt;VERSION&gt;.jar</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>A running instance of <a href="https://www.rabbitmq.com">Rabbit MQ</a></p>
</li>
</ul>
</div>
<hr>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Use gfsh to start a locator and server</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>gfsh&gt;start locator --name=locator1
gfsh&gt;start server --name=server1</code></pre>
</div>
</div>
</li>
<li>
<p>Create a region called <code>Stocks</code></p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>gfsh&gt;create region --name Stocks --type=REPLICATE</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect5">
<h6 id="_use_the_shell_to_create_the_sample_stream">Use the Shell to create the sample stream</h6>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><a href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app">Register</a> the out-of-the-box applications for the Rabbit binder</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
These samples assume that the Data Flow Server can access a remote Maven repository, <code><a href="https://repo.spring.io/libs-release" class="bare">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code>dataflow:&gt;app import --uri <a href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" class="bare">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code><a href="https://repo.spring.io" class="bare">repo.spring.io</a></code>. For example,
<code>source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code>http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code>maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties">download</a> the required apps or <a href="https://github.com/spring-cloud-stream-app-starters">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code>dataflow:&gt;app register&#8230;&#8203;</code> using the <code>maven://</code> resource URI format corresponding to your installed app.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</code></pre>
</div>
</div>
</li>
<li>
<p>Create the stream</p>
<div class="paragraph">
<p>This example creates an http endpoint to which we will post stock prices as a JSON document containing <code>symbol</code> and <code>price</code> fields.
The property <code>--json=true</code> to enable Geode&#8217;s JSON support and configures the sink to convert JSON String payloads to <a href="https://geode.apache.org/releases/latest/javadoc/org/apache/geode/pdx/PdxInstance.html">PdxInstance</a>, the recommended way
to store JSON documents in Geode. The <code>keyExpression</code> property is a SpEL expression used to extract the <code>symbol</code> value the PdxInstance to use as an entry key.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
PDX serialization is very efficient and supports OQL queries without requiring a custom domain class.
Use of custom domain types requires these classes to be in the class path of both the stream apps and the cache server.
For this reason, the use of custom payload types is generally discouraged.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream create --name stocks --definition "http --port=9090 | gemfire --json=true --regionName=Stocks --keyExpression=payload.getField('symbol')" --deploy
Created and deployed new stream 'stocks'</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If the Geode locator isn&#8217;t running on default port on <code>localhost</code>, add the options <code>--connect-type=locator --host-addresses=&lt;host&gt;:&lt;port&gt;</code>. If there are multiple
locators, you can provide a comma separated list of locator addresses. This is not necessary for the sample but is typical for production environments to enable fail-over.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Verify the stream is successfully deployed</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream list</code></pre>
</div>
</div>
</li>
<li>
<p>Post sample data pointing to the <code>http</code> endpoint: <code><a href="http://localhost:9090" class="bare">localhost:9090</a></code> (<code>9090</code> is the <code>port</code> we specified for the <code>http</code> source)</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;http post --target http://localhost:9090 --contentType application/json --data '{"symbol":"VMW","price":117.06}'
&gt; POST (application/json) http://localhost:9090 {"symbol":"VMW","price":117.06}
&gt; 202 ACCEPTED</code></pre>
</div>
</div>
</li>
<li>
<p>Using <code>gfsh</code>, connect to the locator if not already connected, and verify the cache entry was created.</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>gfsh&gt;get --key='VMW' --region=/Stocks
Result      : true
Key Class   : java.lang.String
Key         : VMW
Value Class : org.apache.geode.pdx.internal.PdxInstanceImpl

symbol | price
------ | ------
VMW    | 117.06</code></pre>
</div>
</div>
</li>
<li>
<p>You&#8217;re done!</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="gemfire-http-cf">Using the Cloud Foundry Server</h5>
<div class="sect5">
<h6 id="_additional_prerequisites_6">Additional Prerequisites</h6>
<div class="ulist">
<ul>
<li>
<p>A Cloud Foundry instance</p>
</li>
<li>
<p>Cloud Data Flow Cloud Foundry Server</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Cloud Foundry Data Flow Server is Spring Boot application available for <a href="http://cloud.spring.io/spring-cloud-dataflow/">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow-server-cloudfoundry">build</a> it yourself.
If you build it yourself, the executable jar will be in <code>spring-cloud-dataflow-server-cloudfoundry/target</code></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Although you can run the Data Flow Cloud Foundry Server locally and configure it to deploy to any Cloud Foundry instance, we will
deploy the server to Cloud Foundry as recommended.
</td>
</tr>
</table>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Verify that CF instance is reachable (Your endpoint urls will be different from what is shown here).</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf api
API endpoint: https://api.system.io (API version: ...)

$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

No apps found</code></pre>
</div>
</div>
</li>
<li>
<p>Follow the instructions to deploy the <a href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle">Spring Cloud Data Flow Cloud Foundry server</a>. Don&#8217;t worry about creating a Redis service. We won&#8217;t need it. If you are familiar with Cloud Foundry
application manifests, we recommend creating a manifest for the the Data Flow server as shown <a href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#sample-manifest-template">here</a>.</p>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
As of this writing, there is a typo on the <code>SPRING_APPLICATION_JSON</code> entry in the sample manifest. <code>SPRING_APPLICATION_JSON</code> must be followed by <code>:</code> and The JSON string must be
wrapped in single quotes. Alternatively, you can replace that line with <code>MAVEN_REMOTE_REPOSITORIES_REPO1_URL: <a href="https://repo.spring.io/libs-snapshot" class="bare">repo.spring.io/libs-snapshot</a></code>.  If your Cloud Foundry installation is behind a firewall, you may need to install the stream apps used in this sample in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/1.3.0.M2/reference/htmlsingle/#getting-started-maven-configuration">configure</a> the server to access that repository.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Once you have successfully executed <code>cf push</code>, verify the dataflow server is running</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

name                 requested state   instances   memory   disk   urls
dataflow-server      started           1/1         1G       1G     dataflow-server.app.io</code></pre>
</div>
</div>
</li>
<li>
<p>Notice that the <code>dataflow-server</code> application is started and ready for interaction via the url endpoint</p>
</li>
<li>
<p>Connect the <code>shell</code> with <code>server</code> running on Cloud Foundry, e.g., <code><a href="http://dataflow-server.app.io" class="bare">dataflow-server.app.io</a></code></p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar

  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
server-unknown:&gt;</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>server-unknown:&gt;dataflow config server http://dataflow-server.app.io
Successfully targeted http://dataflow-server.app.io
dataflow:&gt;</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Running instance of a <code>rabbit</code> service in Cloud Foundry</p>
</li>
<li>
<p>Running instance of the <a href="https://docs.pivotal.io/p-cloud-cache/1-0/developer.html">Pivotal Cloud Cache for PCF</a> (PCC) service <code>cloudcache</code> in Cloud Foundry.</p>
</li>
</ul>
</div>
</li>
<li>
<p><a href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app">Register</a> the out-of-the-box applications for the Rabbit binder</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
These samples assume that the Data Flow Server can access a remote Maven repository, <code><a href="https://repo.spring.io/libs-release" class="bare">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code>dataflow:&gt;app import --uri <a href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" class="bare">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code><a href="https://repo.spring.io" class="bare">repo.spring.io</a></code>. For example,
<code>source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code>http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code>maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties">download</a> the required apps or <a href="https://github.com/spring-cloud-stream-app-starters">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code>dataflow:&gt;app register&#8230;&#8203;</code> using the <code>maven://</code> resource URI format corresponding to your installed app.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</code></pre>
</div>
</div>
</li>
<li>
<p>Get the PCC connection information</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf service-key cloudcache my-service-key
Getting key my-service-key for service instance cloudcache as &lt;user&gt;...

{
 "locators": [
  "10.0.16.9[55221]",
  "10.0.16.11[55221]",
  "10.0.16.10[55221]"
 ],
 "urls": {
  "gfsh": "http://...",
  "pulse": "http://.../pulse"
 },
 "users": [
  {
   "password": &lt;password&gt;,
   "username": "cluster_operator"
  },
  {
   "password": &lt;password&gt;,
   "username": "developer"
  }
 ]
}</code></pre>
</div>
</div>
</li>
<li>
<p>Using <code>gfsh</code>, connect to the PCC instance as <code>cluster_operator</code> using the service key values and create the Stocks region.</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>gfsh&gt;connect --use-http --url=&lt;gfsh-url&gt; --user=cluster_operator --password=&lt;cluster_operator_password&gt;
gfsh&gt;create region --name Stocks --type=REPLICATE</code></pre>
</div>
</div>
</li>
<li>
<p>Create the stream, connecting to the PCC instance as developer</p>
<div class="paragraph">
<p>This example creates an http endpoint to which we will post stock prices as a JSON document containing <code>symbol</code> and <code>price</code> fields.
The property <code>--json=true</code> to enable Geode&#8217;s JSON support and configures the sink to convert JSON String payloads to <a href="https://geode.apache.org/releases/latest/javadoc/org/apache/geode/pdx/PdxInstance.html">PdxInstance</a>, the recommended way
to store JSON documents in Geode. The <code>keyExpression</code> property is a SpEL expression used to extract the <code>symbol</code> value the PdxInstance to use as an entry key.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
PDX serialization is very efficient and supports OQL queries without requiring a custom domain class.
Use of custom domain types requires these classes to be in the class path of both the stream apps and the cache server.
For this reason, the use of custom payload types is generally discouraged.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream create --name stocks --definition "http --security.basic.enabled=false | gemfire --username=developer --password=&lt;developer-password&gt; --connect-type=locator --host-addresses=10.0.16.9:55221 --regionName=Stocks --keyExpression=payload.getField('symbol')" --deploy</code></pre>
</div>
</div>
</li>
<li>
<p>Verify the stream is successfully deployed</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream list</code></pre>
</div>
</div>
</li>
<li>
<p>Post sample data pointing to the <code>http</code> endpoint</p>
<div class="paragraph">
<p>Get the url of the http source using <code>cf apps</code></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;http post --target http://&lt;http source url&gt; --contentType application/json --data '{"symbol":"VMW","price":117.06}'
&gt; POST (application/json) http://... {"symbol":"VMW","price":117.06}
&gt; 202 ACCEPTED</code></pre>
</div>
</div>
</li>
<li>
<p>Using <code>gfsh</code>, connect to the PCC instance as <code>cluster_operator</code> using the service key values.</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>gfsh&gt;connect --use-http --url=&lt;gfsh-url&gt; --user=cluster_operator --password=&lt;cluster_operator_password&gt;
gfsh&gt;get --key='VMW' --region=/Stocks
Result      : true
Key Class   : java.lang.String
Key         : VMW
Value Class : org.apache.geode.pdx.internal.PdxInstanceImpl

symbol | price
------ | ------
VMW    | 117.06</code></pre>
</div>
</div>
</li>
<li>
<p>You&#8217;re done!</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_summary_3">Summary</h5>
<div class="paragraph">
<p>In this sample, you have learned:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>How to use Spring Cloud Data Flow&#8217;s <code>Local</code> and <code>Cloud Foundry</code> servers</p>
</li>
<li>
<p>How to use Spring Cloud Data Flow&#8217;s <code>shell</code></p>
</li>
<li>
<p>How to create streaming data pipeline to connect and write to <code>gemfire</code></p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="spring-cloud-data-flow-samples-gemfire-log-overview">2.1.2. Gemfire to Log Demo</h4>
<div class="paragraph">
<p>In this demonstration, you will learn how to build a data pipeline using <a href="http://cloud.spring.io/spring-cloud-dataflow/">Spring Cloud Data Flow</a> to consume data from a <code>gemfire</code> endpoint and write to a log using the <code>log</code> sink.
The <code>gemfire</code> source creates a <a href="https://geode.apache.org/releases/latest/javadoc/org/apache/geode/cache/CacheListener.html">CacheListener</a> to monitor events for a region and publish a message whenever an entry is changed.</p>
</div>
<div class="paragraph">
<p>We will take you through the steps to configure and run Spring Cloud Data Flow server in either a <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started/">local</a> or <a href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#getting-started">Cloud Foundry</a> environment.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
For legacy reasons the <code>gemfire</code> Spring Cloud Stream Apps are named after <code>Pivotal GemFire</code>. The code base for the commercial product has since been open sourced as <code>Apache Geode</code>. These samples should work with compatible versions of Pivotal GemFire or Apache Geode. Herein we will refer to the installed IMDG simply as <code>Geode</code>.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="_prerequisites_4">Prerequisites</h5>
<div class="ulist">
<ul>
<li>
<p>A Running Data Flow Shell</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Spring Cloud Data Flow Shell is available for <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-deploying-spring-cloud-dataflow">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow">build</a> it yourself.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
the Spring Cloud Data Flow Shell and Local server implementation are in the same repository and are both built by running <code>./mvnw install</code> from the project root directory. If you have already run the build, use the jar in <code>spring-cloud-dataflow-shell/target</code>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To run the Shell open a new terminal session:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar
  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
dataflow:&gt;</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The Spring Cloud Data Flow Shell is a Spring Boot application that connects to the Data Flow Serverâ€™s REST API and supports a DSL that simplifies the process of defining a stream or task and managing its lifecycle. Most of these samples
use the shell. If you prefer, you can use the Data Flow UI <a href="http://localhost:9393/dashboard" class="bare">localhost:9393/dashboard</a>, (or wherever it the server is hosted) to perform the same operations.
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>A Geode installation with a locator and cache server running
Unresolved directive in streaming/gemfire/gemfire-log/overview.adoc - include::geode-setup.adoc[]</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="gemfire-log-local">Using the Local Server</h5>
<div class="sect5">
<h6 id="_additional_prerequisites_7">Additional Prerequisites</h6>
<div class="ulist">
<ul>
<li>
<p>A Running Data Flow Server</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Local Data Flow Server is Spring Boot application available for <a href="http://cloud.spring.io/spring-cloud-dataflow/">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow">build</a> it yourself.
If you build it yourself, the executable jar will be in <code>spring-cloud-dataflow-server-local/target</code></p>
</div>
<div class="paragraph">
<p>To run the Local Data Flow server Open a new terminal session:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$cd  &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-LOCAL-JAR&gt;
$java -jar spring-cloud-dataflow-server-local-&lt;VERSION&gt;.jar</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>A running instance of <a href="https://www.rabbitmq.com">Rabbit MQ</a></p>
</li>
</ul>
</div>
<hr>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Use gfsh to start a locator and server</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>gfsh&gt;start locator --name=locator1
gfsh&gt;start server --name=server1</code></pre>
</div>
</div>
</li>
<li>
<p>Create a region called <code>Test</code></p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>gfsh&gt;create region --name Test --type=REPLICATE</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect5">
<h6 id="_use_the_shell_to_create_the_sample_stream_2">Use the Shell to create the sample stream.</h6>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><a href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app">Register</a> the out-of-the-box applications for the Rabbit binder</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
These samples assume that the Data Flow Server can access a remote Maven repository, <code><a href="https://repo.spring.io/libs-release" class="bare">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code>dataflow:&gt;app import --uri <a href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" class="bare">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code><a href="https://repo.spring.io" class="bare">repo.spring.io</a></code>. For example,
<code>source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code>http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code>maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties">download</a> the required apps or <a href="https://github.com/spring-cloud-stream-app-starters">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code>dataflow:&gt;app register&#8230;&#8203;</code> using the <code>maven://</code> resource URI format corresponding to your installed app.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</code></pre>
</div>
</div>
</li>
<li>
<p>Create the stream</p>
<div class="paragraph">
<p>This example creates an gemfire source to which will publish events on a region</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream create --name events --definition " gemfire --regionName=Test | log" --deploy
Created and deployed new stream 'events'</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If the Geode locator isn&#8217;t running on default port on <code>localhost</code>, add the options <code>--connect-type=locator --host-addresses=&lt;host&gt;:&lt;port&gt;</code>. If there are multiple
locators, you can provide a comma separated list of locator addresses. This is not necessary for the sample but is typical for production environments to enable fail-over.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Verify the stream is successfully deployed</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream list</code></pre>
</div>
</div>
</li>
<li>
<p>Monitor stdout for the log sink. When you deploy the stream, you will see log messages in the Data Flow server console like this</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>2017-10-28 17:28:23.275  INFO 15603 --- [nio-9393-exec-2] o.s.c.d.spi.local.LocalAppDeployer       : Deploying app with deploymentId events.log instance 0.
   Logs will be in /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/spring-cloud-dataflow-4093992067314402881/events-1509226103269/events.log
2017-10-28 17:28:23.277  INFO 15603 --- [nio-9393-exec-2] o.s.c.d.s.c.StreamDeploymentController   : Downloading resource URI [maven://org.springframework.cloud.stream.app:gemfire-source-rabbit:1.2.0.RELEASE]
2017-10-28 17:28:23.311  INFO 15603 --- [nio-9393-exec-2] o.s.c.d.s.c.StreamDeploymentController   : Deploying application named [gemfire] as part of stream named [events] with resource URI [maven://org.springframework.cloud.stream.app:gemfire-source-rabbit:1.2.0.RELEASE]
2017-10-28 17:28:23.318  INFO 15603 --- [nio-9393-exec-2] o.s.c.d.spi.local.LocalAppDeployer       : Deploying app with deploymentId events.gemfire instance 0.
   Logs will be in /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/spring-cloud-dataflow-4093992067314402881/events-1509226103311/events.gemfire</code></pre>
</div>
</div>
<div class="paragraph">
<p>Copy the location of the <code>log</code> sink logs. This is a directory that ends in <code>events.log</code>. The log files will be in <code>stdout_0.log</code> under this directory. You can monitor the output of the log sink using <code>tail</code>, or something similar:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$tail -f /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/spring-cloud-dataflow-4093992067314402881/events-1509226103269/events.log/stdout_0.log</code></pre>
</div>
</div>
</li>
<li>
<p>Using <code>gfsh</code>, create and update some cache entries</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>gfsh&gt;put --region /Test --key 1  --value "value 1"
gfsh&gt;put --region /Test --key 2  --value "value 2"
gfsh&gt;put --region /Test --key 3  --value "value 3"
gfsh&gt;put --region /Test --key 1  --value "new value 1"</code></pre>
</div>
</div>
</li>
<li>
<p>Observe the log output
You should see messages like:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log sink                               : value 1"
2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log sink                               : value 2"
2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log sink                               : value 3"
2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log sink                               : new value 1"</code></pre>
</div>
</div>
<div class="paragraph">
<p>By default, the message payload contains the updated value. Depending on your application, you may need additional information. The data comes from <a href="https://geode.apache.org/releases/latest/javadoc/org/apache/geode/cache/EntryEvent.html">EntryEvent</a>. You
can access any fields using the source&#8217;s <code>cache-event-expression</code> property. This takes a SpEL expression bound to the EntryEvent. Try something like <code>--cache-event-expression='{key:'+key+',new_value:'+newValue+'}'</code> (HINT: You will need to destroy the stream and recreate it to
add this property, an exercise left to the reader). Now you should see log messages like:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log-sink                                 : {key:1,new_value:value 1}
2017-10-28 17:41:24.466  INFO 18986 --- [emfire.events-1] log-sink                                 : {key:2,new_value:value 2}</code></pre>
</div>
</div>
</li>
<li>
<p>You&#8217;re done!</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="gemfire-log-cf">Using the Cloud Foundry Server</h5>
<div class="sect5">
<h6 id="_additional_prerequisites_8">Additional Prerequisites</h6>
<div class="ulist">
<ul>
<li>
<p>A Cloud Foundry instance</p>
</li>
<li>
<p>The Spring Cloud Data Flow Cloud Foundry Server</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Cloud Foundry Data Flow Server is Spring Boot application available for <a href="http://cloud.spring.io/spring-cloud-dataflow/">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow-server-cloudfoundry">build</a> it yourself.
If you build it yourself, the executable jar will be in <code>spring-cloud-dataflow-server-cloudfoundry/target</code></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Although you can run the Data Flow Cloud Foundry Server locally and configure it to deploy to any Cloud Foundry instance, we will
deploy the server to Cloud Foundry as recommended.
</td>
</tr>
</table>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Verify that CF instance is reachable (Your endpoint urls will be different from what is shown here).</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf api
API endpoint: https://api.system.io (API version: ...)

$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

No apps found</code></pre>
</div>
</div>
</li>
<li>
<p>Follow the instructions to deploy the <a href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle">Spring Cloud Data Flow Cloud Foundry server</a>. Don&#8217;t worry about creating a Redis service. We won&#8217;t need it. If you are familiar with Cloud Foundry
application manifests, we recommend creating a manifest for the the Data Flow server as shown <a href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#sample-manifest-template">here</a>.</p>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
As of this writing, there is a typo on the <code>SPRING_APPLICATION_JSON</code> entry in the sample manifest. <code>SPRING_APPLICATION_JSON</code> must be followed by <code>:</code> and The JSON string must be
wrapped in single quotes. Alternatively, you can replace that line with <code>MAVEN_REMOTE_REPOSITORIES_REPO1_URL: <a href="https://repo.spring.io/libs-snapshot" class="bare">repo.spring.io/libs-snapshot</a></code>.  If your Cloud Foundry installation is behind a firewall, you may need to install the stream apps used in this sample in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/1.3.0.M2/reference/htmlsingle/#getting-started-maven-configuration">configure</a> the server to access that repository.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Once you have successfully executed <code>cf push</code>, verify the dataflow server is running</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

name                 requested state   instances   memory   disk   urls
dataflow-server      started           1/1         1G       1G     dataflow-server.app.io</code></pre>
</div>
</div>
</li>
<li>
<p>Notice that the <code>dataflow-server</code> application is started and ready for interaction via the url endpoint</p>
</li>
<li>
<p>Connect the <code>shell</code> with <code>server</code> running on Cloud Foundry, e.g., <code><a href="http://dataflow-server.app.io" class="bare">dataflow-server.app.io</a></code></p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar

  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
server-unknown:&gt;</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>server-unknown:&gt;dataflow config server http://dataflow-server.app.io
Successfully targeted http://dataflow-server.app.io
dataflow:&gt;</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Running instance of a <code>rabbit</code> service in Cloud Foundry</p>
</li>
<li>
<p>Running instance of the <a href="https://docs.pivotal.io/p-cloud-cache/1-0/developer.html">Pivotal Cloud Cache for PCF</a> (PCC) service <code>cloudcache</code> in Cloud Foundry.</p>
</li>
</ul>
</div>
</li>
<li>
<p><a href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app">Register</a> the out-of-the-box applications for the Rabbit binder</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
These samples assume that the Data Flow Server can access a remote Maven repository, <code><a href="https://repo.spring.io/libs-release" class="bare">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code>dataflow:&gt;app import --uri <a href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" class="bare">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code><a href="https://repo.spring.io" class="bare">repo.spring.io</a></code>. For example,
<code>source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code>http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code>maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties">download</a> the required apps or <a href="https://github.com/spring-cloud-stream-app-starters">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code>dataflow:&gt;app register&#8230;&#8203;</code> using the <code>maven://</code> resource URI format corresponding to your installed app.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</code></pre>
</div>
</div>
</li>
<li>
<p>Get the PCC connection information</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf service-key cloudcache my-service-key
Getting key my-service-key for service instance cloudcache as &lt;user&gt;...

{
 "locators": [
  "10.0.16.9[55221]",
  "10.0.16.11[55221]",
  "10.0.16.10[55221]"
 ],
 "urls": {
  "gfsh": "http://...",
  "pulse": "http://.../pulse"
 },
 "users": [
  {
   "password": &lt;password&gt;,
   "username": "cluster_operator"
  },
  {
   "password": &lt;password&gt;,
   "username": "developer"
  }
 ]
}</code></pre>
</div>
</div>
</li>
<li>
<p>Using <code>gfsh</code>, connect to the PCC instance as <code>cluster_operator</code> using the service key values and create the Test region.</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>gfsh&gt;connect --use-http --url=&lt;gfsh-url&gt; --user=cluster_operator --password=&lt;cluster_operator_password&gt;
gfsh&gt;create region --name Test --type=REPLICATE</code></pre>
</div>
</div>
</li>
<li>
<p>Create the stream, connecting to the PCC instance as developer. This example creates an gemfire source to which will publish events on a region</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow stream create --name events --definition " gemfire --username=developer --password=&lt;developer-password&gt; --connect-type=locator --host-addresses=10.0.16.9:55221 --regionName=Test | log" --deploy</code></pre>
</div>
</div>
</li>
<li>
<p>Verify the stream is successfully deployed</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream list</code></pre>
</div>
</div>
</li>
<li>
<p>Monitor stdout for the log sink</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>cf logs &lt;log-sink-app-name&gt;</code></pre>
</div>
</div>
</li>
<li>
<p>Using <code>gfsh</code>, create and update some cache entries</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>gfsh&gt;connect --use-http --url=&lt;gfsh-url&gt; --user=cluster_operator --password=&lt;cluster_operator_password&gt;
gfsh&gt;put --region /Test --key 1  --value "value 1"
gfsh&gt;put --region /Test --key 2  --value "value 2"
gfsh&gt;put --region /Test --key 3  --value "value 3"
gfsh&gt;put --region /Test --key 1  --value "new value 1"</code></pre>
</div>
</div>
</li>
<li>
<p>Observe the log output</p>
<div class="paragraph">
<p>You should see messages like:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log sink                               : value 1"
2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log sink                               : value 2"
2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log sink                               : value 3"
2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log sink                               : new value 1"</code></pre>
</div>
</div>
<div class="paragraph">
<p>By default, the message payload contains the updated value. Depending on your application, you may need additional information. The data comes from <a href="https://geode.apache.org/releases/latest/javadoc/org/apache/geode/cache/EntryEvent.html">EntryEvent</a>. You
can access any fields using the source&#8217;s <code>cache-event-expression</code> property. This takes a SpEL expression bound to the EntryEvent. Try something like <code>--cache-event-expression='{key:'+key+',new_value:'+newValue+'}'</code> (HINT: You will need to destroy the stream and recreate it to
add this property, an exercise left to the reader). Now you should see log messages like:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log-sink                                 : {key:1,new_value:value 1}
2017-10-28 17:41:24.466  INFO 18986 --- [emfire.events-1] log-sink                                 : {key:2,new_value:value 2}</code></pre>
</div>
</div>
</li>
<li>
<p>You&#8217;re done!</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_summary_4">Summary</h5>
<div class="paragraph">
<p>In this sample, you have learned:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>How to use Spring Cloud Data Flow&#8217;s <code>Local</code> and <code>Cloud Foundry</code> servers</p>
</li>
<li>
<p>How to use Spring Cloud Data Flow&#8217;s <code>shell</code></p>
</li>
<li>
<p>How to create streaming data pipeline to connect and publish events from <code>gemfire</code></p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="spring-cloud-data-flow-samples-gemfire-cq-log-overview">2.1.3. Gemfire CQ to Log Demo</h4>
<div class="paragraph">
<p>In this demonstration, you will learn how to build a data pipeline using <a href="http://cloud.spring.io/spring-cloud-dataflow/">Spring Cloud Data Flow</a> to consume data from a <code>gemfire-cq</code> (Continuous Query) endpoint and write to a log using the <code>log</code> sink.
The <code>gemfire-cq</code> source creates a Continuous Query to monitor events for a region that match the query&#8217;s result set and publish a message whenever such an event is emitted. In this example, we simulate monitoring orders to trigger a process whenever
the quantity ordered is above a defined limit.</p>
</div>
<div class="paragraph">
<p>We will take you through the steps to configure and run Spring Cloud Data Flow server in either a <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started/">local</a> or <a href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#getting-started">Cloud Foundry</a> environment.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
For legacy reasons the <code>gemfire</code> Spring Cloud Stream Apps are named after <code>Pivotal GemFire</code>. The code base for the commercial product has since been open sourced as <code>Apache Geode</code>. These samples should work with compatible versions of Pivotal GemFire or Apache Geode. Herein we will refer to the installed IMDG simply as <code>Geode</code>.
</td>
</tr>
</table>
</div>
<div class="sect4">
<h5 id="_prerequisites_5">Prerequisites</h5>
<div class="ulist">
<ul>
<li>
<p>A Running Data Flow Shell</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Spring Cloud Data Flow Shell is available for <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-deploying-spring-cloud-dataflow">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow">build</a> it yourself.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
the Spring Cloud Data Flow Shell and Local server implementation are in the same repository and are both built by running <code>./mvnw install</code> from the project root directory. If you have already run the build, use the jar in <code>spring-cloud-dataflow-shell/target</code>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To run the Shell open a new terminal session:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar
  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
dataflow:&gt;</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The Spring Cloud Data Flow Shell is a Spring Boot application that connects to the Data Flow Serverâ€™s REST API and supports a DSL that simplifies the process of defining a stream or task and managing its lifecycle. Most of these samples
use the shell. If you prefer, you can use the Data Flow UI <a href="http://localhost:9393/dashboard" class="bare">localhost:9393/dashboard</a>, (or wherever it the server is hosted) to perform the same operations.
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>A Geode installation with a locator and cache server running
Unresolved directive in streaming/gemfire/gemfire-cq-log/overview.adoc - include::geode-setup.adoc[]</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="gemfire-cq-log-local">Using the Local Server</h5>
<div class="sect5">
<h6 id="_additional_prerequisites_9">Additional Prerequisites</h6>
<div class="ulist">
<ul>
<li>
<p>A Running Data Flow Server</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Local Data Flow Server is Spring Boot application available for <a href="http://cloud.spring.io/spring-cloud-dataflow/">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow">build</a> it yourself.
If you build it yourself, the executable jar will be in <code>spring-cloud-dataflow-server-local/target</code></p>
</div>
<div class="paragraph">
<p>To run the Local Data Flow server Open a new terminal session:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$cd  &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-LOCAL-JAR&gt;
$java -jar spring-cloud-dataflow-server-local-&lt;VERSION&gt;.jar</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>A running instance of <a href="https://www.rabbitmq.com">Rabbit MQ</a></p>
</li>
</ul>
</div>
<hr>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Use gfsh to start a locator and server</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>gfsh&gt;start locator --name=locator1
gfsh&gt;start server --name=server1</code></pre>
</div>
</div>
</li>
<li>
<p>Create a region called <code>Orders</code></p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>gfsh&gt;create region --name Orders --type=REPLICATE</code></pre>
</div>
</div>
<div class="paragraph">
<p>===== Use the Shell to create the sample stream.</p>
</div>
</li>
<li>
<p><a href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app">Register</a> the out-of-the-box applications for the Rabbit binder</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
These samples assume that the Data Flow Server can access a remote Maven repository, <code><a href="https://repo.spring.io/libs-release" class="bare">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code>dataflow:&gt;app import --uri <a href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" class="bare">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code><a href="https://repo.spring.io" class="bare">repo.spring.io</a></code>. For example,
<code>source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code>http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code>maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties">download</a> the required apps or <a href="https://github.com/spring-cloud-stream-app-starters">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code>dataflow:&gt;app register&#8230;&#8203;</code> using the <code>maven://</code> resource URI format corresponding to your installed app.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</code></pre>
</div>
</div>
</li>
<li>
<p>Create the stream</p>
<div class="paragraph">
<p>This example creates an gemfire-cq source to which will publish events matching a query criteria on a region. In this case we will monitor the <code>Orders</code> region. For simplicity, we will avoid creating a data structure for the order.
Each cache entry contains an integer value representing the quantity of the ordered item. This stream will fire a message whenever the value&gt;999. By default, the source emits only the value. Here we will override that using the
<code>cq-event-expression</code> property.  This accepts a SpEL expression bound to a <a href="https://geode.apache.org/releases/latest/javadoc/org/apache/geode/cache/query/CqEvent.html">CQEvent</a>. To reference the entire CQEvent instace, we use <code>#this</code>.
In order to display the contents in the log, we will invoke <code>toString()</code> on the instance.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream create --name orders --definition " gemfire-cq --query='SELECT * from /Orders o where o &gt; 999' --cq-event-expression=#this.toString() | log" --deploy
Created and deployed new stream 'events'</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If the Geode locator isn&#8217;t running on default port on <code>localhost</code>, add the options <code>--connect-type=locator --host-addresses=&lt;host&gt;:&lt;port&gt;</code>. If there are multiple
locators, you can provide a comma separated list of locator addresses. This is not necessary for the sample but is typical for production environments to enable fail-over.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Verify the stream is successfully deployed</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream list</code></pre>
</div>
</div>
</li>
<li>
<p>Monitor stdout for the log sink. When you deploy the stream, you will see log messages in the Data Flow server console like this</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>2017-10-30 09:39:36.283  INFO 8167 --- [nio-9393-exec-5] o.s.c.d.spi.local.LocalAppDeployer       : Deploying app with deploymentId orders.log instance 0.
   Logs will be in /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/spring-cloud-dataflow-5375107584795488581/orders-1509370775940/orders.log</code></pre>
</div>
</div>
<div class="paragraph">
<p>Copy the location of the <code>log</code> sink logs. This is a directory that ends in <code>orders.log</code>. The log files will be in <code>stdout_0.log</code> under this directory. You can monitor the output of the log sink using <code>tail</code>, or something similar:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$tail -f /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/spring-cloud-dataflow-5375107584795488581/orders-1509370775940/orders.log/stdout_0.log</code></pre>
</div>
</div>
</li>
<li>
<p>Using <code>gfsh</code>, create and update some cache entries</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 01234 --value 1000
gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 11234 --value 1005
gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 21234 --value 100
gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 31234 --value 999
gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 21234 --value 1000</code></pre>
</div>
</div>
</li>
<li>
<p>Observe the log output
You should see messages like:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>2017-10-30 09:53:02.231  INFO 8563 --- [ire-cq.orders-1] log-sink                                 : CqEvent [CqName=GfCq1; base operation=CREATE; cq operation=CREATE; key=01234; value=1000]
2017-10-30 09:53:19.732  INFO 8563 --- [ire-cq.orders-1] log-sink                                 : CqEvent [CqName=GfCq1; base operation=CREATE; cq operation=CREATE; key=11234; value=1005]
2017-10-30 09:53:53.242  INFO 8563 --- [ire-cq.orders-1] log-sink                                 : CqEvent [CqName=GfCq1; base operation=UPDATE; cq operation=CREATE; key=21234; value=1000]</code></pre>
</div>
</div>
</li>
<li>
<p>Another interesting demonstration combines <code>gemfire-cq</code> with the <a href=":../http-gemfire/README.adoc">http-gemfire</a> example.</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt; stream create --name stocks --definition "http --port=9090 | gemfire-json-server --regionName=Stocks --keyExpression=payload.getField('symbol')" --deploy
dataflow:&gt; stream create --name stock_watch --definition "gemfire-cq --query='Select * from /Stocks where symbol=''VMW''' | log" --deploy</code></pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>You&#8217;re done!</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="gemfire-cq-log-cf">Using the Cloud Foundry Server</h5>
<div class="sect5">
<h6 id="_additional_prerequisites_10">Additional Prerequisites</h6>
<div class="ulist">
<ul>
<li>
<p>A Cloud Foundry instance</p>
</li>
<li>
<p>The Spring Cloud Data Flow Cloud Foundry Server</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Cloud Foundry Data Flow Server is Spring Boot application available for <a href="http://cloud.spring.io/spring-cloud-dataflow/">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow-server-cloudfoundry">build</a> it yourself.
If you build it yourself, the executable jar will be in <code>spring-cloud-dataflow-server-cloudfoundry/target</code></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Although you can run the Data Flow Cloud Foundry Server locally and configure it to deploy to any Cloud Foundry instance, we will
deploy the server to Cloud Foundry as recommended.
</td>
</tr>
</table>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Verify that CF instance is reachable (Your endpoint urls will be different from what is shown here).</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf api
API endpoint: https://api.system.io (API version: ...)

$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

No apps found</code></pre>
</div>
</div>
</li>
<li>
<p>Follow the instructions to deploy the <a href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle">Spring Cloud Data Flow Cloud Foundry server</a>. Don&#8217;t worry about creating a Redis service. We won&#8217;t need it. If you are familiar with Cloud Foundry
application manifests, we recommend creating a manifest for the the Data Flow server as shown <a href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#sample-manifest-template">here</a>.</p>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
As of this writing, there is a typo on the <code>SPRING_APPLICATION_JSON</code> entry in the sample manifest. <code>SPRING_APPLICATION_JSON</code> must be followed by <code>:</code> and The JSON string must be
wrapped in single quotes. Alternatively, you can replace that line with <code>MAVEN_REMOTE_REPOSITORIES_REPO1_URL: <a href="https://repo.spring.io/libs-snapshot" class="bare">repo.spring.io/libs-snapshot</a></code>.  If your Cloud Foundry installation is behind a firewall, you may need to install the stream apps used in this sample in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/1.3.0.M2/reference/htmlsingle/#getting-started-maven-configuration">configure</a> the server to access that repository.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Once you have successfully executed <code>cf push</code>, verify the dataflow server is running</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

name                 requested state   instances   memory   disk   urls
dataflow-server      started           1/1         1G       1G     dataflow-server.app.io</code></pre>
</div>
</div>
</li>
<li>
<p>Notice that the <code>dataflow-server</code> application is started and ready for interaction via the url endpoint</p>
</li>
<li>
<p>Connect the <code>shell</code> with <code>server</code> running on Cloud Foundry, e.g., <code><a href="http://dataflow-server.app.io" class="bare">dataflow-server.app.io</a></code></p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar

  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
server-unknown:&gt;</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>server-unknown:&gt;dataflow config server http://dataflow-server.app.io
Successfully targeted http://dataflow-server.app.io
dataflow:&gt;</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Running instance of a <code>rabbit</code> service in Cloud Foundry</p>
</li>
<li>
<p>Running instance of the <a href="https://docs.pivotal.io/p-cloud-cache/1-0/developer.html">Pivotal Cloud Cache for PCF</a> (PCC) service <code>cloudcache</code> in Cloud Foundry.</p>
</li>
</ul>
</div>
</li>
<li>
<p><a href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app">Register</a> the out-of-the-box applications for the Rabbit binder</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
These samples assume that the Data Flow Server can access a remote Maven repository, <code><a href="https://repo.spring.io/libs-release" class="bare">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code>dataflow:&gt;app import --uri <a href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" class="bare">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code><a href="https://repo.spring.io" class="bare">repo.spring.io</a></code>. For example,
<code>source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code>http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code>maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties">download</a> the required apps or <a href="https://github.com/spring-cloud-stream-app-starters">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code>dataflow:&gt;app register&#8230;&#8203;</code> using the <code>maven://</code> resource URI format corresponding to your installed app.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</code></pre>
</div>
</div>
</li>
<li>
<p>Get the PCC connection information</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf service-key cloudcache my-service-key
Getting key my-service-key for service instance cloudcache as &lt;user&gt;...

{
 "locators": [
  "10.0.16.9[55221]",
  "10.0.16.11[55221]",
  "10.0.16.10[55221]"
 ],
 "urls": {
  "gfsh": "http://...",
  "pulse": "http://.../pulse"
 },
 "users": [
  {
   "password": &lt;password&gt;,
   "username": "cluster_operator"
  },
  {
   "password": &lt;password&gt;,
   "username": "developer"
  }
 ]
}</code></pre>
</div>
</div>
</li>
<li>
<p>Using <code>gfsh</code>, connect to the PCC instance as <code>cluster_operator</code> using the service key values and create the Test region.</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>gfsh&gt;connect --use-http --url=&lt;gfsh-url&gt; --user=cluster_operator --password=&lt;cluster_operator_password&gt;
gfsh&gt;create region --name Orders --type=REPLICATE</code></pre>
</div>
</div>
</li>
<li>
<p>Create the stream using the Data Flow Shell</p>
<div class="paragraph">
<p>This example creates an gemfire-cq source to which will publish events matching a query criteria on a region. In this case we will monitor the <code>Orders</code> region. For simplicity, we will avoid creating a data structure for the order.
Each cache entry contains an integer value representing the quantity of the ordered item. This stream will fire a message whenever the value&gt;999. By default, the source emits only the value. Here we will override that using the
<code>cq-event-expression</code> property.  This accepts a SpEL expression bound to a <a href="https://geode.apache.org/releases/latest/javadoc/org/apache/geode/cache/query/CqEvent.html">CQEvent</a>. To reference the entire CQEvent instance, we use <code>#this</code>.
In order to display the contents in the log, we will invoke <code>toString()</code> on the instance.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream create --name orders --definition " gemfire-cq  --username=developer --password=&lt;developer-password&gt; --connect-type=locator --host-addresses=10.0.16.9:55221 --query='SELECT * from /Orders o where o &gt; 999' --cq-event-expression=#this.toString()  | log" --deploy
Created and deployed new stream 'events'</code></pre>
</div>
</div>
</li>
<li>
<p>Verify the stream is successfully deployed</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream list</code></pre>
</div>
</div>
</li>
<li>
<p>Monitor stdout for the log sink</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>cf logs &lt;log-sink-app-name&gt;</code></pre>
</div>
</div>
</li>
<li>
<p>Using <code>gfsh</code>, create and update some cache entries</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>gfsh&gt;connect --use-http --url=&lt;gfsh-url&gt; --user=cluster_operator --password=&lt;cluster_operator_password&gt;
gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 01234 --value 1000
gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 11234 --value 1005
gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 21234 --value 100
gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 31234 --value 999
gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 21234 --value 1000</code></pre>
</div>
</div>
</li>
<li>
<p>Observe the log output
You should see messages like:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>2017-10-30 09:53:02.231  INFO 8563 --- [ire-cq.orders-1] log-sink                                 : CqEvent [CqName=GfCq1; base operation=CREATE; cq operation=CREATE; key=01234; value=1000]
2017-10-30 09:53:19.732  INFO 8563 --- [ire-cq.orders-1] log-sink                                 : CqEvent [CqName=GfCq1; base operation=CREATE; cq operation=CREATE; key=11234; value=1005]
2017-10-30 09:53:53.242  INFO 8563 --- [ire-cq.orders-1] log-sink                                 : CqEvent [CqName=GfCq1; base operation=UPDATE; cq operation=CREATE; key=21234; value=1000]</code></pre>
</div>
</div>
</li>
<li>
<p>Another interesting demonstration combines <code>gemfire-cq</code> with the <a href="../http-gemfire/README.adoc">http-gemfire</a> example.</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt; stream create --name stocks --definition "http --port=9090 | gemfire-json-server --regionName=Stocks --keyExpression=payload.getField('symbol')" --deploy
dataflow:&gt; stream create --name stock_watch --definition "gemfire-cq --query='Select * from /Stocks where symbol=''VMW''' | log" --deploy</code></pre>
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>You&#8217;re done!</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_summary_5">Summary</h5>
<div class="paragraph">
<p>In this sample, you have learned:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>How to use Spring Cloud Data Flow&#8217;s <code>Local</code> and <code>Cloud Foundry</code> servers</p>
</li>
<li>
<p>How to use Spring Cloud Data Flow&#8217;s <code>shell</code></p>
</li>
<li>
<p>How to create streaming data pipeline to connect and publish CQ events from <code>gemfire</code></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="spring-cloud-data-flow-samples-custom-apps-overview">Custom Stream Application Samples</h3>
<div class="sect3">
<h4 id="spring-cloud-data-flow-samples-custom-application-overview">2.1.1. Custom Spring Cloud Stream Processor</h4>
<div class="sect4">
<h5 id="_prerequisites_6">Prerequisites</h5>
<div class="ulist">
<ul>
<li>
<p>A Running Data Flow Shell</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Spring Cloud Data Flow Shell is available for <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-deploying-spring-cloud-dataflow">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow">build</a> it yourself.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
the Spring Cloud Data Flow Shell and Local server implementation are in the same repository and are both built by running <code>./mvnw install</code> from the project root directory. If you have already run the build, use the jar in <code>spring-cloud-dataflow-shell/target</code>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To run the Shell open a new terminal session:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar
  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
dataflow:&gt;</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The Spring Cloud Data Flow Shell is a Spring Boot application that connects to the Data Flow Serverâ€™s REST API and supports a DSL that simplifies the process of defining a stream or task and managing its lifecycle. Most of these samples
use the shell. If you prefer, you can use the Data Flow UI <a href="http://localhost:9393/dashboard" class="bare">localhost:9393/dashboard</a>, (or wherever it the server is hosted) to perform the same operations.
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>A running local Data Flow Server</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Local Data Flow Server is Spring Boot application available for <a href="http://cloud.spring.io/spring-cloud-dataflow/">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow">build</a> it yourself.
If you build it yourself, the executable jar will be in <code>spring-cloud-dataflow-server-local/target</code></p>
</div>
<div class="paragraph">
<p>To run the Local Data Flow server Open a new terminal session:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$cd  &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-LOCAL-JAR&gt;
$java -jar spring-cloud-dataflow-server-local-&lt;VERSION&gt;.jar</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>A Java IDE</p>
</li>
<li>
<p><a href="https://maven.apache.org/">Maven</a> Installed</p>
</li>
<li>
<p>A running instance of <a href="https://www.rabbitmq.com/">Rabbit MQ</a></p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_create_the_custom_stream_app">Create the custom stream app</h5>
<div class="paragraph">
<p>We will create a custom <a href="https://cloud.spring.io/spring-cloud-stream/">Spring Cloud Stream</a> application and run it on Spring Cloud Data Flow.
We&#8217;ll go through the steps to make a simple processor that converts temperature from Fahrenheit to Celsius.
We will be running the demo locally, but all the steps will work in a Cloud Foundry environment as well.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Create a new spring cloud stream project</p>
<div class="ulist">
<ul>
<li>
<p>Create a <a href="http://start.spring.io/">Spring initializer</a> project</p>
</li>
<li>
<p>Set the group to <code>demo.celsius.converter</code> and the artifact name as <code>celsius-converter-processor</code></p>
</li>
<li>
<p>Choose a message transport binding as a dependency for the custom app
There are options for choosing <code>Rabbit MQ</code> or <code>Kafka</code> as the message transport.
For this demo, we will use <code>rabbit</code>. Type <em>rabbit</em> in the search bar under <em>Search for dependencies</em> and select <code>Stream Rabbit</code>.</p>
</li>
<li>
<p>Hit the generate project button and open the new project in an IDE of your choice</p>
</li>
</ul>
</div>
</li>
<li>
<p>Develop the app</p>
<div class="paragraph">
<p>We can now create our custom app. Our Spring Cloud Stream application is a Spring Boot application that runs as an executable jar. The application will include two Java classes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>CelsiusConverterProcessorAplication.java</code> - the main Spring Boot application class, generated by Spring initializr</p>
</li>
<li>
<p><code>CelsiusConverterProcessorConfiguration.java</code> - the Spring Cloud Stream code that we will write</p>
<div class="paragraph">
<p>We are creating a transformer that takes a Fahrenheit input and converts it to Celsius.
Following the same naming convention as the application file, create a new Java class in the same package called <code>CelsiusConverterProcessorConfiguration.java</code>.</p>
</div>
<div class="listingblock">
<div class="title">CelsiusConverterProcessorConfiguration.java</div>
<div class="content">
<pre class="highlight"><code>@EnableBinding(Processor.class)
public class CelsiusConverterProcessorConfiguration {

    @Transformer(inputChannel = Processor.INPUT, outputChannel = Processor.OUTPUT)
    public int convertToCelsius(String payload) {
        int fahrenheitTemperature = Integer.parseInt(payload);
        return (farenheitTemperature-32)*5/9;
    }
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Here we introduced two important Spring annotations.
First we annotated the class with <code>@EnableBinding(Processor.class)</code>.
Second we created a method and annotated it with <code>@Transformer(inputChannel = Processor.INPUT, outputChannel = Processor.OUTPUT)</code>.
By adding these two annotations we have configured this stream app as a <code>Processor</code> (as opposed to a <code>Source</code> or a <code>Sink</code>).
This means that the application receives input from an upstream application via the <code>Processor.INPUT</code> channel and sends its output to a downstream application via the <code>Processor.OUTPUT</code> channel.</p>
</div>
<div class="paragraph">
<p>The <code>convertToCelsius</code> method takes a <code>String</code> as input for Fahrenheit and then returns the converted Celsius as an integer.
This method is very simple, but that is also the beauty of this programming style.
We can add as much logic as we want to this method to enrich this processor.
As long as we annotate it properly and return valid output, it works as a Spring Cloud Stream Processor. Also note that it is straightforward to unit test this code.</p>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Build the Spring Boot application with Maven</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$cd &lt;PROJECT_DIR&gt;
$./mvnw clean package</code></pre>
</div>
</div>
</li>
<li>
<p>Run the Application standalone</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>java -jar target/celsius-converter-processor-0.0.1-SNAPSHOT.jar</code></pre>
</div>
</div>
<div class="paragraph">
<p>If all goes well, we should have a running standalone Spring Boot Application.
Once we verify that the app is started and running without any errors, we can stop it.</p>
</div>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="_deploy_the_app_to_spring_cloud_data_flow">Deploy the app to Spring Cloud Data Flow</h5>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><a href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app">Register</a> the out-of-the-box applications for the Rabbit binder</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
These samples assume that the Data Flow Server can access a remote Maven repository, <code><a href="https://repo.spring.io/libs-release" class="bare">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code>dataflow:&gt;app import --uri <a href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" class="bare">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code><a href="https://repo.spring.io" class="bare">repo.spring.io</a></code>. For example,
<code>source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code>http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code>maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties">download</a> the required apps or <a href="https://github.com/spring-cloud-stream-app-starters">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code>dataflow:&gt;app register&#8230;&#8203;</code> using the <code>maven://</code> resource URI format corresponding to your installed app.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</code></pre>
</div>
</div>
</li>
<li>
<p>Register the custom processor</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>app register --type processor --name convertToCelsius --uri &lt;File URL of the jar file on the local filesystem where you built the project above&gt; --force</code></pre>
</div>
</div>
</li>
<li>
<p>Create the stream</p>
<div class="paragraph">
<p>We will create a stream that uses the out of the box <code>http</code> source and <code>log</code> sink and our custom transformer.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream create --name convertToCelsiusStream --definition "http  --port=9090 | convertToCelsius | log" --deploy

Created and deployed new stream 'convertToCelsiusStream'</code></pre>
</div>
</div>
</li>
<li>
<p>Verify the stream is successfully deployed</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream list</code></pre>
</div>
</div>
</li>
<li>
<p>Verify that the apps have successfully deployed</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;runtime apps</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>2016-09-27 10:03:11.988  INFO 95234 --- [nio-9393-exec-9] o.s.c.d.spi.local.LocalAppDeployer       : deploying app convertToCelsiusStream.log instance 0
   Logs will be in /var/folders/2q/krqwcbhj2d58csmthyq_n1nw0000gp/T/spring-cloud-dataflow-3236898888473815319/convertToCelsiusStream-1474984991968/convertToCelsiusStream.log
2016-09-27 10:03:12.397  INFO 95234 --- [nio-9393-exec-9] o.s.c.d.spi.local.LocalAppDeployer       : deploying app convertToCelsiusStream.convertToCelsius instance 0
   Logs will be in /var/folders/2q/krqwcbhj2d58csmthyq_n1nw0000gp/T/spring-cloud-dataflow-3236898888473815319/convertToCelsiusStream-1474984992392/convertToCelsiusStream.convertToCelsius
2016-09-27 10:03:14.445  INFO 95234 --- [nio-9393-exec-9] o.s.c.d.spi.local.LocalAppDeployer       : deploying app convertToCelsiusStream.http instance 0
   Logs will be in /var/folders/2q/krqwcbhj2d58csmthyq_n1nw0000gp/T/spring-cloud-dataflow-3236898888473815319/convertToCelsiusStream-1474984994440/convertToCelsiusStream.http</code></pre>
</div>
</div>
</li>
<li>
<p>Post sample data to the <code>http</code> endpoint: <code><a href="http://localhost:9090" class="bare">localhost:9090</a></code> (<code>9090</code> is the <code>port</code> we specified for the <code>http</code> source in this case)</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;http post --target http://localhost:9090 --data 76
&gt; POST (text/plain;Charset=UTF-8) http://localhost:9090 76
&gt; 202 ACCEPTED</code></pre>
</div>
</div>
</li>
<li>
<p>Open the log file for the <code>convertToCelsiusStream.log</code> app to see the output of our stream</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>tail -f /var/folders/2q/krqwcbhj2d58csmthyq_n1nw0000gp/T/spring-cloud-dataflow-7563139704229890655/convertToCelsiusStream-1474990317406/convertToCelsiusStream.log/stdout_0.log</code></pre>
</div>
</div>
<div class="paragraph">
<p>You should see the temperature you posted converted to Celsius!</p>
</div>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>2016-09-27 10:05:34.933  INFO 95616 --- [CelsiusStream-1] log.sink                                 : 24</code></pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_summary_6">Summary</h5>
<div class="paragraph">
<p>In this sample, you have learned:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>How to write a custom <code>Processor</code> stream application</p>
</li>
<li>
<p>How to use Spring Cloud Data Flow&#8217;s <code>Local</code> server</p>
</li>
<li>
<p>How to use Spring Cloud Data Flow&#8217;s <code>shell</code> application</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_task_batch">3. Task / Batch</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="spring-cloud-data-flow-samples-task-overview">3.1. Task Samples</h3>
<div class="sect3">
<h4 id="_batch_job_on_cloud_foundry">3.1.1. Batch Job on Cloud Foundry</h4>
<div class="paragraph">
<p>In this demonstration, you will learn how to orchestrate short-lived data processing application (<em>eg: Spring Batch Jobs</em>) using <a href="http://cloud.spring.io/spring-cloud-task/">Spring Cloud Task</a> and <a href="http://cloud.spring.io/spring-cloud-dataflow/">Spring Cloud Data Flow</a> on Cloud Foundry.</p>
</div>
<div class="sect5">
<h6 id="_prerequisites_7">Prerequisites</h6>
<div class="ulist">
<ul>
<li>
<p>Local <a href="https://pivotal.io/pcf-dev">PCFDev</a> instance</p>
</li>
<li>
<p>Local install of <a href="https://github.com/cloudfoundry/cli">cf CLI</a> command line tool</p>
</li>
<li>
<p>Running instance of mysql in PCFDev</p>
</li>
<li>
<p>A Running Data Flow Shell</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Spring Cloud Data Flow Shell is available for <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-deploying-spring-cloud-dataflow">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow">build</a> it yourself.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
the Spring Cloud Data Flow Shell and Local server implementation are in the same repository and are both built by running <code>./mvnw install</code> from the project root directory. If you have already run the build, use the jar in <code>spring-cloud-dataflow-shell/target</code>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To run the Shell open a new terminal session:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar
  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
dataflow:&gt;</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The Spring Cloud Data Flow Shell is a Spring Boot application that connects to the Data Flow Serverâ€™s REST API and supports a DSL that simplifies the process of defining a stream or task and managing its lifecycle. Most of these samples
use the shell. If you prefer, you can use the Data Flow UI <a href="http://localhost:9393/dashboard" class="bare">localhost:9393/dashboard</a>, (or wherever it the server is hosted) to perform the same operations.
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>The Spring Cloud Data Flow Cloud Foundry Server running in PCFDev</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Cloud Foundry Data Flow Server is Spring Boot application available for <a href="http://cloud.spring.io/spring-cloud-dataflow/">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow-server-cloudfoundry">build</a> it yourself.
If you build it yourself, the executable jar will be in <code>spring-cloud-dataflow-server-cloudfoundry/target</code></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Although you can run the Data Flow Cloud Foundry Server locally and configure it to deploy to any Cloud Foundry instance, we will
deploy the server to Cloud Foundry as recommended.
</td>
</tr>
</table>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Verify that CF instance is reachable (Your endpoint urls will be different from what is shown here).</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf api
API endpoint: https://api.system.io (API version: ...)

$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

No apps found</code></pre>
</div>
</div>
</li>
<li>
<p>Follow the instructions to deploy the <a href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle">Spring Cloud Data Flow Cloud Foundry server</a>. Don&#8217;t worry about creating a Redis service. We won&#8217;t need it. If you are familiar with Cloud Foundry
application manifests, we recommend creating a manifest for the the Data Flow server as shown <a href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#sample-manifest-template">here</a>.</p>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
As of this writing, there is a typo on the <code>SPRING_APPLICATION_JSON</code> entry in the sample manifest. <code>SPRING_APPLICATION_JSON</code> must be followed by <code>:</code> and The JSON string must be
wrapped in single quotes. Alternatively, you can replace that line with <code>MAVEN_REMOTE_REPOSITORIES_REPO1_URL: <a href="https://repo.spring.io/libs-snapshot" class="bare">repo.spring.io/libs-snapshot</a></code>.  If your Cloud Foundry installation is behind a firewall, you may need to install the stream apps used in this sample in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/1.3.0.M2/reference/htmlsingle/#getting-started-maven-configuration">configure</a> the server to access that repository.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Once you have successfully executed <code>cf push</code>, verify the dataflow server is running</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

name                 requested state   instances   memory   disk   urls
dataflow-server      started           1/1         1G       1G     dataflow-server.app.io</code></pre>
</div>
</div>
</li>
<li>
<p>Notice that the <code>dataflow-server</code> application is started and ready for interaction via the url endpoint</p>
</li>
<li>
<p>Connect the <code>shell</code> with <code>server</code> running on Cloud Foundry, e.g., <code><a href="http://dataflow-server.app.io" class="bare">dataflow-server.app.io</a></code></p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar

  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
server-unknown:&gt;</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>server-unknown:&gt;dataflow config server http://dataflow-server.app.io
Successfully targeted http://dataflow-server.app.io
dataflow:&gt;</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
PCF 1.7.12 or greater is required to run Tasks on Spring Cloud Data Flow. As of this writing, PCFDev and PWS supports builds upon this version.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Task support needs to be enabled on pcf-dev. Being logged as <code>admin</code>, issue the following command:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>cf enable-feature-flag task_creation
Setting status of task_creation as admin...

OK

Feature task_creation Enabled.</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
For this sample, all you need is the <code>mysql</code> service and in PCFDev, the <code>mysql</code> service comes with a different plan. From CF CLI, create the service by: <code>cf create-service p-mysql 512mb mysql</code> and bind this service to <code>dataflow-server</code> by: <code>cf bind-service dataflow-server mysql</code>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
All the apps deployed to PCFDev start with low memory by default. It is recommended to change it to at least 768MB for <code>dataflow-server</code>. Ditto for every app spawned <strong>by</strong> Spring Cloud Data Flow. Change the memory by: <code>cf set-env dataflow-server SPRING_CLOUD_DEPLOYER_CLOUDFOUNDRY_MEMORY 512</code>. Likewise, we would have to skip SSL validation by: <code>cf set-env dataflow-server SPRING_CLOUD_DEPLOYER_CLOUDFOUNDRY_SKIP_SSL_VALIDATION true</code>.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Tasks in Spring Cloud Data Flow require an RDBMS to host "task repository" (see <a href="http://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#spring-cloud-dataflow-task-repository">here</a> for more details), so let&#8217;s instruct the Spring Cloud Data Flow server to bind the <code>mysql</code> service to each deployed task:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf set-env dataflow-server SPRING_CLOUD_DEPLOYER_CLOUDFOUNDRY_TASK_SERVICES mysql
$ cf restage dataflow-server</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
We only need <code>mysql</code> service for this sample.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>As a recap, here is what you should see as configuration for the Spring Cloud Data Flow server:</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>cf env dataflow-server

....
User-Provided:
SPRING_CLOUD_DEPLOYER_CLOUDFOUNDRY_DOMAIN: local.pcfdev.io
SPRING_CLOUD_DEPLOYER_CLOUDFOUNDRY_MEMORY: 512
SPRING_CLOUD_DEPLOYER_CLOUDFOUNDRY_ORG: pcfdev-org
SPRING_CLOUD_DEPLOYER_CLOUDFOUNDRY_PASSWORD: pass
SPRING_CLOUD_DEPLOYER_CLOUDFOUNDRY_SKIP_SSL_VALIDATION: false
SPRING_CLOUD_DEPLOYER_CLOUDFOUNDRY_SPACE: pcfdev-space
SPRING_CLOUD_DEPLOYER_CLOUDFOUNDRY_TASK_SERVICES: mysql
SPRING_CLOUD_DEPLOYER_CLOUDFOUNDRY_URL: https://api.local.pcfdev.io
SPRING_CLOUD_DEPLOYER_CLOUDFOUNDRY_USERNAME: user

No running env variables have been set

No staging env variables have been set</code></pre>
</div>
</div>
</li>
<li>
<p>Notice that <code>dataflow-server</code> application is started and ready for interaction via <code><a href="http://dataflow-server.local.pcfdev.io" class="bare">dataflow-server.local.pcfdev.io</a></code> endpoint</p>
</li>
<li>
<p>Build and register the batch-job <a href="https://github.com/spring-cloud/spring-cloud-task/tree/master/spring-cloud-task-samples/batch-job">example</a> from Spring Cloud Task samples. For convenience, the final <a href="https://github.com/spring-cloud/spring-cloud-dataflow-samples/raw/master/src/main/asciidoc/tasks/simple-batch-job/batch-job-1.0.0.BUILD-SNAPSHOT.jar">uber-jar artifact</a> is provided with this sample.</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;app register --type task --name simple_batch_job --uri https://github.com/spring-cloud/spring-cloud-dataflow-samples/raw/master/tasks/simple-batch-job/batch-job-1.3.0.BUILD-SNAPSHOT.jar</code></pre>
</div>
</div>
</li>
<li>
<p>Create the task with <code>simple-batch-job</code> application</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;task create foo --definition "simple_batch_job"</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Unlike Streams, the Task definitions don&#8217;t require explicit deployment. They can be launched on-demand, scheduled, or triggered by streams.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Verify there&#8217;s <strong>still</strong> no Task applications running on PCFDev - they are listed only after the initial launch/staging attempt on PCF</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf apps
Getting apps in org pcfdev-org / space pcfdev-space as user...
OK

name              requested state   instances   memory   disk   urls
dataflow-server   started           1/1         768M     512M   dataflow-server.local.pcfdev.io</code></pre>
</div>
</div>
</li>
<li>
<p>Let&#8217;s launch <code>foo</code></p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;task launch foo</code></pre>
</div>
</div>
</li>
<li>
<p>Verify the execution of <code>foo</code> by tailing the logs</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf logs foo
Retrieving logs for app foo in org pcfdev-org / space pcfdev-space as user...

2016-08-14T18:48:54.22-0700 [APP/TASK/foo/0]OUT Creating container
2016-08-14T18:48:55.47-0700 [APP/TASK/foo/0]OUT

2016-08-14T18:49:06.59-0700 [APP/TASK/foo/0]OUT 2016-08-15 01:49:06.598  INFO 14 --- [           main] o.s.b.c.l.support.SimpleJobLauncher      : Job: [SimpleJob: [name=job1]] launched with the following parameters: [{}]

...
...

2016-08-14T18:49:06.78-0700 [APP/TASK/foo/0]OUT 2016-08-15 01:49:06.785  INFO 14 --- [           main] o.s.b.c.l.support.SimpleJobLauncher      : Job: [SimpleJob: [name=job1]] completed with the following parameters: [{}] and the following status: [COMPLETED]

...
...

2016-08-14T18:49:07.36-0700 [APP/TASK/foo/0]OUT 2016-08-15 01:49:07.363  INFO 14 --- [           main] o.s.b.c.l.support.SimpleJobLauncher      : Job: [SimpleJob: [name=job2]] launched with the following parameters: [{}]

...
...

2016-08-14T18:49:07.53-0700 [APP/TASK/foo/0]OUT 2016-08-15 01:49:07.536  INFO 14 --- [           main] o.s.b.c.l.support.SimpleJobLauncher      : Job: [SimpleJob: [name=job2]] completed with the following parameters: [{}] and the following status: [COMPLETED]

...
...

2016-08-14T18:49:07.71-0700 [APP/TASK/foo/0]OUT Exit status 0
2016-08-14T18:49:07.78-0700 [APP/TASK/foo/0]OUT Destroying container
2016-08-14T18:49:08.47-0700 [APP/TASK/foo/0]OUT Successfully destroyed container</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Verify <code>job1</code> and <code>job2</code> operations embeddded in <code>simple-batch-job</code> application are launched independently and they returned with the status <code>COMPLETED</code>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Unlike LRPs in Cloud Foundry, tasks are short-lived, so the logs aren&#8217;t always available. They are generated only when the Task application runs; at the end of Task operation, the container that ran the Task application is destroyed to free-up resources.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>List Tasks in Cloud Foundry</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cf apps
Getting apps in org pcfdev-org / space pcfdev-space as user...
OK

name              requested state   instances   memory   disk   urls
dataflow-server   started           1/1         768M     512M   dataflow-server.local.pcfdev.io
foo               stopped           0/1         1G       1G</code></pre>
</div>
</div>
</li>
<li>
<p>Verify Task execution details</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;task execution list
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•—
â•‘        Task Name         â”‚IDâ”‚         Start Time         â”‚          End Time          â”‚Exit Codeâ•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•£
â•‘foo                       â”‚1 â”‚Sun Aug 14 18:49:05 PDT 2016â”‚Sun Aug 14 18:49:07 PDT 2016â”‚0        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•</code></pre>
</div>
</div>
</li>
<li>
<p>Verify Job execution details</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;job execution list
â•”â•â•â•â•¤â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ID â”‚Task IDâ”‚Job Name â”‚         Start Time         â”‚Step Execution Count â”‚Definition Status â•‘
â• â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘2  â”‚1      â”‚job2     â”‚Sun Aug 14 18:49:07 PDT 2016â”‚1                    â”‚Destroyed         â•‘
â•‘1  â”‚1      â”‚job1     â”‚Sun Aug 14 18:49:06 PDT 2016â”‚1                    â”‚Destroyed         â•‘
â•šâ•â•â•â•§â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</code></pre>
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect5">
<h6 id="_summary_7">Summary</h6>
<div class="paragraph">
<p>In this sample, you have learned:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>How to register and orchestrate Spring Batch jobs in Spring Cloud Data Flow</p>
</li>
<li>
<p>How to use the <code>cf</code> CLI in the context of Task applications orchestrated by Spring Cloud Data Flow</p>
</li>
<li>
<p>How to verify task executions and task repository</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_analytics">4. Analytics</h2>
<div class="sectionbody">
<div class="sect3">
<h4 id="spring-cloud-data-flow-samples-twitter-analytics-overview">4.1. Twitter Analytics</h4>
<div class="paragraph">
<p>In this demonstration, you will learn how to build a data pipeline using <a href="http://cloud.spring.io/spring-cloud-dataflow/">Spring Cloud Data Flow</a> to consume data from <em>TwitterStream</em> and compute simple analytics over data-in-transit using <em>Field-Value-Counter</em>.</p>
</div>
<div class="paragraph">
<p>We will take you through the steps to configure Spring Cloud Data Flow&#8217;s <code>Local</code> server.</p>
</div>
<div class="sect5">
<h6 id="_prerequisites_8">Prerequisites</h6>
<div class="ulist">
<ul>
<li>
<p>A Running Data Flow Shell</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Spring Cloud Data Flow Shell is available for <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-deploying-spring-cloud-dataflow">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow">build</a> it yourself.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
the Spring Cloud Data Flow Shell and Local server implementation are in the same repository and are both built by running <code>./mvnw install</code> from the project root directory. If you have already run the build, use the jar in <code>spring-cloud-dataflow-shell/target</code>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To run the Shell open a new terminal session:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar
  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
dataflow:&gt;</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The Spring Cloud Data Flow Shell is a Spring Boot application that connects to the Data Flow Serverâ€™s REST API and supports a DSL that simplifies the process of defining a stream or task and managing its lifecycle. Most of these samples
use the shell. If you prefer, you can use the Data Flow UI <a href="http://localhost:9393/dashboard" class="bare">localhost:9393/dashboard</a>, (or wherever it the server is hosted) to perform the same operations.
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>A running local Data Flow Server</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Local Data Flow Server is Spring Boot application available for <a href="http://cloud.spring.io/spring-cloud-dataflow/">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow">build</a> it yourself.
If you build it yourself, the executable jar will be in <code>spring-cloud-dataflow-server-local/target</code></p>
</div>
<div class="paragraph">
<p>To run the Local Data Flow server Open a new terminal session:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$cd  &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-LOCAL-JAR&gt;
$java -jar spring-cloud-dataflow-server-local-&lt;VERSION&gt;.jar</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>Running instance of <a href="http://redis.io/">Redis</a></p>
</li>
<li>
<p>Running instance of <a href="http://kafka.apache.org/downloads.html">Kafka</a></p>
</li>
<li>
<p>Twitter credentials from <a href="https://apps.twitter.com/">Twitter Developers</a> site</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><a href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app">Register</a> the out-of-the-box applications for the Kafka binder</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
These samples assume that the Data Flow Server can access a remote Maven repository, <code><a href="https://repo.spring.io/libs-release" class="bare">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code>dataflow:&gt;app import --uri <a href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" class="bare">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code><a href="https://repo.spring.io" class="bare">repo.spring.io</a></code>. For example,
<code>source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code>http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code>maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties">download</a> the required apps or <a href="https://github.com/spring-cloud-stream-app-starters">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code>dataflow:&gt;app register&#8230;&#8203;</code> using the <code>maven://</code> resource URI format corresponding to your installed app.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-kafka-10-maven</code></pre>
</div>
</div>
</li>
<li>
<p>Create and deploy the following streams</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>(1) dataflow:&gt;stream create tweets --definition "twitterstream --consumerKey=&lt;CONSUMER_KEY&gt; --consumerSecret=&lt;CONSUMER_SECRET&gt; --accessToken=&lt;ACCESS_TOKEN&gt; --accessTokenSecret=&lt;ACCESS_TOKEN_SECRET&gt; | log"
Created new stream 'tweets'

(2) dataflow:&gt;stream create tweetlang  --definition ":tweets.twitterstream &gt; field-value-counter --fieldName=lang --name=language" --deploy
Created and deployed new stream 'tweetlang'

(3) dataflow:&gt;stream create tagcount --definition ":tweets.twitterstream &gt; field-value-counter --fieldName=entities.hashtags.text --name=hashtags" --deploy
Created and deployed new stream 'tagcount'

(4) dataflow:&gt;stream deploy tweets
Deployed stream 'tweets'</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
To get a consumerKey and consumerSecret you need to register a twitter application. If you donâ€™t already have one set up, you can create an app at the <a href="https://apps.twitter.com/">Twitter Developers</a> site to get these credentials. The tokens <code>&lt;CONSUMER_KEY&gt;</code>, <code>&lt;CONSUMER_SECRET&gt;</code>, <code>&lt;ACCESS_TOKEN&gt;</code>, and <code>&lt;ACCESS_TOKEN_SECRET&gt;</code> are required to be replaced with your account credentials.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Verify the streams are successfully deployed. Where: (1) is the primary pipeline; (2) and (3) are tapping the primary pipeline with the DSL syntax <code>&lt;stream-name&gt;.&lt;label/app name&gt;</code> [e.x. <code>:tweets.twitterstream</code>]; and (4) is the final deployment of primary pipeline</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream list</code></pre>
</div>
</div>
</li>
<li>
<p>Notice that <code>tweetlang.field-value-counter</code>, <code>tagcount.field-value-counter</code>, <code>tweets.log</code> and <code>tweets.twitterstream</code> <a href="https://github.com/spring-cloud-stream-app-starters/">Spring Cloud Stream</a> applications are running as Spring Boot applications within the <code>local-server</code>.</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>2016-02-16 11:43:26.174  INFO 10189 --- [nio-9393-exec-2] o.s.c.d.d.l.OutOfProcessModuleDeployer   : deploying module org.springframework.cloud.stream.module:field-value-counter-sink:jar:exec:1.0.0.BUILD-SNAPSHOT instance 0
   Logs will be in /var/folders/c3/ctx7_rns6x30tq7rb76wzqwr0000gp/T/spring-cloud-data-flow-6990537012958280418/tweetlang-1455651806160/tweetlang.field-value-counter
2016-02-16 11:43:26.206  INFO 10189 --- [nio-9393-exec-3] o.s.c.d.d.l.OutOfProcessModuleDeployer   : deploying module org.springframework.cloud.stream.module:field-value-counter-sink:jar:exec:1.0.0.BUILD-SNAPSHOT instance 0
   Logs will be in /var/folders/c3/ctx7_rns6x30tq7rb76wzqwr0000gp/T/spring-cloud-data-flow-6990537012958280418/tagcount-1455651806202/tagcount.field-value-counter
2016-02-16 11:43:26.806  INFO 10189 --- [nio-9393-exec-4] o.s.c.d.d.l.OutOfProcessModuleDeployer   : deploying module org.springframework.cloud.stream.module:log-sink:jar:exec:1.0.0.BUILD-SNAPSHOT instance 0
   Logs will be in /var/folders/c3/ctx7_rns6x30tq7rb76wzqwr0000gp/T/spring-cloud-data-flow-6990537012958280418/tweets-1455651806800/tweets.log
2016-02-16 11:43:26.813  INFO 10189 --- [nio-9393-exec-4] o.s.c.d.d.l.OutOfProcessModuleDeployer   : deploying module org.springframework.cloud.stream.module:twitterstream-source:jar:exec:1.0.0.BUILD-SNAPSHOT instance 0
   Logs will be in /var/folders/c3/ctx7_rns6x30tq7rb76wzqwr0000gp/T/spring-cloud-data-flow-6990537012958280418/tweets-1455651806800/tweets.twitterstream</code></pre>
</div>
</div>
</li>
<li>
<p>Verify that two <code>field-value-counter</code> with the names <code>hashtags</code> and <code>language</code> is listing successfully</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;field-value-counter list
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘Field Value Counter nameâ•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘hashtags                â•‘
â•‘language                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•</code></pre>
</div>
</div>
</li>
<li>
<p>Verify you can query individual <code>field-value-counter</code> results successfully</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;field-value-counter display hashtags
Displaying values for field value counter 'hashtags'
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•—
â•‘                Value                 â”‚Countâ•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•£
â•‘KCA                                   â”‚   40â•‘
â•‘PENNYSTOCKS                           â”‚   17â•‘
â•‘TEAMBILLIONAIRE                       â”‚   17â•‘
â•‘UCL                                   â”‚   11â•‘
â•‘...                                   â”‚   ..â•‘
â•‘...                                   â”‚   ..â•‘
â•‘...                                   â”‚   ..â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•

dataflow:&gt;field-value-counter display language
Displaying values for field value counter 'language'
â•”â•â•â•â•â•â•¤â•â•â•â•â•â•—
â•‘Valueâ”‚Countâ•‘
â• â•â•â•â•â•â•ªâ•â•â•â•â•â•£
â•‘en   â”‚1,171â•‘
â•‘es   â”‚  337â•‘
â•‘ar   â”‚  296â•‘
â•‘und  â”‚  251â•‘
â•‘pt   â”‚  175â•‘
â•‘ja   â”‚  137â•‘
â•‘..   â”‚  ...â•‘
â•‘..   â”‚  ...â•‘
â•‘..   â”‚  ...â•‘
â•šâ•â•â•â•â•â•§â•â•â•â•â•â•</code></pre>
</div>
</div>
</li>
<li>
<p>Go to <code>Dashboard</code> accessible at <code><a href="http://localhost:9393/dashboard" class="bare">localhost:9393/dashboard</a></code> and launch the <code>Analytics</code> tab. From the default <code>Dashboard</code> menu, select the following combinations to visualize real-time updates on <code>field-value-counter</code>.</p>
<div class="ulist">
<ul>
<li>
<p>For real-time updates on <code>language</code> tags, select:</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>Metric Type as <code>Field-Value-Counters</code></p>
</li>
<li>
<p>Stream as <code>language</code></p>
</li>
<li>
<p>Visualization as <code>Bubble-Chart</code> or <code>Pie-Chart</code></p>
</li>
</ol>
</div>
</li>
<li>
<p>For real-time updates on <code>hashtags</code> tags, select:</p>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>Metric Type as <code>Field-Value-Counters</code></p>
</li>
<li>
<p>Stream as <code>hashtags</code></p>
</li>
<li>
<p>Visualization as <code>Bubble-Chart</code> or <code>Pie-Chart</code></p>
</li>
</ol>
</div>
</li>
</ul>
</div>
</li>
</ol>
</div>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="images/twitter_analytics.png" alt="Twitter Analytics Visualization">
</div>
</div>
</div>
<div class="sect5">
<h6 id="_summary_8">Summary</h6>
<div class="paragraph">
<p>In this sample, you have learned:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>How to use Spring Cloud Data Flow&#8217;s <code>Local</code> server</p>
</li>
<li>
<p>How to use Spring Cloud Data Flow&#8217;s <code>shell</code> application</p>
</li>
<li>
<p>How to create streaming data pipeline to compute simple analytics using <code>Twitter Stream</code> and <code>Field Value Counter</code> applications</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_functions">5. Functions</h2>
<div class="sectionbody">
<div class="sect4">
<h5 id="_functions_in_spring_cloud_data_flow">Functions in Spring Cloud Data Flow</h5>
<div class="paragraph">
<p>In this sample, you will learn how to use <a href="https://github.com/spring-cloud/spring-cloud-function">Spring Cloud Function</a> based streaming applications in Spring Cloud Data Flow. To learn more about Spring Cloud Function, check out the <a href="http://cloud.spring.io/spring-cloud-function/">project page</a>.</p>
</div>
<div class="sect5">
<h6 id="_prerequisites_9">Prerequisites</h6>
<div class="ulist">
<ul>
<li>
<p>A Running Data Flow Shell</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Spring Cloud Data Flow Shell is available for <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-deploying-spring-cloud-dataflow">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow">build</a> it yourself.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
the Spring Cloud Data Flow Shell and Local server implementation are in the same repository and are both built by running <code>./mvnw install</code> from the project root directory. If you have already run the build, use the jar in <code>spring-cloud-dataflow-shell/target</code>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To run the Shell open a new terminal session:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar
  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
dataflow:&gt;</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The Spring Cloud Data Flow Shell is a Spring Boot application that connects to the Data Flow Serverâ€™s REST API and supports a DSL that simplifies the process of defining a stream or task and managing its lifecycle. Most of these samples
use the shell. If you prefer, you can use the Data Flow UI <a href="http://localhost:9393/dashboard" class="bare">localhost:9393/dashboard</a>, (or wherever it the server is hosted) to perform the same operations.
</td>
</tr>
</table>
</div>
<div class="ulist">
<ul>
<li>
<p>A running local Data Flow Server</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The Local Data Flow Server is Spring Boot application available for <a href="http://cloud.spring.io/spring-cloud-dataflow/">download</a> or you can <a href="https://github.com/spring-cloud/spring-cloud-dataflow">build</a> it yourself.
If you build it yourself, the executable jar will be in <code>spring-cloud-dataflow-server-local/target</code></p>
</div>
<div class="paragraph">
<p>To run the Local Data Flow server Open a new terminal session:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>$cd  &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-LOCAL-JAR&gt;
$java -jar spring-cloud-dataflow-server-local-&lt;VERSION&gt;.jar</code></pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>A local build of <a href="https://github.com/spring-cloud/spring-cloud-function">Spring Cloud Function</a></p>
</li>
<li>
<p>A running instance of <a href="https://www.rabbitmq.com/">Rabbit MQ</a></p>
</li>
<li>
<p>General understanding of the out-of-the-box <a href="https://github.com/spring-cloud-stream-app-starters/function/blob/master/spring-cloud-starter-stream-app-function/README.adoc">function-runner</a> application</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><a href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app">Register</a> the out-of-the-box applications for the Rabbit binder</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
These samples assume that the Data Flow Server can access a remote Maven repository, <code><a href="https://repo.spring.io/libs-release" class="bare">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code>dataflow:&gt;app import --uri <a href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" class="bare">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code><a href="https://repo.spring.io" class="bare">repo.spring.io</a></code>. For example,
<code>source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code>http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code>maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties">download</a> the required apps or <a href="https://github.com/spring-cloud-stream-app-starters">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code>dataflow:&gt;app register&#8230;&#8203;</code> using the <code>maven://</code> resource URI format corresponding to your installed app.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</code></pre>
</div>
</div>
</li>
<li>
<p>Register the out-of-the-box <a href="https://github.com/spring-cloud-stream-app-starters/function/blob/master/spring-cloud-starter-stream-app-function/README.adoc">function-runner</a> application (<em>we will use the <code>1.0.0.BUILD-SNAPSHOT</code> built by the Spring CI system</em>)</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;app register --name function-runner --type processor --uri http://repo.spring.io/libs-snapshot/org/springframework/cloud/stream/app/function-app-rabbit/1.0.0.BUILD-SNAPSHOT/function-app-rabbit-1.0.0.BUILD-SNAPSHOT.jar --metadata-uri http://repo.spring.io/libs-snapshot/org/springframework/cloud/stream/app/function-app-rabbit/1.0.0.BUILD-SNAPSHOT/function-app-rabbit-1.0.0.BUILD-SNAPSHOT-metadata.jar</code></pre>
</div>
</div>
</li>
<li>
<p>Create and deploy the following stream</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;stream create foo --definition "http --server.port=9001 | function-runner --function.className=com.example.functions.CharCounter --function.location=file:///&lt;PATH/TO/SPRING-CLOUD-FUNCTION&gt;/spring-cloud-function-samples/function-sample/target/spring-cloud-function-sample-1.0.0.BUILD-SNAPSHOT.jar | log" --deploy</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Replace the <code>&lt;PATH/TO/SPRING-CLOUD-FUNCTION&gt;</code> with the correct path.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The source core of <code>CharCounter</code> function is in Spring cloud Function&#8217;s <a href="https://github.com/spring-cloud/spring-cloud-function/blob/master/spring-cloud-function-samples/function-sample/src/main/java/com/example/functions/CharCounter.java">samples repo</a>.
</td>
</tr>
</table>
</div>
</li>
<li>
<p>Verify the stream is successfully deployed.</p>
<div class="listingblock">
<div class="content">
<pre class="highlight nowrap"><code class="language-bash" data-lang="bash">dataflow:&gt;stream list
â•”â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘Streamâ”‚                                                                                        Stream Definition                                                                                         â”‚   Status   â•‘
â•‘ Name â”‚                                                                                                                                                                                                  â”‚            â•‘
â• â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘foo   â”‚http --server.port=9001 | function-runner --function.className=com.example.functions.CharCounter                                                                                                  â”‚All apps    â•‘
â•‘      â”‚--function.location=file:///&lt;PATH/TO/SPRING-CLOUD-FUNCTION&gt;/spring-cloud-function-samples/function-sample/target/spring-cloud-function-sample-1.0.0.BUILD-&lt;SNAPSHOT class="jar"&gt;&lt;/SNAPSHOT&gt;		    â”‚have been   â•‘
â•‘      â”‚| log                                                                                                                                                                                             â”‚successfullyâ•‘
â•‘      â”‚                                                                                                                                                                                                  â”‚deployed    â•‘
â•šâ•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•</code></pre>
</div>
</div>
</li>
<li>
<p>Notice that <code>foo-http</code>, <code>foo-function-runner</code>, and <code>foo-log</code> <a href="https://github.com/spring-cloud-stream-app-starters/">Spring Cloud Stream</a> applications are running as Spring Boot applications and the log locations will be printed in the Local-server console.</p>
<div class="listingblock">
<div class="content">
<pre class="highlight nowrap"><code class="language-bash" data-lang="bash">....
....
2017-10-17 11:43:03.714  INFO 18409 --- [nio-9393-exec-7] o.s.c.d.s.s.AppDeployerStreamDeployer    : Deploying application named [log] as part of stream named [foo] with resource URI [maven://org.springframework.cloud.stream.app:log-sink-rabbit:jar:1.2.0.RELEASE]
2017-10-17 11:43:04.379  INFO 18409 --- [nio-9393-exec-7] o.s.c.d.spi.local.LocalAppDeployer       : Deploying app with deploymentId foo.log instance 0.
   Logs will be in /var/folders/c3/ctx7_rns6x30tq7rb76wzqwr0000gs/T/spring-cloud-dataflow-6549025456609489200/foo-1508265783715/foo.log
2017-10-17 11:43:04.380  INFO 18409 --- [nio-9393-exec-7] o.s.c.d.s.s.AppDeployerStreamDeployer    : Deploying application named [function-runner] as part of stream named [foo] with resource URI [file:/var/folders/c3/ctx7_rns6x30tq7rb76wzqwr0000gs/T/deployer-resource-cache8941581850579153886/http-c73a62adae0abd7ec0dee91d891575709f02f8c9]
2017-10-17 11:43:04.384  INFO 18409 --- [nio-9393-exec-7] o.s.c.d.spi.local.LocalAppDeployer       : Deploying app with deploymentId foo.function-runner instance 0.
   Logs will be in /var/folders/c3/ctx7_rns6x30tq7rb76wzqwr0000gs/T/spring-cloud-dataflow-6549025456609489200/foo-1508265784380/foo.function-runner
2017-10-17 11:43:04.385  INFO 18409 --- [nio-9393-exec-7] o.s.c.d.s.s.AppDeployerStreamDeployer    : Deploying application named [http] as part of stream named [foo] with resource URI [maven://org.springframework.cloud.stream.app:http-source-rabbit:jar:1.2.0.RELEASE]
2017-10-17 11:43:04.391  INFO 18409 --- [nio-9393-exec-7] o.s.c.d.spi.local.LocalAppDeployer       : Deploying app with deploymentId foo.http instance 0.
   Logs will be in /var/folders/c3/ctx7_rns6x30tq7rb76wzqwr0000gs/T/spring-cloud-dataflow-6549025456609489200/foo-1508265784385/foo.http
....
....</code></pre>
</div>
</div>
</li>
<li>
<p>Post sample data pointing to the <code>http</code> endpoint: <code><a href="http://localhost:9001" class="bare">localhost:9001</a></code> (<code>9001</code> is the <code>port</code> we specified for the <code>http</code> source in this case)</p>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code>dataflow:&gt;http post --target http://localhost:9001 --data "hello world"
&gt; POST (text/plain) http://localhost:9001 hello world
&gt; 202 ACCEPTED


dataflow:&gt;http post --target http://localhost:9001 --data "hmm, yeah, it works now!"
&gt; POST (text/plain) http://localhost:9001 hmm, yeah, it works now!
&gt; 202 ACCEPTED</code></pre>
</div>
</div>
</li>
<li>
<p>Tail the log-sink&#8217;s standard-out logs to see the character counts</p>
<div class="listingblock">
<div class="content">
<pre class="highlight nowrap"><code class="language-bash" data-lang="bash">$ tail -f /var/folders/c3/ctx7_rns6x30tq7rb76wzqwr0000gs/T/spring-cloud-dataflow-6549025456609489200/foo-1508265783715/foo.log/stdout_0.log

....
....
....
....
2017-10-17 11:45:39.363  INFO 19193 --- [on-runner.foo-1] log-sink                                 : 11
2017-10-17 11:46:40.997  INFO 19193 --- [on-runner.foo-1] log-sink                                 : 24
....
....</code></pre>
</div>
</div>
</li>
</ol>
</div>
</li>
</ul>
</div>
</div>
<div class="sect5">
<h6 id="_summary_9">Summary</h6>
<div class="paragraph">
<p>In this sample, you have learned:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>How to use Spring Cloud Data Flow&#8217;s <code>Local</code> server</p>
</li>
<li>
<p>How to use Spring Cloud Data Flow&#8217;s <code>shell</code> application</p>
</li>
<li>
<p>How to use the out-of-the-box <code>function-runner</code> application in Spring Cloud Data Flow</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2017-10-31 05:48:02 EDT
</div>
</div>
</body>
</html>