<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title>1.&nbsp;Streaming</title><link rel="stylesheet" type="text/css" href="css/manual-multipage.css"><meta name="generator" content="DocBook XSL Stylesheets V1.78.1"><link rel="home" href="index.html" title="Spring Cloud Data Flow Samples"><link rel="up" href="index.html" title="Spring Cloud Data Flow Samples"><link rel="prev" href="pr01.html" title=""><link rel="next" href="_task_batch.html" title="2.&nbsp;Task / Batch"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">1.&nbsp;Streaming</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="pr01.html">Prev</a>&nbsp;</td><th width="60%" align="center">&nbsp;</th><td width="20%" align="right">&nbsp;<a accesskey="n" href="_task_batch.html">Next</a></td></tr></table><hr></div><div class="chapter"><div class="titlepage"><div><div><h1 class="title"><a name="_streaming" href="#_streaming"></a>1.&nbsp;Streaming</h1></div></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="spring-cloud-data-flow-samples-cassandra-overview" href="#spring-cloud-data-flow-samples-cassandra-overview"></a>1.1&nbsp;Cassandra Samples</h2></div></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="spring-cloud-data-flow-samples-http-cassandra-overview" href="#spring-cloud-data-flow-samples-http-cassandra-overview"></a>1.1.1&nbsp;HTTP to Cassandra Demo</h3></div></div></div><p>In this demonstration, you will learn how to build a data pipeline using <a class="link" href="http://cloud.spring.io/spring-cloud-dataflow/" target="_top">Spring Cloud Data Flow</a> to consume data from an <span class="emphasis"><em>HTTP</em></span> endpoint and write the payload to a <span class="emphasis"><em>Cassandra</em></span> database.</p><p>We will take you through the steps to configure and Spring Cloud Data Flow server in either a <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started/" target="_top">local</a> or <a class="link" href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#getting-started" target="_top">Cloud Foundry</a> environment.</p><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="_prerequisites" href="#_prerequisites"></a>Prerequisites</h4></div></div></div><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A Running Data Flow Shell</li></ul></div><p>The Spring Cloud Data Flow Shell is available for <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-deploying-spring-cloud-dataflow" target="_top">download</a> or you can <a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow" target="_top">build</a> it yourself.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>The Spring Cloud Data Flow Shell is a Spring Boot application that connects to the Data Flow Server&#8217;s REST API and supports a DSL that simplifies the process of defining a stream or task and managing its lifecycle. Most of these samples
use the shell. If you prefer, you can use the Data Flow UI <a class="link" href="http://localhost:9393/dashboard" target="_top">localhost:9393/dashboard</a>, (or wherever it the server is hosted) to perform the same operations.</p></td></tr></table></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>the Spring Cloud Data Flow Shell and Local server implementation are in the same repository and are both built by running <code class="literal">./mvnw install</code> from the project root directory. If you have already run the build, use the jar in <code class="literal">spring-cloud-dataflow-shell/target</code></p></td></tr></table></div><p>To run the Shell open a new terminal session:</p><pre class="screen">$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar
  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
dataflow:&gt;</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>The shell will try to connect to a local server by default. If the Local Dataflow Server is not running you will see:</p></td></tr></table></div><pre class="screen"> ____                              ____ _                __
/ ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
\___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
 ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
|____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
 ____ |_|    _          __|___/                 __________
|  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
| | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
| |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
|____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
server unknown:&gt;</pre><p>Connect the <code class="literal">shell</code> to the <code class="literal">server</code> running on , e.g., <code class="literal"><a class="link" href="http://dataflow-server.app.io" target="_top">dataflow-server.app.io</a></code></p><pre class="screen">server unknown:&gt;dataflow config server http://dataflow-server.app.io
Successfully targeted http://dataflow-server.app.io
dataflow:&gt;</pre></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="http-cassandra-local" href="#http-cassandra-local"></a>Using the Local Server</h4></div></div></div><div class="section"><div class="titlepage"><div><div><h5 class="title"><a name="_additional_prerequisites" href="#_additional_prerequisites"></a>Additional Prerequisites</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A running local Data Flow Server</li></ul></div><p>The Local Data Flow Server is Spring Boot application available for <a class="link" href="http://cloud.spring.io/spring-cloud-dataflow/" target="_top">download</a> or you can <a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow" target="_top">build</a> it yourself.
If you build it yourself, the executable jar will be in <code class="literal">spring-cloud-dataflow-server-local/target</code></p><p>To run the Local Data Flow server Open a new terminal session:</p><pre class="screen">$cd  &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-LOCAL-JAR&gt;
$java -jar spring-cloud-dataflow-server-local-&lt;VERSION&gt;.jar</pre><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">Running instance of <a class="link" href="http://kafka.apache.org/downloads.html" target="_top">Kafka</a></li><li class="listitem">Running instance of <a class="link" href="http://cassandra.apache.org/" target="_top">Apache Cassandra</a></li><li class="listitem">A database utility tool such as <a class="link" href="http://dbeaver.jkiss.org/" target="_top">DBeaver</a> to connect to the Cassandra instance. You might have to provide <code class="literal">host</code>, <code class="literal">port</code>, <code class="literal">username</code> and <code class="literal">password</code> depending on the Cassandra configuration you are using.</li><li class="listitem"><p class="simpara">Create a keyspace and a <code class="literal">book</code> table in Cassandra using:</p><pre class="screen">CREATE KEYSPACE clouddata WITH REPLICATION = { 'class' : 'org.apache.cassandra.locator.SimpleStrategy', 'replication_factor': '1' } AND DURABLE_WRITES = true;
USE clouddata;
CREATE TABLE book  (
    id          uuid PRIMARY KEY,
    isbn        text,
    author      text,
    title       text
);</pre><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara"><a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app" target="_top">Register</a> the out-of-the-box applications for the Kafka binder</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>These samples assume that the Data Flow Server can access a remote Maven repository, <code class="literal"><a class="link" href="https://repo.spring.io/libs-release" target="_top">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration" target="_top">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code class="literal">dataflow:&gt;app import --uri <a class="link" href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" target="_top">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code class="literal"><a class="link" href="https://repo.spring.io" target="_top">repo.spring.io</a></code>. For example,
<code class="literal">source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code class="literal">http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code class="literal">maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a class="link" href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties" target="_top">download</a> the required apps or <a class="link" href="https://github.com/spring-cloud-stream-app-starters" target="_top">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code class="literal">dataflow:&gt;app register&#8230;&#8203;</code> using the <code class="literal">maven://</code> resource URI format corresponding to your installed app.</p></td></tr></table></div><pre class="screen">dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-kafka-10-maven</pre></li><li class="listitem"><p class="simpara">Create the stream</p><pre class="screen">dataflow:&gt;stream create cassandrastream --definition "http --server.port=8888 --spring.cloud.stream.bindings.output.contentType='application/json' | cassandra --ingestQuery='insert into book (id, isbn, title, author) values (uuid(), ?, ?, ?)' --keyspace=clouddata" --deploy

Created and deployed new stream 'cassandrastream'</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>If Cassandra isn&#8217;t running on default port on <code class="literal">localhost</code> or if you need username and password to connect, use one of the following options to specify the necessary connection parameters: <code class="literal">--username='&lt;USERNAME&gt;' --password='&lt;PASSWORD&gt;' --port=&lt;PORT&gt; --contact-points=&lt;LIST-OF-HOSTS&gt;</code></p></td></tr></table></div></li><li class="listitem"><p class="simpara">Verify the stream is successfully deployed</p><pre class="screen">dataflow:&gt;stream list</pre></li><li class="listitem"><p class="simpara">Notice that <code class="literal">cassandrastream-http</code> and <code class="literal">cassandrastream-cassandra</code> <a class="link" href="https://github.com/spring-cloud-stream-app-starters//" target="_top">Spring Cloud Stream</a> applications are running as Spring Boot applications within the <code class="literal">server</code> as a collocated process.</p><pre class="screen">2015-12-15 15:52:31.576  INFO 18337 --- [nio-9393-exec-1] o.s.c.d.a.s.l.OutOfProcessModuleDeployer : deploying module org.springframework.cloud.stream.module:cassandra-sink:jar:exec:1.0.0.BUILD-SNAPSHOT instance 0
   Logs will be in /var/folders/c3/ctx7_rns6x30tq7rb76wzqwr0000gp/T/spring-cloud-data-flow-284240942697761420/cassandrastream.cassandra
2015-12-15 15:52:31.583  INFO 18337 --- [nio-9393-exec-1] o.s.c.d.a.s.l.OutOfProcessModuleDeployer : deploying module org.springframework.cloud.stream.module:http-source:jar:exec:1.0.0.BUILD-SNAPSHOT instance 0
   Logs will be in /var/folders/c3/ctx7_rns6x30tq7rb76wzqwr0000gp/T/spring-cloud-data-flow-284240942697761420/cassandrastream.http</pre></li><li class="listitem"><p class="simpara">Post sample data pointing to the <code class="literal">http</code> endpoint: <code class="literal"><a class="link" href="http://localhost:8888" target="_top">localhost:8888</a></code> (<code class="literal">8888</code> is the <code class="literal">server.port</code> we specified for the <code class="literal">http</code> source in this case)</p><pre class="screen">dataflow:&gt;http post --contentType 'application/json' --data '{"isbn": "1599869772", "title": "The Art of War", "author": "Sun Tzu"}' --target http://localhost:8888
&gt; POST (application/json;charset=UTF-8) http://localhost:8888 {"isbn": "1599869772", "title": "The Art of War", "author": "Sun Tzu"}
&gt; 202 ACCEPTED</pre></li><li class="listitem"><p class="simpara">Connect to the Cassandra instance and query the table <code class="literal">clouddata.book</code> to list the persisted records</p><pre class="screen">select * from clouddata.book;</pre></li><li class="listitem">You&#8217;re done!</li></ol></div></li></ul></div></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="http-cassandra-cf" href="#http-cassandra-cf"></a>Using Cloud Foundry Server</h4></div></div></div><div class="section"><div class="titlepage"><div><div><h5 class="title"><a name="_additional_prerequisites_2" href="#_additional_prerequisites_2"></a>Additional Prerequisites</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">Cloud Foundry instance</li><li class="listitem">The Spring Cloud Data Flow Cloud Foundry Server</li></ul></div><p>The Cloud Foundry Data Flow Server is Spring Boot application available for <a class="link" href="http://cloud.spring.io/spring-cloud-dataflow/" target="_top">download</a> or you can <a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow-server-cloudfoundry" target="_top">build</a> it yourself.
If you build it yourself, the executable jar will be in <code class="literal">spring-cloud-dataflow-server-cloudfoundry/target</code></p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>Although you can run the Data Flow Cloud Foundry Server locally and configure it to deploy to any Cloud Foundry instance, we will
deploy the server to Cloud Foundry as recommended.</p></td></tr></table></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">Verify that CF instance is reachable (Your endpoint urls will be different from what is shown here).</p><pre class="screen">$ cf api
API endpoint: https://api.system.io (API version: ...)

$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

No apps found</pre></li><li class="listitem"><p class="simpara">Follow the instructions to deploy the <a class="link" href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle" target="_top">Spring Cloud Data Flow Cloud Foundry server</a>. Don&#8217;t worry about creating a Redis service. We won&#8217;t need it. If you are familiar with Cloud Foundry
application manifests, we recommend creating a manifest for the the Data Flow server as shown <a class="link" href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#sample-manifest-template" target="_top">here</a>.</p><div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Warning"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Warning]" src="images/warning.png"></td><th align="left">Warning</th></tr><tr><td align="left" valign="top"><p>As of this writing, there is a typo on the <code class="literal">SPRING_APPLICATION_JSON</code> entry in the sample manifest. <code class="literal">SPRING_APPLICATION_JSON</code> must be followed by <code class="literal">:</code> and The JSON string must be
wrapped in single quotes. Alternatively, you can replace that line with <code class="literal">MAVEN_REMOTE_REPOSITORIES_REPO1_URL: <a class="link" href="https://repo.spring.io/libs-snapshot" target="_top">repo.spring.io/libs-snapshot</a></code>.  If your Cloud Foundry installation is behind a firewall, you may need to install the stream apps used in this sample in your internal Maven repository and <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/1.3.0.M2/reference/htmlsingle/#getting-started-maven-configuration" target="_top">configure</a> the server to access that repository.</p></td></tr></table></div></li><li class="listitem"><p class="simpara">Once you have successfully executed <code class="literal">cf push</code>, verify the dataflow server is running</p><pre class="screen">$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

name                 requested state   instances   memory   disk   urls
dataflow-server      started           1/1         1G       1G     dataflow-server.app.io</pre></li><li class="listitem">Notice that the <code class="literal">dataflow-server</code> application is started and ready for interaction via the url endpoint</li><li class="listitem"><p class="simpara">Connect the <code class="literal">shell</code> with <code class="literal">server</code> running on Cloud Foundry, e.g., <code class="literal"><a class="link" href="http://dataflow-server.app.io" target="_top">dataflow-server.app.io</a></code></p><pre class="screen">$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar

  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
server-unknown:&gt;</pre><pre class="screen">server-unknown:&gt;dataflow config server http://dataflow-server.app.io
Successfully targeted http://dataflow-server.app.io
dataflow:&gt;</pre><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">Running instance of <code class="literal">cassandra</code> in Cloud Foundry or from another Cloud provider</li><li class="listitem">A database utility tool such as <a class="link" href="http://dbeaver.jkiss.org/" target="_top">DBeaver</a> to connect to the Cassandra instance. You might have to provide <code class="literal">host</code>, <code class="literal">port</code>, <code class="literal">username</code> and <code class="literal">password</code> depending on the Cassandra configuration you are using.</li><li class="listitem"><p class="simpara">Create a <code class="literal">book</code> table in your Cassandra keyspace using:</p><pre class="screen">CREATE TABLE book  (
    id          uuid PRIMARY KEY,
    isbn        text,
    author      text,
    title       text
);</pre></li></ul></div></li><li class="listitem"><p class="simpara"><a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app" target="_top">Register</a> the out-of-the-box applications for the Rabbit binder</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>These samples assume that the Data Flow Server can access a remote Maven repository, <code class="literal"><a class="link" href="https://repo.spring.io/libs-release" target="_top">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration" target="_top">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code class="literal">dataflow:&gt;app import --uri <a class="link" href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" target="_top">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code class="literal"><a class="link" href="https://repo.spring.io" target="_top">repo.spring.io</a></code>. For example,
<code class="literal">source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code class="literal">http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code class="literal">maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a class="link" href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties" target="_top">download</a> the required apps or <a class="link" href="https://github.com/spring-cloud-stream-app-starters" target="_top">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code class="literal">dataflow:&gt;app register&#8230;&#8203;</code> using the <code class="literal">maven://</code> resource URI format corresponding to your installed app.</p></td></tr></table></div><pre class="screen">dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</pre></li><li class="listitem"><p class="simpara">Create the stream</p><pre class="screen">dataflow:&gt;stream create cassandrastream --definition "http --spring.cloud.stream.bindings.output.contentType='application/json' | cassandra --ingestQuery='insert into book (id, isbn, title, author) values (uuid(), ?, ?, ?)' --username='&lt;USERNAME&gt;' --password='&lt;PASSWORD&gt;' --port=&lt;PORT&gt; --contact-points=&lt;HOST&gt; --keyspace='&lt;KEYSPACE&gt;'" --deploy

Created and deployed new stream 'cassandrastream'</pre></li><li class="listitem"><p class="simpara">Verify the stream is successfully deployed</p><pre class="screen">dataflow:&gt;stream list</pre></li><li class="listitem"><p class="simpara">Notice that <code class="literal">cassandrastream-http</code> and <code class="literal">cassandrastream-cassandra</code> <a class="link" href="https://github.com/spring-cloud-stream-app-starters/" target="_top">Spring Cloud Stream</a> applications are running as <span class="emphasis"><em>cloud-native</em></span> (microservice) applications in Cloud Foundry</p><pre class="screen">$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

name                        requested state   instances   memory   disk   urls
cassandrastream-cassandra   started           1/1         1G       1G     cassandrastream-cassandra.app.io
cassandrastream-http        started           1/1         1G       1G     cassandrastream-http.app.io
dataflow-server             started           1/1         1G       1G     dataflow-server.app.io</pre></li><li class="listitem"><p class="simpara">Lookup the <code class="literal">url</code> for <code class="literal">cassandrastream-http</code> application from the list above. Post sample data pointing to the <code class="literal">http</code> endpoint: <code class="literal">&lt;YOUR-cassandrastream-http-APP-URL&gt;</code></p><pre class="screen">http post --contentType 'application/json' --data '{"isbn": "1599869772", "title": "The Art of War", "author": "Sun Tzu"}' --target http://&lt;YOUR-cassandrastream-http-APP-URL&gt;
&gt; POST (application/json;charset=UTF-8) http://cassandrastream-http.app.io {"isbn": "1599869772", "title": "The Art of War", "author": "Sun Tzu"}
&gt; 202 ACCEPTED</pre></li><li class="listitem"><p class="simpara">Connect to the Cassandra instance and query the table <code class="literal">book</code> to list the data inserted</p><pre class="screen">select * from book;</pre></li><li class="listitem"><p class="simpara">Now, let&#8217;s try to take advantage of Pivotal Cloud Foundry&#8217;s platform capability. Let&#8217;s scale the <code class="literal">cassandrastream-http</code> application from 1 to 3 instances</p><pre class="screen">$ cf scale cassandrastream-http -i 3
Scaling app cassandrastream-http in org user-dataflow / space development as user...
OK</pre></li><li class="listitem"><p class="simpara">Verify App instances (3/3) running successfully</p><pre class="screen">$ cf apps
Getting apps in org user-dataflow / space development as user...
OK

name                        requested state   instances   memory   disk   urls
cassandrastream-cassandra   started           1/1         1G       1G     cassandrastream-cassandra.app.io
cassandrastream-http        started           3/3         1G       1G     cassandrastream-http.app.io
dataflow-server             started           1/1         1G       1G     dataflow-server.app.io</pre></li><li class="listitem">You&#8217;re done!</li></ol></div></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="_summary" href="#_summary"></a>Summary</h4></div></div></div><p>In this sample, you have learned:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">How to use Spring Cloud Data Flow&#8217;s <code class="literal">Local</code> and <code class="literal">Cloud Foundry</code> servers</li><li class="listitem">How to use Spring Cloud Data Flow&#8217;s <code class="literal">shell</code></li><li class="listitem">How to create streaming data pipeline to connect and write to <code class="literal">Cassandra</code></li><li class="listitem">How to scale data microservice applications on <code class="literal">Pivotal Cloud Foundry</code></li></ul></div></div></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="spring-cloud-data-flow-samples-jdbc-overview" href="#spring-cloud-data-flow-samples-jdbc-overview"></a>1.2&nbsp;JDBC Samples</h2></div></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="_http_to_mysql_demo" href="#_http_to_mysql_demo"></a>1.2.1&nbsp;HTTP to MySQL Demo</h3></div></div></div><p>In this demonstration, you will learn how to build a data pipeline using <a class="link" href="http://cloud.spring.io/spring-cloud-dataflow/" target="_top">Spring Cloud Data Flow</a> to consume data from an <code class="literal">http</code> endpoint and write to MySQL database using <code class="literal">jdbc</code> sink.</p><p>We will take you through the steps to configure and Spring Cloud Data Flow server in either a <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started/" target="_top">local</a> or <a class="link" href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#getting-started" target="_top">Cloud Foundry</a> environment.</p><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="_prerequisites_2" href="#_prerequisites_2"></a>Prerequisites</h4></div></div></div><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A Running Data Flow Shell</li></ul></div><p>The Spring Cloud Data Flow Shell is available for <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-deploying-spring-cloud-dataflow" target="_top">download</a> or you can <a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow" target="_top">build</a> it yourself.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>The Spring Cloud Data Flow Shell is a Spring Boot application that connects to the Data Flow Server&#8217;s REST API and supports a DSL that simplifies the process of defining a stream or task and managing its lifecycle. Most of these samples
use the shell. If you prefer, you can use the Data Flow UI <a class="link" href="http://localhost:9393/dashboard" target="_top">localhost:9393/dashboard</a>, (or wherever it the server is hosted) to perform the same operations.</p></td></tr></table></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>the Spring Cloud Data Flow Shell and Local server implementation are in the same repository and are both built by running <code class="literal">./mvnw install</code> from the project root directory. If you have already run the build, use the jar in <code class="literal">spring-cloud-dataflow-shell/target</code></p></td></tr></table></div><p>To run the Shell open a new terminal session:</p><pre class="screen">$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar
  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
dataflow:&gt;</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>The shell will try to connect to a local server by default. If the Local Dataflow Server is not running you will see:</p></td></tr></table></div><pre class="screen"> ____                              ____ _                __
/ ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
\___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
 ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
|____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
 ____ |_|    _          __|___/                 __________
|  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
| | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
| |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
|____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
server unknown:&gt;</pre><p>Connect the <code class="literal">shell</code> to the <code class="literal">server</code> running on , e.g., <code class="literal"><a class="link" href="http://dataflow-server.app.io" target="_top">dataflow-server.app.io</a></code></p><pre class="screen">server unknown:&gt;dataflow config server http://dataflow-server.app.io
Successfully targeted http://dataflow-server.app.io
dataflow:&gt;</pre></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="_using_local_server" href="#_using_local_server"></a>Using Local Server</h4></div></div></div><div class="section"><div class="titlepage"><div><div><h5 class="title"><a name="_additional_prerequisites_3" href="#_additional_prerequisites_3"></a>Additional Prerequisites</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A running local Data Flow Server</li></ul></div><p>The Local Data Flow Server is Spring Boot application available for <a class="link" href="http://cloud.spring.io/spring-cloud-dataflow/" target="_top">download</a> or you can <a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow" target="_top">build</a> it yourself.
If you build it yourself, the executable jar will be in <code class="literal">spring-cloud-dataflow-server-local/target</code></p><p>To run the Local Data Flow server Open a new terminal session:</p><pre class="screen">$cd  &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-LOCAL-JAR&gt;
$java -jar spring-cloud-dataflow-server-local-&lt;VERSION&gt;.jar</pre><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">Running instance of <a class="link" href="http://kafka.apache.org/downloads.html" target="_top">Kafka</a></li><li class="listitem">Running instance of <a class="link" href="http://www.mysql.com/" target="_top">MySQL</a></li><li class="listitem">A database utility tool such as <a class="link" href="http://dbeaver.jkiss.org/" target="_top">DBeaver</a> or <a class="link" href="https://www.dbvis.com/" target="_top">DbVisualizer</a></li><li class="listitem"><p class="simpara">Create the <code class="literal">test</code> database with a <code class="literal">names</code> table (in MySQL) using:</p><pre class="screen">CREATE DATABASE test;
USE test;
CREATE TABLE names
(
	name varchar(255)
);</pre><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara"><a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app" target="_top">Register</a> the out-of-the-box applications for the Kafka binder</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>These samples assume that the Data Flow Server can access a remote Maven repository, <code class="literal"><a class="link" href="https://repo.spring.io/libs-release" target="_top">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration" target="_top">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code class="literal">dataflow:&gt;app import --uri <a class="link" href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" target="_top">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code class="literal"><a class="link" href="https://repo.spring.io" target="_top">repo.spring.io</a></code>. For example,
<code class="literal">source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code class="literal">http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code class="literal">maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a class="link" href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties" target="_top">download</a> the required apps or <a class="link" href="https://github.com/spring-cloud-stream-app-starters" target="_top">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code class="literal">dataflow:&gt;app register&#8230;&#8203;</code> using the <code class="literal">maven://</code> resource URI format corresponding to your installed app.</p></td></tr></table></div><pre class="screen">dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-kafka-10-maven</pre></li><li class="listitem"><p class="simpara">Create the stream</p><pre class="screen">dataflow:&gt;stream create --name mysqlstream --definition "http --server.port=8787 | jdbc --tableName=names --columns=name --spring.datasource.driver-class-name=org.mariadb.jdbc.Driver --spring.datasource.url='jdbc:mysql://localhost:3306/test'" --deploy

Created and deployed new stream 'mysqlstream'</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>If MySQL isn&#8217;t running on default port on <code class="literal">localhost</code> or if you need username and password to connect, use one of the following options to specify the necessary connection parameters: <code class="literal">--spring.datasource.url='jdbc:mysql://&lt;HOST&gt;:&lt;PORT&gt;/&lt;NAME&gt;' --spring.datasource.username=&lt;USERNAME&gt; --spring.datasource.password=&lt;PASSWORD&gt;</code></p></td></tr></table></div></li><li class="listitem"><p class="simpara">Verify the stream is successfully deployed</p><pre class="screen">dataflow:&gt;stream list</pre></li><li class="listitem"><p class="simpara">Notice that <code class="literal">mysqlstream-http</code> and <code class="literal">mysqlstream-jdbc</code> <a class="link" href="https://github.com/spring-cloud-stream-app-starters//" target="_top">Spring Cloud Stream</a> applications are running as Spring Boot applications within the Local <code class="literal">server</code> as collocated processes.</p><pre class="screen">2016-05-03 09:29:55.918  INFO 65162 --- [nio-9393-exec-3] o.s.c.d.spi.local.LocalAppDeployer       : deploying app mysqlstream.jdbc instance 0
   Logs will be in /var/folders/c3/ctx7_rns6x30tq7rb76wzqwr0000gp/T/spring-cloud-dataflow-6850863945840320040/mysqlstream1-1462292995903/mysqlstream.jdbc
2016-05-03 09:29:55.939  INFO 65162 --- [nio-9393-exec-3] o.s.c.d.spi.local.LocalAppDeployer       : deploying app mysqlstream.http instance 0
   Logs will be in /var/folders/c3/ctx7_rns6x30tq7rb76wzqwr0000gp/T/spring-cloud-dataflow-6850863945840320040/mysqlstream-1462292995934/mysqlstream.http</pre></li><li class="listitem">Post sample data pointing to the <code class="literal">http</code> endpoint: <code class="literal"><a class="link" href="http://localhost:8787" target="_top">localhost:8787</a></code> [<code class="literal">8787</code> is the <code class="literal">server.port</code> we specified for the <code class="literal">http</code> source in this case]</li></ol></div><pre class="screen">dataflow:&gt;http post --contentType 'application/json' --target http://localhost:8787 --data "{\"name\": \"Foo\"}"
&gt; POST (application/json;charset=UTF-8) http://localhost:8787 {"name": "Spring Boot"}
&gt; 202 ACCEPTED</pre><p class="simpara">+</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">Connect to the MySQL instance and query the table <code class="literal">test.names</code> to list the new rows:</p><pre class="screen">select * from test.names;</pre></li><li class="listitem">You&#8217;re done!</li></ol></div></li></ul></div></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="_using_cloud_foundry_server" href="#_using_cloud_foundry_server"></a>Using Cloud Foundry Server</h4></div></div></div><div class="section"><div class="titlepage"><div><div><h5 class="title"><a name="_additional_prerequisites_4" href="#_additional_prerequisites_4"></a>Additional Prerequisites</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">Cloud Foundry instance</li><li class="listitem">The Spring Cloud Data Flow Cloud Foundry Server</li></ul></div><p>The Cloud Foundry Data Flow Server is Spring Boot application available for <a class="link" href="http://cloud.spring.io/spring-cloud-dataflow/" target="_top">download</a> or you can <a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow-server-cloudfoundry" target="_top">build</a> it yourself.
If you build it yourself, the executable jar will be in <code class="literal">spring-cloud-dataflow-server-cloudfoundry/target</code></p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>Although you can run the Data Flow Cloud Foundry Server locally and configure it to deploy to any Cloud Foundry instance, we will
deploy the server to Cloud Foundry as recommended.</p></td></tr></table></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">Verify that CF instance is reachable (Your endpoint urls will be different from what is shown here).</p><pre class="screen">$ cf api
API endpoint: https://api.system.io (API version: ...)

$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

No apps found</pre></li><li class="listitem"><p class="simpara">Follow the instructions to deploy the <a class="link" href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle" target="_top">Spring Cloud Data Flow Cloud Foundry server</a>. Don&#8217;t worry about creating a Redis service. We won&#8217;t need it. If you are familiar with Cloud Foundry
application manifests, we recommend creating a manifest for the the Data Flow server as shown <a class="link" href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#sample-manifest-template" target="_top">here</a>.</p><div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Warning"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Warning]" src="images/warning.png"></td><th align="left">Warning</th></tr><tr><td align="left" valign="top"><p>As of this writing, there is a typo on the <code class="literal">SPRING_APPLICATION_JSON</code> entry in the sample manifest. <code class="literal">SPRING_APPLICATION_JSON</code> must be followed by <code class="literal">:</code> and The JSON string must be
wrapped in single quotes. Alternatively, you can replace that line with <code class="literal">MAVEN_REMOTE_REPOSITORIES_REPO1_URL: <a class="link" href="https://repo.spring.io/libs-snapshot" target="_top">repo.spring.io/libs-snapshot</a></code>.  If your Cloud Foundry installation is behind a firewall, you may need to install the stream apps used in this sample in your internal Maven repository and <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/1.3.0.M2/reference/htmlsingle/#getting-started-maven-configuration" target="_top">configure</a> the server to access that repository.</p></td></tr></table></div></li><li class="listitem"><p class="simpara">Once you have successfully executed <code class="literal">cf push</code>, verify the dataflow server is running</p><pre class="screen">$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

name                 requested state   instances   memory   disk   urls
dataflow-server      started           1/1         1G       1G     dataflow-server.app.io</pre></li><li class="listitem">Notice that the <code class="literal">dataflow-server</code> application is started and ready for interaction via the url endpoint</li><li class="listitem"><p class="simpara">Connect the <code class="literal">shell</code> with <code class="literal">server</code> running on Cloud Foundry, e.g., <code class="literal"><a class="link" href="http://dataflow-server.app.io" target="_top">dataflow-server.app.io</a></code></p><pre class="screen">$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar

  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
server-unknown:&gt;</pre><pre class="screen">server-unknown:&gt;dataflow config server http://dataflow-server.app.io
Successfully targeted http://dataflow-server.app.io
dataflow:&gt;</pre><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">Running instance of <code class="literal">rabbit</code> in Cloud Foundry</li><li class="listitem">Running instance of <code class="literal">mysql</code> in Cloud Foundry</li><li class="listitem">A database utility tool such as <a class="link" href="http://dbeaver.jkiss.org/" target="_top">DBeaver</a> or <a class="link" href="https://www.dbvis.com/" target="_top">DbVisualizer</a></li><li class="listitem"><p class="simpara">Create the <code class="literal">names</code> table (in MySQL) using:</p><pre class="screen">CREATE TABLE names
(
	name varchar(255)
);</pre></li></ul></div></li><li class="listitem"><p class="simpara"><a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app" target="_top">Register</a> the out-of-the-box applications for the Rabbit binder</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>These samples assume that the Data Flow Server can access a remote Maven repository, <code class="literal"><a class="link" href="https://repo.spring.io/libs-release" target="_top">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration" target="_top">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code class="literal">dataflow:&gt;app import --uri <a class="link" href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" target="_top">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code class="literal"><a class="link" href="https://repo.spring.io" target="_top">repo.spring.io</a></code>. For example,
<code class="literal">source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code class="literal">http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code class="literal">maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a class="link" href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties" target="_top">download</a> the required apps or <a class="link" href="https://github.com/spring-cloud-stream-app-starters" target="_top">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code class="literal">dataflow:&gt;app register&#8230;&#8203;</code> using the <code class="literal">maven://</code> resource URI format corresponding to your installed app.</p></td></tr></table></div><pre class="screen">dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</pre></li><li class="listitem"><p class="simpara">Create the stream</p><pre class="screen">dataflow:&gt;stream create --name mysqlstream --definition "http | jdbc --tableName=names --columns=name"
Created new stream 'mysqlstream'

dataflow:&gt;stream deploy --name mysqlstream --properties "app.jdbc.spring.cloud.deployer.cloudfoundry.services=mysql"
Deployed stream 'mysqlstream'</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>By supplying  the <code class="literal">app.jdbc.spring.cloud.deployer.cloudfoundry.services=mysql</code> property, we are deploying the stream with <code class="literal">jdbc-sink</code> to automatically bind to <code class="literal">mysql</code> service and only this application in the stream gets the service binding. This also eliminates the requirement to supply <code class="literal">datasource</code> credentials in stream definition.</p></td></tr></table></div></li><li class="listitem"><p class="simpara">Verify the stream is successfully deployed</p><pre class="screen">dataflow:&gt;stream list</pre></li><li class="listitem"><p class="simpara">Notice that <code class="literal">mysqlstream-http</code> and <code class="literal">mysqlstream-jdbc</code> <a class="link" href="https://github.com/spring-cloud-stream-app-starters/" target="_top">Spring Cloud Stream</a> applications are running as <span class="emphasis"><em>cloud-native</em></span> (microservice) applications in Cloud Foundry</p><pre class="screen">$ cf apps
Getting apps in org user-dataflow / space development as user...
OK

name                        requested state   instances   memory   disk   urls
mysqlstream-http            started           1/1         1G       1G     mysqlstream-http.app.io
mysqlstream-jdbc            started           1/1         1G       1G     mysqlstream-jdbc.app.io
dataflow-server             started           1/1         1G       1G     dataflow-server.app.io</pre></li><li class="listitem"><p class="simpara">Lookup the <code class="literal">url</code> for <code class="literal">mysqlstream-http</code> application from the list above. Post sample data pointing to the <code class="literal">http</code> endpoint: <code class="literal">&lt;YOUR-mysqlstream-http-APP-URL&gt;</code></p><pre class="screen">http post --contentType 'application/json' --target http://mysqlstream-http.app.io --data "{\"name\": \"Bar"}"
&gt; POST (application/json;charset=UTF-8) http://mysqlstream-http.app.io {"name": "Bar"}
&gt; 202 ACCEPTED</pre></li><li class="listitem"><p class="simpara">Connect to the MySQL instance and query the table <code class="literal">names</code> to list the new rows:</p><pre class="screen">select * from names;</pre></li><li class="listitem"><p class="simpara">Now, let&#8217;s take advantage of Pivotal Cloud Foundry&#8217;s platform capability. Let&#8217;s scale the <code class="literal">mysqlstream-http</code> application from 1 to 3 instances</p><pre class="screen">$ cf scale mysqlstream-http -i 3
Scaling app mysqlstream-http in org user-dataflow / space development as user...
OK</pre></li><li class="listitem"><p class="simpara">Verify App instances (3/3) running successfully</p><pre class="screen">$ cf apps
Getting apps in org user-dataflow / space development as user...
OK

name                        requested state   instances   memory   disk   urls
mysqlstream-http            started           3/3         1G       1G     mysqlstream-http.app.io
mysqlstream-jdbc            started           1/1         1G       1G     mysqlstream-jdbc.app.io
dataflow-server             started           1/1         1G       1G     dataflow-server.app.io</pre></li><li class="listitem">You&#8217;re done!</li></ol></div></div></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="_summary_2" href="#_summary_2"></a>1.2.2&nbsp;Summary</h3></div></div></div><p>In this sample, you have learned:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">How to use Spring Cloud Data Flow&#8217;s <code class="literal">Local</code> and <code class="literal">Cloud Foundry</code> servers</li><li class="listitem">How to use Spring Cloud Data Flow&#8217;s <code class="literal">shell</code></li><li class="listitem">How to create streaming data pipeline to connect and write to <code class="literal">MySQL</code></li><li class="listitem">How to scale data microservice applications on <code class="literal">Pivotal Cloud Foundry</code></li></ul></div></div></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="spring-cloud-data-flow-samples-gemfire-overview" href="#spring-cloud-data-flow-samples-gemfire-overview"></a>1.3&nbsp;GemFire Samples</h2></div></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="spring-cloud-data-flow-samples-gemfire-http-overview" href="#spring-cloud-data-flow-samples-gemfire-http-overview"></a>1.3.1&nbsp;HTTP to Gemfire Demo</h3></div></div></div><p>In this demonstration, you will learn how to build a data pipeline using <a class="link" href="http://cloud.spring.io/spring-cloud-dataflow/" target="_top">Spring Cloud Data Flow</a> to consume data from an <code class="literal">http</code> endpoint and write to Gemfire using the <code class="literal">gemfire</code> sink.</p><p>We will take you through the steps to configure and run Spring Cloud Data Flow server in either a <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started/" target="_top">local</a> or <a class="link" href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#getting-started" target="_top">Cloud Foundry</a> environment.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>For legacy reasons the <code class="literal">gemfire</code> Spring Cloud Stream Apps are named after <code class="literal">Pivotal GemFire</code>. The code base for the commercial product has since been open sourced as <code class="literal">Apache Geode</code>. These samples should work with compatible versions of Pivotal GemFire or Apache Geode. Herein we will refer to the installed IMDG simply as <code class="literal">Geode</code>.</p></td></tr></table></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="_prerequisites_3" href="#_prerequisites_3"></a>Prerequisites</h4></div></div></div><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A Running Data Flow Shell</li></ul></div><p>The Spring Cloud Data Flow Shell is available for <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-deploying-spring-cloud-dataflow" target="_top">download</a> or you can <a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow" target="_top">build</a> it yourself.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>The Spring Cloud Data Flow Shell is a Spring Boot application that connects to the Data Flow Server&#8217;s REST API and supports a DSL that simplifies the process of defining a stream or task and managing its lifecycle. Most of these samples
use the shell. If you prefer, you can use the Data Flow UI <a class="link" href="http://localhost:9393/dashboard" target="_top">localhost:9393/dashboard</a>, (or wherever it the server is hosted) to perform the same operations.</p></td></tr></table></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>the Spring Cloud Data Flow Shell and Local server implementation are in the same repository and are both built by running <code class="literal">./mvnw install</code> from the project root directory. If you have already run the build, use the jar in <code class="literal">spring-cloud-dataflow-shell/target</code></p></td></tr></table></div><p>To run the Shell open a new terminal session:</p><pre class="screen">$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar
  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
dataflow:&gt;</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>The shell will try to connect to a local server by default. If the Local Dataflow Server is not running you will see:</p></td></tr></table></div><pre class="screen"> ____                              ____ _                __
/ ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
\___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
 ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
|____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
 ____ |_|    _          __|___/                 __________
|  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
| | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
| |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
|____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
server unknown:&gt;</pre><p>Connect the <code class="literal">shell</code> to the <code class="literal">server</code> running on , e.g., <code class="literal"><a class="link" href="http://dataflow-server.app.io" target="_top">dataflow-server.app.io</a></code></p><pre class="screen">server unknown:&gt;dataflow config server http://dataflow-server.app.io
Successfully targeted http://dataflow-server.app.io
dataflow:&gt;</pre><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A Geode installation with a locator and cache server running
Unresolved directive in streaming/gemfire/gemfire-http/overview.adoc - include::geode-setup.adoc[]</li></ul></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="gemfire-http-local" href="#gemfire-http-local"></a>Using the Local Server</h4></div></div></div><div class="section"><div class="titlepage"><div><div><h5 class="title"><a name="_additional_prerequisites_5" href="#_additional_prerequisites_5"></a>Additional Prerequisites</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A running local Data Flow Server</li></ul></div><p>The Local Data Flow Server is Spring Boot application available for <a class="link" href="http://cloud.spring.io/spring-cloud-dataflow/" target="_top">download</a> or you can <a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow" target="_top">build</a> it yourself.
If you build it yourself, the executable jar will be in <code class="literal">spring-cloud-dataflow-server-local/target</code></p><p>To run the Local Data Flow server Open a new terminal session:</p><pre class="screen">$cd  &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-LOCAL-JAR&gt;
$java -jar spring-cloud-dataflow-server-local-&lt;VERSION&gt;.jar</pre><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A running instance of <a class="link" href="https://www.rabbitmq.com" target="_top">Rabbit MQ</a></li></ul></div><p></p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">Use gfsh to start a locator and server</p><pre class="screen">gfsh&gt;start locator --name=locator1
gfsh&gt;start server --name=server1</pre></li><li class="listitem"><p class="simpara">Create a region called <code class="literal">Stocks</code></p><pre class="screen">gfsh&gt;create region --name Stocks --type=REPLICATE</pre></li></ol></div></div><div class="section"><div class="titlepage"><div><div><h5 class="title"><a name="_use_the_shell_to_create_the_sample_stream" href="#_use_the_shell_to_create_the_sample_stream"></a>Use the Shell to create the sample stream</h5></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara"><a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app" target="_top">Register</a> the out-of-the-box applications for the Rabbit binder</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>These samples assume that the Data Flow Server can access a remote Maven repository, <code class="literal"><a class="link" href="https://repo.spring.io/libs-release" target="_top">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration" target="_top">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code class="literal">dataflow:&gt;app import --uri <a class="link" href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" target="_top">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code class="literal"><a class="link" href="https://repo.spring.io" target="_top">repo.spring.io</a></code>. For example,
<code class="literal">source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code class="literal">http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code class="literal">maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a class="link" href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties" target="_top">download</a> the required apps or <a class="link" href="https://github.com/spring-cloud-stream-app-starters" target="_top">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code class="literal">dataflow:&gt;app register&#8230;&#8203;</code> using the <code class="literal">maven://</code> resource URI format corresponding to your installed app.</p></td></tr></table></div><pre class="screen">dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</pre></li><li class="listitem"><p class="simpara">Create the stream</p><p class="simpara">This example creates an http endpoint to which we will post stock prices as a JSON document containing <code class="literal">symbol</code> and <code class="literal">price</code> fields.
The property <code class="literal">--json=true</code> to enable Geode&#8217;s JSON support and configures the sink to convert JSON String payloads to <a class="link" href="https://geode.apache.org/releases/latest/javadoc/org/apache/geode/pdx/PdxInstance.html" target="_top">PdxInstance</a>, the recommended way
to store JSON documents in Geode. The <code class="literal">keyExpression</code> property is a SpEL expression used to extract the <code class="literal">symbol</code> value the PdxInstance to use as an entry key.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>PDX serialization is very efficient and supports OQL queries without requiring a custom domain class.
Use of custom domain types requires these classes to be in the class path of both the stream apps and the cache server.
For this reason, the use of custom payload types is generally discouraged.</p></td></tr></table></div><pre class="screen">dataflow:&gt;stream create --name stocks --definition "http --port=9090 | gemfire --json=true --regionName=Stocks --keyExpression=payload.getField('symbol')" --deploy
Created and deployed new stream 'stocks'</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>If the Geode locator isn&#8217;t running on default port on <code class="literal">localhost</code>, add the options <code class="literal">--connect-type=locator --host-addresses=&lt;host&gt;:&lt;port&gt;</code>. If there are multiple
locators, you can provide a comma separated list of locator addresses. This is not necessary for the sample but is typical for production environments to enable fail-over.</p></td></tr></table></div></li><li class="listitem"><p class="simpara">Verify the stream is successfully deployed</p><pre class="screen">dataflow:&gt;stream list</pre></li><li class="listitem"><p class="simpara">Post sample data pointing to the <code class="literal">http</code> endpoint: <code class="literal"><a class="link" href="http://localhost:9090" target="_top">localhost:9090</a></code> (<code class="literal">9090</code> is the <code class="literal">port</code> we specified for the <code class="literal">http</code> source)</p><pre class="screen">dataflow:&gt;http post --target http://localhost:9090 --contentType application/json --data '{"symbol":"VMW","price":117.06}'
&gt; POST (application/json) http://localhost:9090 {"symbol":"VMW","price":117.06}
&gt; 202 ACCEPTED</pre></li><li class="listitem"><p class="simpara">Using <code class="literal">gfsh</code>, connect to the locator if not already connected, and verify the cache entry was created.</p><pre class="screen">gfsh&gt;get --key='VMW' --region=/Stocks
Result      : true
Key Class   : java.lang.String
Key         : VMW
Value Class : org.apache.geode.pdx.internal.PdxInstanceImpl

symbol | price
------ | ------
VMW    | 117.06</pre></li><li class="listitem">You&#8217;re done!</li></ol></div></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="gemfire-http-cf" href="#gemfire-http-cf"></a>Using the Cloud Foundry Server</h4></div></div></div><div class="section"><div class="titlepage"><div><div><h5 class="title"><a name="_additional_prerequisites_6" href="#_additional_prerequisites_6"></a>Additional Prerequisites</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A Cloud Foundry instance</li><li class="listitem">Cloud Data Flow Cloud Foundry Server</li></ul></div><p>The Cloud Foundry Data Flow Server is Spring Boot application available for <a class="link" href="http://cloud.spring.io/spring-cloud-dataflow/" target="_top">download</a> or you can <a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow-server-cloudfoundry" target="_top">build</a> it yourself.
If you build it yourself, the executable jar will be in <code class="literal">spring-cloud-dataflow-server-cloudfoundry/target</code></p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>Although you can run the Data Flow Cloud Foundry Server locally and configure it to deploy to any Cloud Foundry instance, we will
deploy the server to Cloud Foundry as recommended.</p></td></tr></table></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">Verify that CF instance is reachable (Your endpoint urls will be different from what is shown here).</p><pre class="screen">$ cf api
API endpoint: https://api.system.io (API version: ...)

$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

No apps found</pre></li><li class="listitem"><p class="simpara">Follow the instructions to deploy the <a class="link" href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle" target="_top">Spring Cloud Data Flow Cloud Foundry server</a>. Don&#8217;t worry about creating a Redis service. We won&#8217;t need it. If you are familiar with Cloud Foundry
application manifests, we recommend creating a manifest for the the Data Flow server as shown <a class="link" href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#sample-manifest-template" target="_top">here</a>.</p><div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Warning"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Warning]" src="images/warning.png"></td><th align="left">Warning</th></tr><tr><td align="left" valign="top"><p>As of this writing, there is a typo on the <code class="literal">SPRING_APPLICATION_JSON</code> entry in the sample manifest. <code class="literal">SPRING_APPLICATION_JSON</code> must be followed by <code class="literal">:</code> and The JSON string must be
wrapped in single quotes. Alternatively, you can replace that line with <code class="literal">MAVEN_REMOTE_REPOSITORIES_REPO1_URL: <a class="link" href="https://repo.spring.io/libs-snapshot" target="_top">repo.spring.io/libs-snapshot</a></code>.  If your Cloud Foundry installation is behind a firewall, you may need to install the stream apps used in this sample in your internal Maven repository and <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/1.3.0.M2/reference/htmlsingle/#getting-started-maven-configuration" target="_top">configure</a> the server to access that repository.</p></td></tr></table></div></li><li class="listitem"><p class="simpara">Once you have successfully executed <code class="literal">cf push</code>, verify the dataflow server is running</p><pre class="screen">$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

name                 requested state   instances   memory   disk   urls
dataflow-server      started           1/1         1G       1G     dataflow-server.app.io</pre></li><li class="listitem">Notice that the <code class="literal">dataflow-server</code> application is started and ready for interaction via the url endpoint</li><li class="listitem"><p class="simpara">Connect the <code class="literal">shell</code> with <code class="literal">server</code> running on Cloud Foundry, e.g., <code class="literal"><a class="link" href="http://dataflow-server.app.io" target="_top">dataflow-server.app.io</a></code></p><pre class="screen">$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar

  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
server-unknown:&gt;</pre><pre class="screen">server-unknown:&gt;dataflow config server http://dataflow-server.app.io
Successfully targeted http://dataflow-server.app.io
dataflow:&gt;</pre><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">Running instance of a <code class="literal">rabbit</code> service in Cloud Foundry</li><li class="listitem">Running instance of the <a class="link" href="https://docs.pivotal.io/p-cloud-cache/1-0/developer.html" target="_top">Pivotal Cloud Cache for PCF</a> (PCC) service <code class="literal">cloudcache</code> in Cloud Foundry.</li></ul></div></li><li class="listitem"><p class="simpara"><a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app" target="_top">Register</a> the out-of-the-box applications for the Rabbit binder</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>These samples assume that the Data Flow Server can access a remote Maven repository, <code class="literal"><a class="link" href="https://repo.spring.io/libs-release" target="_top">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration" target="_top">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code class="literal">dataflow:&gt;app import --uri <a class="link" href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" target="_top">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code class="literal"><a class="link" href="https://repo.spring.io" target="_top">repo.spring.io</a></code>. For example,
<code class="literal">source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code class="literal">http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code class="literal">maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a class="link" href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties" target="_top">download</a> the required apps or <a class="link" href="https://github.com/spring-cloud-stream-app-starters" target="_top">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code class="literal">dataflow:&gt;app register&#8230;&#8203;</code> using the <code class="literal">maven://</code> resource URI format corresponding to your installed app.</p></td></tr></table></div><pre class="screen">dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</pre></li><li class="listitem"><p class="simpara">Get the PCC connection information</p><pre class="screen">$ cf service-key cloudcache my-service-key
Getting key my-service-key for service instance cloudcache as &lt;user&gt;...

{
 "locators": [
  "10.0.16.9[55221]",
  "10.0.16.11[55221]",
  "10.0.16.10[55221]"
 ],
 "urls": {
  "gfsh": "http://...",
  "pulse": "http://.../pulse"
 },
 "users": [
  {
   "password": &lt;password&gt;,
   "username": "cluster_operator"
  },
  {
   "password": &lt;password&gt;,
   "username": "developer"
  }
 ]
}</pre></li><li class="listitem"><p class="simpara">Using <code class="literal">gfsh</code>, connect to the PCC instance as <code class="literal">cluster_operator</code> using the service key values and create the Stocks region.</p><pre class="screen">gfsh&gt;connect --use-http --url=&lt;gfsh-url&gt; --user=cluster_operator --password=&lt;cluster_operator_password&gt;
gfsh&gt;create region --name Stocks --type=REPLICATE</pre></li><li class="listitem"><p class="simpara">Create the stream, connecting to the PCC instance as developer</p><p class="simpara">This example creates an http endpoint to which we will post stock prices as a JSON document containing <code class="literal">symbol</code> and <code class="literal">price</code> fields.
The property <code class="literal">--json=true</code> to enable Geode&#8217;s JSON support and configures the sink to convert JSON String payloads to <a class="link" href="https://geode.apache.org/releases/latest/javadoc/org/apache/geode/pdx/PdxInstance.html" target="_top">PdxInstance</a>, the recommended way
to store JSON documents in Geode. The <code class="literal">keyExpression</code> property is a SpEL expression used to extract the <code class="literal">symbol</code> value the PdxInstance to use as an entry key.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>PDX serialization is very efficient and supports OQL queries without requiring a custom domain class.
Use of custom domain types requires these classes to be in the class path of both the stream apps and the cache server.
For this reason, the use of custom payload types is generally discouraged.</p></td></tr></table></div><pre class="screen">dataflow:&gt;stream create --name stocks --definition "http --security.basic.enabled=false | gemfire --username=developer --password=&lt;developer-password&gt; --connect-type=locator --host-addresses=10.0.16.9:55221 --regionName=Stocks --keyExpression=payload.getField('symbol')" --deploy</pre></li><li class="listitem"><p class="simpara">Verify the stream is successfully deployed</p><pre class="screen">dataflow:&gt;stream list</pre></li><li class="listitem"><p class="simpara">Post sample data pointing to the <code class="literal">http</code> endpoint</p><p class="simpara">Get the url of the http source using <code class="literal">cf apps</code></p><pre class="screen">dataflow:&gt;http post --target http://&lt;http source url&gt; --contentType application/json --data '{"symbol":"VMW","price":117.06}'
&gt; POST (application/json) http://... {"symbol":"VMW","price":117.06}
&gt; 202 ACCEPTED</pre></li><li class="listitem"><p class="simpara">Using <code class="literal">gfsh</code>, connect to the PCC instance as <code class="literal">cluster_operator</code> using the service key values.</p><pre class="screen">gfsh&gt;connect --use-http --url=&lt;gfsh-url&gt; --user=cluster_operator --password=&lt;cluster_operator_password&gt;
gfsh&gt;get --key='VMW' --region=/Stocks
Result      : true
Key Class   : java.lang.String
Key         : VMW
Value Class : org.apache.geode.pdx.internal.PdxInstanceImpl

symbol | price
------ | ------
VMW    | 117.06</pre></li><li class="listitem">You&#8217;re done!</li></ol></div></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="_summary_3" href="#_summary_3"></a>Summary</h4></div></div></div><p>In this sample, you have learned:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">How to use Spring Cloud Data Flow&#8217;s <code class="literal">Local</code> and <code class="literal">Cloud Foundry</code> servers</li><li class="listitem">How to use Spring Cloud Data Flow&#8217;s <code class="literal">shell</code></li><li class="listitem">How to create streaming data pipeline to connect and write to <code class="literal">gemfire</code></li></ul></div></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="spring-cloud-data-flow-samples-gemfire-log-overview" href="#spring-cloud-data-flow-samples-gemfire-log-overview"></a>1.3.2&nbsp;Gemfire to Log Demo</h3></div></div></div><p>In this demonstration, you will learn how to build a data pipeline using <a class="link" href="http://cloud.spring.io/spring-cloud-dataflow/" target="_top">Spring Cloud Data Flow</a> to consume data from a <code class="literal">gemfire</code> endpoint and write to a log using the <code class="literal">log</code> sink.
The <code class="literal">gemfire</code> source creates a <a class="link" href="https://geode.apache.org/releases/latest/javadoc/org/apache/geode/cache/CacheListener.html" target="_top">CacheListener</a> to monitor events for a region and publish a message whenever an entry is changed.</p><p>We will take you through the steps to configure and run Spring Cloud Data Flow server in either a <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started/" target="_top">local</a> or <a class="link" href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#getting-started" target="_top">Cloud Foundry</a> environment.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>For legacy reasons the <code class="literal">gemfire</code> Spring Cloud Stream Apps are named after <code class="literal">Pivotal GemFire</code>. The code base for the commercial product has since been open sourced as <code class="literal">Apache Geode</code>. These samples should work with compatible versions of Pivotal GemFire or Apache Geode. Herein we will refer to the installed IMDG simply as <code class="literal">Geode</code>.</p></td></tr></table></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="_prerequisites_4" href="#_prerequisites_4"></a>Prerequisites</h4></div></div></div><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A Running Data Flow Shell</li></ul></div><p>The Spring Cloud Data Flow Shell is available for <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-deploying-spring-cloud-dataflow" target="_top">download</a> or you can <a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow" target="_top">build</a> it yourself.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>The Spring Cloud Data Flow Shell is a Spring Boot application that connects to the Data Flow Server&#8217;s REST API and supports a DSL that simplifies the process of defining a stream or task and managing its lifecycle. Most of these samples
use the shell. If you prefer, you can use the Data Flow UI <a class="link" href="http://localhost:9393/dashboard" target="_top">localhost:9393/dashboard</a>, (or wherever it the server is hosted) to perform the same operations.</p></td></tr></table></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>the Spring Cloud Data Flow Shell and Local server implementation are in the same repository and are both built by running <code class="literal">./mvnw install</code> from the project root directory. If you have already run the build, use the jar in <code class="literal">spring-cloud-dataflow-shell/target</code></p></td></tr></table></div><p>To run the Shell open a new terminal session:</p><pre class="screen">$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar
  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
dataflow:&gt;</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>The shell will try to connect to a local server by default. If the Local Dataflow Server is not running you will see:</p></td></tr></table></div><pre class="screen"> ____                              ____ _                __
/ ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
\___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
 ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
|____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
 ____ |_|    _          __|___/                 __________
|  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
| | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
| |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
|____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
server unknown:&gt;</pre><p>Connect the <code class="literal">shell</code> to the <code class="literal">server</code> running on , e.g., <code class="literal"><a class="link" href="http://dataflow-server.app.io" target="_top">dataflow-server.app.io</a></code></p><pre class="screen">server unknown:&gt;dataflow config server http://dataflow-server.app.io
Successfully targeted http://dataflow-server.app.io
dataflow:&gt;</pre><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A Geode installation with a locator and cache server running
Unresolved directive in streaming/gemfire/gemfire-log/overview.adoc - include::geode-setup.adoc[]</li></ul></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="gemfire-log-local" href="#gemfire-log-local"></a>Using the Local Server</h4></div></div></div><div class="section"><div class="titlepage"><div><div><h5 class="title"><a name="_additional_prerequisites_7" href="#_additional_prerequisites_7"></a>Additional Prerequisites</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A Running Data Flow Server</li></ul></div><p>The Local Data Flow Server is Spring Boot application available for <a class="link" href="http://cloud.spring.io/spring-cloud-dataflow/" target="_top">download</a> or you can <a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow" target="_top">build</a> it yourself.
If you build it yourself, the executable jar will be in <code class="literal">spring-cloud-dataflow-server-local/target</code></p><p>To run the Local Data Flow server Open a new terminal session:</p><pre class="screen">$cd  &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-LOCAL-JAR&gt;
$java -jar spring-cloud-dataflow-server-local-&lt;VERSION&gt;.jar</pre><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A running instance of <a class="link" href="https://www.rabbitmq.com" target="_top">Rabbit MQ</a></li></ul></div><p></p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">Use gfsh to start a locator and server</p><pre class="screen">gfsh&gt;start locator --name=locator1
gfsh&gt;start server --name=server1</pre></li><li class="listitem"><p class="simpara">Create a region called <code class="literal">Test</code></p><pre class="screen">gfsh&gt;create region --name Test --type=REPLICATE</pre></li></ol></div></div><div class="section"><div class="titlepage"><div><div><h5 class="title"><a name="_use_the_shell_to_create_the_sample_stream_2" href="#_use_the_shell_to_create_the_sample_stream_2"></a>Use the Shell to create the sample stream.</h5></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara"><a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app" target="_top">Register</a> the out-of-the-box applications for the Rabbit binder</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>These samples assume that the Data Flow Server can access a remote Maven repository, <code class="literal"><a class="link" href="https://repo.spring.io/libs-release" target="_top">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration" target="_top">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code class="literal">dataflow:&gt;app import --uri <a class="link" href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" target="_top">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code class="literal"><a class="link" href="https://repo.spring.io" target="_top">repo.spring.io</a></code>. For example,
<code class="literal">source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code class="literal">http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code class="literal">maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a class="link" href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties" target="_top">download</a> the required apps or <a class="link" href="https://github.com/spring-cloud-stream-app-starters" target="_top">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code class="literal">dataflow:&gt;app register&#8230;&#8203;</code> using the <code class="literal">maven://</code> resource URI format corresponding to your installed app.</p></td></tr></table></div><pre class="screen">dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</pre></li><li class="listitem"><p class="simpara">Create the stream</p><p class="simpara">This example creates an gemfire source to which will publish events on a region</p><pre class="screen">dataflow:&gt;stream create --name events --definition " gemfire --regionName=Test | log" --deploy
Created and deployed new stream 'events'</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>If the Geode locator isn&#8217;t running on default port on <code class="literal">localhost</code>, add the options <code class="literal">--connect-type=locator --host-addresses=&lt;host&gt;:&lt;port&gt;</code>. If there are multiple
locators, you can provide a comma separated list of locator addresses. This is not necessary for the sample but is typical for production environments to enable fail-over.</p></td></tr></table></div></li><li class="listitem"><p class="simpara">Verify the stream is successfully deployed</p><pre class="screen">dataflow:&gt;stream list</pre></li><li class="listitem"><p class="simpara">Monitor stdout for the log sink. When you deploy the stream, you will see log messages in the Data Flow server console like this</p><pre class="screen">2017-10-28 17:28:23.275  INFO 15603 --- [nio-9393-exec-2] o.s.c.d.spi.local.LocalAppDeployer       : Deploying app with deploymentId events.log instance 0.
   Logs will be in /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/spring-cloud-dataflow-4093992067314402881/events-1509226103269/events.log
2017-10-28 17:28:23.277  INFO 15603 --- [nio-9393-exec-2] o.s.c.d.s.c.StreamDeploymentController   : Downloading resource URI [maven://org.springframework.cloud.stream.app:gemfire-source-rabbit:1.2.0.RELEASE]
2017-10-28 17:28:23.311  INFO 15603 --- [nio-9393-exec-2] o.s.c.d.s.c.StreamDeploymentController   : Deploying application named [gemfire] as part of stream named [events] with resource URI [maven://org.springframework.cloud.stream.app:gemfire-source-rabbit:1.2.0.RELEASE]
2017-10-28 17:28:23.318  INFO 15603 --- [nio-9393-exec-2] o.s.c.d.spi.local.LocalAppDeployer       : Deploying app with deploymentId events.gemfire instance 0.
   Logs will be in /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/spring-cloud-dataflow-4093992067314402881/events-1509226103311/events.gemfire</pre><p class="simpara">Copy the location of the <code class="literal">log</code> sink logs. This is a directory that ends in <code class="literal">events.log</code>. The log files will be in <code class="literal">stdout_0.log</code> under this directory. You can monitor the output of the log sink using <code class="literal">tail</code>, or something similar:</p><pre class="screen">$tail -f /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/spring-cloud-dataflow-4093992067314402881/events-1509226103269/events.log/stdout_0.log</pre></li><li class="listitem"><p class="simpara">Using <code class="literal">gfsh</code>, create and update some cache entries</p><pre class="screen">gfsh&gt;put --region /Test --key 1  --value "value 1"
gfsh&gt;put --region /Test --key 2  --value "value 2"
gfsh&gt;put --region /Test --key 3  --value "value 3"
gfsh&gt;put --region /Test --key 1  --value "new value 1"</pre></li><li class="listitem"><p class="simpara">Observe the log output
You should see messages like:</p><pre class="screen">2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log sink                               : value 1"
2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log sink                               : value 2"
2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log sink                               : value 3"
2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log sink                               : new value 1"</pre><p class="simpara">By default, the message payload contains the updated value. Depending on your application, you may need additional information. The data comes from <a class="link" href="https://geode.apache.org/releases/latest/javadoc/org/apache/geode/cache/EntryEvent.html" target="_top">EntryEvent</a>. You
can access any fields using the source&#8217;s <code class="literal">cache-event-expression</code> property. This takes a SpEL expression bound to the EntryEvent. Try something like <code class="literal">--cache-event-expression='{key:'+key+',new_value:'+newValue+'}'</code> (HINT: You will need to destroy the stream and recreate it to
add this property, an exercise left to the reader). Now you should see log messages like:</p><pre class="screen">2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log-sink                                 : {key:1,new_value:value 1}
2017-10-28 17:41:24.466  INFO 18986 --- [emfire.events-1] log-sink                                 : {key:2,new_value:value 2}</pre></li><li class="listitem">You&#8217;re done!</li></ol></div></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="gemfire-log-cf" href="#gemfire-log-cf"></a>Using the Cloud Foundry Server</h4></div></div></div><div class="section"><div class="titlepage"><div><div><h5 class="title"><a name="_additional_prerequisites_8" href="#_additional_prerequisites_8"></a>Additional Prerequisites</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A Cloud Foundry instance</li><li class="listitem">The Spring Cloud Data Flow Cloud Foundry Server</li></ul></div><p>The Cloud Foundry Data Flow Server is Spring Boot application available for <a class="link" href="http://cloud.spring.io/spring-cloud-dataflow/" target="_top">download</a> or you can <a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow-server-cloudfoundry" target="_top">build</a> it yourself.
If you build it yourself, the executable jar will be in <code class="literal">spring-cloud-dataflow-server-cloudfoundry/target</code></p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>Although you can run the Data Flow Cloud Foundry Server locally and configure it to deploy to any Cloud Foundry instance, we will
deploy the server to Cloud Foundry as recommended.</p></td></tr></table></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">Verify that CF instance is reachable (Your endpoint urls will be different from what is shown here).</p><pre class="screen">$ cf api
API endpoint: https://api.system.io (API version: ...)

$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

No apps found</pre></li><li class="listitem"><p class="simpara">Follow the instructions to deploy the <a class="link" href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle" target="_top">Spring Cloud Data Flow Cloud Foundry server</a>. Don&#8217;t worry about creating a Redis service. We won&#8217;t need it. If you are familiar with Cloud Foundry
application manifests, we recommend creating a manifest for the the Data Flow server as shown <a class="link" href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#sample-manifest-template" target="_top">here</a>.</p><div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Warning"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Warning]" src="images/warning.png"></td><th align="left">Warning</th></tr><tr><td align="left" valign="top"><p>As of this writing, there is a typo on the <code class="literal">SPRING_APPLICATION_JSON</code> entry in the sample manifest. <code class="literal">SPRING_APPLICATION_JSON</code> must be followed by <code class="literal">:</code> and The JSON string must be
wrapped in single quotes. Alternatively, you can replace that line with <code class="literal">MAVEN_REMOTE_REPOSITORIES_REPO1_URL: <a class="link" href="https://repo.spring.io/libs-snapshot" target="_top">repo.spring.io/libs-snapshot</a></code>.  If your Cloud Foundry installation is behind a firewall, you may need to install the stream apps used in this sample in your internal Maven repository and <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/1.3.0.M2/reference/htmlsingle/#getting-started-maven-configuration" target="_top">configure</a> the server to access that repository.</p></td></tr></table></div></li><li class="listitem"><p class="simpara">Once you have successfully executed <code class="literal">cf push</code>, verify the dataflow server is running</p><pre class="screen">$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

name                 requested state   instances   memory   disk   urls
dataflow-server      started           1/1         1G       1G     dataflow-server.app.io</pre></li><li class="listitem">Notice that the <code class="literal">dataflow-server</code> application is started and ready for interaction via the url endpoint</li><li class="listitem"><p class="simpara">Connect the <code class="literal">shell</code> with <code class="literal">server</code> running on Cloud Foundry, e.g., <code class="literal"><a class="link" href="http://dataflow-server.app.io" target="_top">dataflow-server.app.io</a></code></p><pre class="screen">$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar

  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
server-unknown:&gt;</pre><pre class="screen">server-unknown:&gt;dataflow config server http://dataflow-server.app.io
Successfully targeted http://dataflow-server.app.io
dataflow:&gt;</pre><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">Running instance of a <code class="literal">rabbit</code> service in Cloud Foundry</li><li class="listitem">Running instance of the <a class="link" href="https://docs.pivotal.io/p-cloud-cache/1-0/developer.html" target="_top">Pivotal Cloud Cache for PCF</a> (PCC) service <code class="literal">cloudcache</code> in Cloud Foundry.</li></ul></div></li><li class="listitem"><p class="simpara"><a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app" target="_top">Register</a> the out-of-the-box applications for the Rabbit binder</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>These samples assume that the Data Flow Server can access a remote Maven repository, <code class="literal"><a class="link" href="https://repo.spring.io/libs-release" target="_top">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration" target="_top">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code class="literal">dataflow:&gt;app import --uri <a class="link" href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" target="_top">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code class="literal"><a class="link" href="https://repo.spring.io" target="_top">repo.spring.io</a></code>. For example,
<code class="literal">source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code class="literal">http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code class="literal">maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a class="link" href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties" target="_top">download</a> the required apps or <a class="link" href="https://github.com/spring-cloud-stream-app-starters" target="_top">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code class="literal">dataflow:&gt;app register&#8230;&#8203;</code> using the <code class="literal">maven://</code> resource URI format corresponding to your installed app.</p></td></tr></table></div><pre class="screen">dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</pre></li><li class="listitem"><p class="simpara">Get the PCC connection information</p><pre class="screen">$ cf service-key cloudcache my-service-key
Getting key my-service-key for service instance cloudcache as &lt;user&gt;...

{
 "locators": [
  "10.0.16.9[55221]",
  "10.0.16.11[55221]",
  "10.0.16.10[55221]"
 ],
 "urls": {
  "gfsh": "http://...",
  "pulse": "http://.../pulse"
 },
 "users": [
  {
   "password": &lt;password&gt;,
   "username": "cluster_operator"
  },
  {
   "password": &lt;password&gt;,
   "username": "developer"
  }
 ]
}</pre></li><li class="listitem"><p class="simpara">Using <code class="literal">gfsh</code>, connect to the PCC instance as <code class="literal">cluster_operator</code> using the service key values and create the Test region.</p><pre class="screen">gfsh&gt;connect --use-http --url=&lt;gfsh-url&gt; --user=cluster_operator --password=&lt;cluster_operator_password&gt;
gfsh&gt;create region --name Test --type=REPLICATE</pre></li><li class="listitem"><p class="simpara">Create the stream, connecting to the PCC instance as developer. This example creates an gemfire source to which will publish events on a region</p><pre class="screen">dataflow stream create --name events --definition " gemfire --username=developer --password=&lt;developer-password&gt; --connect-type=locator --host-addresses=10.0.16.9:55221 --regionName=Test | log" --deploy</pre></li><li class="listitem"><p class="simpara">Verify the stream is successfully deployed</p><pre class="screen">dataflow:&gt;stream list</pre></li><li class="listitem"><p class="simpara">Monitor stdout for the log sink</p><pre class="screen">cf logs &lt;log-sink-app-name&gt;</pre></li><li class="listitem"><p class="simpara">Using <code class="literal">gfsh</code>, create and update some cache entries</p><pre class="screen">gfsh&gt;connect --use-http --url=&lt;gfsh-url&gt; --user=cluster_operator --password=&lt;cluster_operator_password&gt;
gfsh&gt;put --region /Test --key 1  --value "value 1"
gfsh&gt;put --region /Test --key 2  --value "value 2"
gfsh&gt;put --region /Test --key 3  --value "value 3"
gfsh&gt;put --region /Test --key 1  --value "new value 1"</pre></li><li class="listitem"><p class="simpara">Observe the log output</p><p class="simpara">You should see messages like:</p><pre class="screen">2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log sink                               : value 1"
2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log sink                               : value 2"
2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log sink                               : value 3"
2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log sink                               : new value 1"</pre><p class="simpara">By default, the message payload contains the updated value. Depending on your application, you may need additional information. The data comes from <a class="link" href="https://geode.apache.org/releases/latest/javadoc/org/apache/geode/cache/EntryEvent.html" target="_top">EntryEvent</a>. You
can access any fields using the source&#8217;s <code class="literal">cache-event-expression</code> property. This takes a SpEL expression bound to the EntryEvent. Try something like <code class="literal">--cache-event-expression='{key:'+key+',new_value:'+newValue+'}'</code> (HINT: You will need to destroy the stream and recreate it to
add this property, an exercise left to the reader). Now you should see log messages like:</p><pre class="screen">2017-10-28 17:28:52.893  INFO 18986 --- [emfire.events-1] log-sink                                 : {key:1,new_value:value 1}
2017-10-28 17:41:24.466  INFO 18986 --- [emfire.events-1] log-sink                                 : {key:2,new_value:value 2}</pre></li><li class="listitem">You&#8217;re done!</li></ol></div></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="_summary_4" href="#_summary_4"></a>Summary</h4></div></div></div><p>In this sample, you have learned:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">How to use Spring Cloud Data Flow&#8217;s <code class="literal">Local</code> and <code class="literal">Cloud Foundry</code> servers</li><li class="listitem">How to use Spring Cloud Data Flow&#8217;s <code class="literal">shell</code></li><li class="listitem">How to create streaming data pipeline to connect and publish events from <code class="literal">gemfire</code></li></ul></div></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a name="spring-cloud-data-flow-samples-gemfire-cq-log-overview" href="#spring-cloud-data-flow-samples-gemfire-cq-log-overview"></a>1.3.3&nbsp;Gemfire CQ to Log Demo</h3></div></div></div><p>In this demonstration, you will learn how to build a data pipeline using <a class="link" href="http://cloud.spring.io/spring-cloud-dataflow/" target="_top">Spring Cloud Data Flow</a> to consume data from a <code class="literal">gemfire-cq</code> (Continuous Query) endpoint and write to a log using the <code class="literal">log</code> sink.
The <code class="literal">gemfire-cq</code> source creates a Continuous Query to monitor events for a region that match the query&#8217;s result set and publish a message whenever such an event is emitted. In this example, we simulate monitoring orders to trigger a process whenever
the quantity ordered is above a defined limit.</p><p>We will take you through the steps to configure and run Spring Cloud Data Flow server in either a <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started/" target="_top">local</a> or <a class="link" href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#getting-started" target="_top">Cloud Foundry</a> environment.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>For legacy reasons the <code class="literal">gemfire</code> Spring Cloud Stream Apps are named after <code class="literal">Pivotal GemFire</code>. The code base for the commercial product has since been open sourced as <code class="literal">Apache Geode</code>. These samples should work with compatible versions of Pivotal GemFire or Apache Geode. Herein we will refer to the installed IMDG simply as <code class="literal">Geode</code>.</p></td></tr></table></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="_prerequisites_5" href="#_prerequisites_5"></a>Prerequisites</h4></div></div></div><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A Running Data Flow Shell</li></ul></div><p>The Spring Cloud Data Flow Shell is available for <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-deploying-spring-cloud-dataflow" target="_top">download</a> or you can <a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow" target="_top">build</a> it yourself.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>The Spring Cloud Data Flow Shell is a Spring Boot application that connects to the Data Flow Server&#8217;s REST API and supports a DSL that simplifies the process of defining a stream or task and managing its lifecycle. Most of these samples
use the shell. If you prefer, you can use the Data Flow UI <a class="link" href="http://localhost:9393/dashboard" target="_top">localhost:9393/dashboard</a>, (or wherever it the server is hosted) to perform the same operations.</p></td></tr></table></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>the Spring Cloud Data Flow Shell and Local server implementation are in the same repository and are both built by running <code class="literal">./mvnw install</code> from the project root directory. If you have already run the build, use the jar in <code class="literal">spring-cloud-dataflow-shell/target</code></p></td></tr></table></div><p>To run the Shell open a new terminal session:</p><pre class="screen">$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar
  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
dataflow:&gt;</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>The shell will try to connect to a local server by default. If the Local Dataflow Server is not running you will see:</p></td></tr></table></div><pre class="screen"> ____                              ____ _                __
/ ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
\___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
 ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
|____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
 ____ |_|    _          __|___/                 __________
|  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
| | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
| |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
|____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
server unknown:&gt;</pre><p>Connect the <code class="literal">shell</code> to the <code class="literal">server</code> running on , e.g., <code class="literal"><a class="link" href="http://dataflow-server.app.io" target="_top">dataflow-server.app.io</a></code></p><pre class="screen">server unknown:&gt;dataflow config server http://dataflow-server.app.io
Successfully targeted http://dataflow-server.app.io
dataflow:&gt;</pre><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A Geode installation with a locator and cache server running
Unresolved directive in streaming/gemfire/gemfire-cq-log/overview.adoc - include::geode-setup.adoc[]</li></ul></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="gemfire-cq-log-local" href="#gemfire-cq-log-local"></a>Using the Local Server</h4></div></div></div><div class="section"><div class="titlepage"><div><div><h5 class="title"><a name="_additional_prerequisites_9" href="#_additional_prerequisites_9"></a>Additional Prerequisites</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A Running Data Flow Server</li></ul></div><p>The Local Data Flow Server is Spring Boot application available for <a class="link" href="http://cloud.spring.io/spring-cloud-dataflow/" target="_top">download</a> or you can <a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow" target="_top">build</a> it yourself.
If you build it yourself, the executable jar will be in <code class="literal">spring-cloud-dataflow-server-local/target</code></p><p>To run the Local Data Flow server Open a new terminal session:</p><pre class="screen">$cd  &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-LOCAL-JAR&gt;
$java -jar spring-cloud-dataflow-server-local-&lt;VERSION&gt;.jar</pre><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A running instance of <a class="link" href="https://www.rabbitmq.com" target="_top">Rabbit MQ</a></li></ul></div><p></p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">Use gfsh to start a locator and server</p><pre class="screen">gfsh&gt;start locator --name=locator1
gfsh&gt;start server --name=server1</pre></li><li class="listitem"><p class="simpara">Create a region called <code class="literal">Orders</code></p><pre class="screen">gfsh&gt;create region --name Orders --type=REPLICATE</pre><p class="simpara">===== Use the Shell to create the sample stream.</p></li><li class="listitem"><p class="simpara"><a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app" target="_top">Register</a> the out-of-the-box applications for the Rabbit binder</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>These samples assume that the Data Flow Server can access a remote Maven repository, <code class="literal"><a class="link" href="https://repo.spring.io/libs-release" target="_top">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration" target="_top">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code class="literal">dataflow:&gt;app import --uri <a class="link" href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" target="_top">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code class="literal"><a class="link" href="https://repo.spring.io" target="_top">repo.spring.io</a></code>. For example,
<code class="literal">source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code class="literal">http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code class="literal">maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a class="link" href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties" target="_top">download</a> the required apps or <a class="link" href="https://github.com/spring-cloud-stream-app-starters" target="_top">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code class="literal">dataflow:&gt;app register&#8230;&#8203;</code> using the <code class="literal">maven://</code> resource URI format corresponding to your installed app.</p></td></tr></table></div><pre class="screen">dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</pre></li><li class="listitem"><p class="simpara">Create the stream</p><p class="simpara">This example creates an gemfire-cq source to which will publish events matching a query criteria on a region. In this case we will monitor the <code class="literal">Orders</code> region. For simplicity, we will avoid creating a data structure for the order.
Each cache entry contains an integer value representing the quantity of the ordered item. This stream will fire a message whenever the value&gt;999. By default, the source emits only the value. Here we will override that using the
<code class="literal">cq-event-expression</code> property.  This accepts a SpEL expression bound to a <a class="link" href="https://geode.apache.org/releases/latest/javadoc/org/apache/geode/cache/query/CqEvent.html" target="_top">CQEvent</a>. To reference the entire CQEvent instace, we use <code class="literal">#this</code>.
In order to display the contents in the log, we will invoke <code class="literal">toString()</code> on the instance.</p><pre class="screen">dataflow:&gt;stream create --name orders --definition " gemfire-cq --query='SELECT * from /Orders o where o &gt; 999' --cq-event-expression=#this.toString() | log" --deploy
Created and deployed new stream 'events'</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>If the Geode locator isn&#8217;t running on default port on <code class="literal">localhost</code>, add the options <code class="literal">--connect-type=locator --host-addresses=&lt;host&gt;:&lt;port&gt;</code>. If there are multiple
locators, you can provide a comma separated list of locator addresses. This is not necessary for the sample but is typical for production environments to enable fail-over.</p></td></tr></table></div></li><li class="listitem"><p class="simpara">Verify the stream is successfully deployed</p><pre class="screen">dataflow:&gt;stream list</pre></li><li class="listitem"><p class="simpara">Monitor stdout for the log sink. When you deploy the stream, you will see log messages in the Data Flow server console like this</p><pre class="screen">2017-10-30 09:39:36.283  INFO 8167 --- [nio-9393-exec-5] o.s.c.d.spi.local.LocalAppDeployer       : Deploying app with deploymentId orders.log instance 0.
   Logs will be in /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/spring-cloud-dataflow-5375107584795488581/orders-1509370775940/orders.log</pre><p class="simpara">Copy the location of the <code class="literal">log</code> sink logs. This is a directory that ends in <code class="literal">orders.log</code>. The log files will be in <code class="literal">stdout_0.log</code> under this directory. You can monitor the output of the log sink using <code class="literal">tail</code>, or something similar:</p><pre class="screen">$tail -f /var/folders/hd/5yqz2v2d3sxd3n879f4sg4gr0000gn/T/spring-cloud-dataflow-5375107584795488581/orders-1509370775940/orders.log/stdout_0.log</pre></li><li class="listitem"><p class="simpara">Using <code class="literal">gfsh</code>, create and update some cache entries</p><pre class="screen">gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 01234 --value 1000
gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 11234 --value 1005
gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 21234 --value 100
gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 31234 --value 999
gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 21234 --value 1000</pre></li><li class="listitem"><p class="simpara">Observe the log output
You should see messages like:</p><pre class="screen">2017-10-30 09:53:02.231  INFO 8563 --- [ire-cq.orders-1] log-sink                                 : CqEvent [CqName=GfCq1; base operation=CREATE; cq operation=CREATE; key=01234; value=1000]
2017-10-30 09:53:19.732  INFO 8563 --- [ire-cq.orders-1] log-sink                                 : CqEvent [CqName=GfCq1; base operation=CREATE; cq operation=CREATE; key=11234; value=1005]
2017-10-30 09:53:53.242  INFO 8563 --- [ire-cq.orders-1] log-sink                                 : CqEvent [CqName=GfCq1; base operation=UPDATE; cq operation=CREATE; key=21234; value=1000]</pre></li><li class="listitem">Another interesting demonstration combines <code class="literal">gemfire-cq</code> with the <a class="link" href=":../http-gemfire/README.adoc" target="_top">http-gemfire</a> example.</li></ol></div><pre class="screen">dataflow:&gt; stream create --name stocks --definition "http --port=9090 | gemfire-json-server --regionName=Stocks --keyExpression=payload.getField('symbol')" --deploy
dataflow:&gt; stream create --name stock_watch --definition "gemfire-cq --query='Select * from /Stocks where symbol=''VMW''' | log" --deploy</pre><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">You&#8217;re done!</li></ol></div></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="gemfire-cq-log-cf" href="#gemfire-cq-log-cf"></a>Using the Cloud Foundry Server</h4></div></div></div><div class="section"><div class="titlepage"><div><div><h5 class="title"><a name="_additional_prerequisites_10" href="#_additional_prerequisites_10"></a>Additional Prerequisites</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">A Cloud Foundry instance</li><li class="listitem">The Spring Cloud Data Flow Cloud Foundry Server</li></ul></div><p>The Cloud Foundry Data Flow Server is Spring Boot application available for <a class="link" href="http://cloud.spring.io/spring-cloud-dataflow/" target="_top">download</a> or you can <a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow-server-cloudfoundry" target="_top">build</a> it yourself.
If you build it yourself, the executable jar will be in <code class="literal">spring-cloud-dataflow-server-cloudfoundry/target</code></p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>Although you can run the Data Flow Cloud Foundry Server locally and configure it to deploy to any Cloud Foundry instance, we will
deploy the server to Cloud Foundry as recommended.</p></td></tr></table></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">Verify that CF instance is reachable (Your endpoint urls will be different from what is shown here).</p><pre class="screen">$ cf api
API endpoint: https://api.system.io (API version: ...)

$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

No apps found</pre></li><li class="listitem"><p class="simpara">Follow the instructions to deploy the <a class="link" href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle" target="_top">Spring Cloud Data Flow Cloud Foundry server</a>. Don&#8217;t worry about creating a Redis service. We won&#8217;t need it. If you are familiar with Cloud Foundry
application manifests, we recommend creating a manifest for the the Data Flow server as shown <a class="link" href="https://docs.spring.io/spring-cloud-dataflow-server-cloudfoundry/docs/current/reference/htmlsingle/#sample-manifest-template" target="_top">here</a>.</p><div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Warning"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Warning]" src="images/warning.png"></td><th align="left">Warning</th></tr><tr><td align="left" valign="top"><p>As of this writing, there is a typo on the <code class="literal">SPRING_APPLICATION_JSON</code> entry in the sample manifest. <code class="literal">SPRING_APPLICATION_JSON</code> must be followed by <code class="literal">:</code> and The JSON string must be
wrapped in single quotes. Alternatively, you can replace that line with <code class="literal">MAVEN_REMOTE_REPOSITORIES_REPO1_URL: <a class="link" href="https://repo.spring.io/libs-snapshot" target="_top">repo.spring.io/libs-snapshot</a></code>.  If your Cloud Foundry installation is behind a firewall, you may need to install the stream apps used in this sample in your internal Maven repository and <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/1.3.0.M2/reference/htmlsingle/#getting-started-maven-configuration" target="_top">configure</a> the server to access that repository.</p></td></tr></table></div></li><li class="listitem"><p class="simpara">Once you have successfully executed <code class="literal">cf push</code>, verify the dataflow server is running</p><pre class="screen">$ cf apps
Getting apps in org [your-org] / space [your-space] as user...
OK

name                 requested state   instances   memory   disk   urls
dataflow-server      started           1/1         1G       1G     dataflow-server.app.io</pre></li><li class="listitem">Notice that the <code class="literal">dataflow-server</code> application is started and ready for interaction via the url endpoint</li><li class="listitem"><p class="simpara">Connect the <code class="literal">shell</code> with <code class="literal">server</code> running on Cloud Foundry, e.g., <code class="literal"><a class="link" href="http://dataflow-server.app.io" target="_top">dataflow-server.app.io</a></code></p><pre class="screen">$ cd &lt;PATH/TO/SPRING-CLOUD-DATAFLOW-SHELL-JAR&gt;
$ java -jar spring-cloud-dataflow-shell-&lt;VERSION&gt;.jar

  ____                              ____ _                __
 / ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
 \___ \| '_ \| '__| | '_ \ / _` | | |   | |/ _ \| | | |/ _` |
  ___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
 |____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
  ____ |_|    _          __|___/                 __________
 |  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
 | | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
 | |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
 |____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/


Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type "help".
server-unknown:&gt;</pre><pre class="screen">server-unknown:&gt;dataflow config server http://dataflow-server.app.io
Successfully targeted http://dataflow-server.app.io
dataflow:&gt;</pre><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">Running instance of a <code class="literal">rabbit</code> service in Cloud Foundry</li><li class="listitem">Running instance of the <a class="link" href="https://docs.pivotal.io/p-cloud-cache/1-0/developer.html" target="_top">Pivotal Cloud Cache for PCF</a> (PCC) service <code class="literal">cloudcache</code> in Cloud Foundry.</li></ul></div></li><li class="listitem"><p class="simpara"><a class="link" href="https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/spring-cloud-dataflow-docs/src/main/asciidoc/streams.adoc#register-a-stream-app" target="_top">Register</a> the out-of-the-box applications for the Rabbit binder</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>These samples assume that the Data Flow Server can access a remote Maven repository, <code class="literal"><a class="link" href="https://repo.spring.io/libs-release" target="_top">repo.spring.io/libs-release</a></code> by default. If your Data Flow server is running behind a firewall, or you are using a maven proxy preventing
access to public repositories, you will need to install the sample apps in your internal Maven repository and <a class="link" href="https://docs.spring.io/spring-cloud-dataflow/docs/current/reference/htmlsingle/#getting-started-maven-configuration" target="_top">configure</a>
the server accordingly.  The sample applications are typically registered using Data Flow&#8217;s bulk import facility. For example, the Shell command <code class="literal">dataflow:&gt;app import --uri <a class="link" href="http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven" target="_top">bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</a></code> (The actual URI is release and binder specific so refer to the sample instructions for the actual URL).
The bulk import URI references a plain text file containing entries for all of the publicly available Spring Cloud Stream and Task applications published to <code class="literal"><a class="link" href="https://repo.spring.io" target="_top">repo.spring.io</a></code>. For example,
<code class="literal">source.http=maven://org.springframework.cloud.stream.app:http-source-rabbit:1.2.0.RELEASE</code> registers the <code class="literal">http</code> source app at the corresponding Maven address, relative to the remote repository(ies) configured for the
Data Flow server. The format is <code class="literal">maven://&lt;groupId&gt;:&lt;artifactId&gt;:&lt;version&gt;</code>  You will need to <a class="link" href="https://repo.spring.io/libs-release/org/springframework/cloud/stream/app/spring-cloud-stream-app-descriptor/Bacon.RELEASE/spring-cloud-stream-app-descriptor-Bacon.RELEASE.rabbit-apps-maven-repo-url.properties" target="_top">download</a> the required apps or <a class="link" href="https://github.com/spring-cloud-stream-app-starters" target="_top">build</a> them and then install them in your Maven repository, using whatever group, artifact, and version you choose. If you do
this, register individual apps using <code class="literal">dataflow:&gt;app register&#8230;&#8203;</code> using the <code class="literal">maven://</code> resource URI format corresponding to your installed app.</p></td></tr></table></div><pre class="screen">dataflow:&gt;app import --uri http://bit.ly/Bacon-RELEASE-stream-applications-rabbit-maven</pre></li><li class="listitem"><p class="simpara">Get the PCC connection information</p><pre class="screen">$ cf service-key cloudcache my-service-key
Getting key my-service-key for service instance cloudcache as &lt;user&gt;...

{
 "locators": [
  "10.0.16.9[55221]",
  "10.0.16.11[55221]",
  "10.0.16.10[55221]"
 ],
 "urls": {
  "gfsh": "http://...",
  "pulse": "http://.../pulse"
 },
 "users": [
  {
   "password": &lt;password&gt;,
   "username": "cluster_operator"
  },
  {
   "password": &lt;password&gt;,
   "username": "developer"
  }
 ]
}</pre></li><li class="listitem"><p class="simpara">Using <code class="literal">gfsh</code>, connect to the PCC instance as <code class="literal">cluster_operator</code> using the service key values and create the Test region.</p><pre class="screen">gfsh&gt;connect --use-http --url=&lt;gfsh-url&gt; --user=cluster_operator --password=&lt;cluster_operator_password&gt;
gfsh&gt;create region --name Orders --type=REPLICATE</pre></li><li class="listitem"><p class="simpara">Create the stream using the Data Flow Shell</p><p class="simpara">This example creates an gemfire-cq source to which will publish events matching a query criteria on a region. In this case we will monitor the <code class="literal">Orders</code> region. For simplicity, we will avoid creating a data structure for the order.
Each cache entry contains an integer value representing the quantity of the ordered item. This stream will fire a message whenever the value&gt;999. By default, the source emits only the value. Here we will override that using the
<code class="literal">cq-event-expression</code> property.  This accepts a SpEL expression bound to a <a class="link" href="https://geode.apache.org/releases/latest/javadoc/org/apache/geode/cache/query/CqEvent.html" target="_top">CQEvent</a>. To reference the entire CQEvent instace, we use <code class="literal">#this</code>.
In order to display the contents in the log, we will invoke <code class="literal">toString()</code> on the instance.</p><pre class="screen">dataflow:&gt;stream create --name orders --definition " gemfire-cq  --username=developer --password=&lt;developer-password&gt; --connect-type=locator --host-addresses=10.0.16.9:55221 --query='SELECT * from /Orders o where o &gt; 999' --cq-event-expression=#this.toString()  | log" --deploy
Created and deployed new stream 'events'</pre></li><li class="listitem"><p class="simpara">Verify the stream is successfully deployed</p><pre class="screen">dataflow:&gt;stream list</pre></li><li class="listitem"><p class="simpara">Monitor stdout for the log sink</p><pre class="screen">cf logs &lt;log-sink-app-name&gt;</pre></li><li class="listitem"><p class="simpara">Using <code class="literal">gfsh</code>, create and update some cache entries</p><pre class="screen">gfsh&gt;connect --use-http --url=&lt;gfsh-url&gt; --user=cluster_operator --password=&lt;cluster_operator_password&gt;
gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 01234 --value 1000
gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 11234 --value 1005
gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 21234 --value 100
gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 31234 --value 999
gfsh&gt;put --region Orders  --value-class java.lang.Integer --key 21234 --value 1000</pre></li><li class="listitem"><p class="simpara">Observe the log output
You should see messages like:</p><pre class="screen">2017-10-30 09:53:02.231  INFO 8563 --- [ire-cq.orders-1] log-sink                                 : CqEvent [CqName=GfCq1; base operation=CREATE; cq operation=CREATE; key=01234; value=1000]
2017-10-30 09:53:19.732  INFO 8563 --- [ire-cq.orders-1] log-sink                                 : CqEvent [CqName=GfCq1; base operation=CREATE; cq operation=CREATE; key=11234; value=1005]
2017-10-30 09:53:53.242  INFO 8563 --- [ire-cq.orders-1] log-sink                                 : CqEvent [CqName=GfCq1; base operation=UPDATE; cq operation=CREATE; key=21234; value=1000]</pre></li><li class="listitem">Another interesting demonstration combines <code class="literal">gemfire-cq</code> with the <a class="link" href="../http-gemfire/README.adoc" target="_top">http-gemfire</a> example.</li></ol></div><pre class="screen">dataflow:&gt; stream create --name stocks --definition "http --port=9090 | gemfire-json-server --regionName=Stocks --keyExpression=payload.getField('symbol')" --deploy
dataflow:&gt; stream create --name stock_watch --definition "gemfire-cq --query='Select * from /Stocks where symbol=''VMW''' | log" --deploy</pre><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">You&#8217;re done!</li></ol></div></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a name="_summary_5" href="#_summary_5"></a>Summary</h4></div></div></div><p>In this sample, you have learned:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem">How to use Spring Cloud Data Flow&#8217;s <code class="literal">Local</code> and <code class="literal">Cloud Foundry</code> servers</li><li class="listitem">How to use Spring Cloud Data Flow&#8217;s <code class="literal">shell</code></li><li class="listitem">How to create streaming data pipeline to connect and publish CQ events from <code class="literal">gemfire</code></li></ul></div></div></div></div></div><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="pr01.html">Prev</a>&nbsp;</td><td width="20%" align="center">&nbsp;</td><td width="40%" align="right">&nbsp;<a accesskey="n" href="_task_batch.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;2.&nbsp;Task / Batch</td></tr></table></div></body></html>